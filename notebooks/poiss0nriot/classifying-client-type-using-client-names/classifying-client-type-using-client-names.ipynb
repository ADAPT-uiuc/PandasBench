{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scale_input_data(scale_factor):\n",
    "  file_bases = ['./input/cliente_tabla']\n",
    "  for file_base in file_bases:\n",
    "    import pandas as pd\n",
    "    import shutil\n",
    "    if scale_factor == 1.0:\n",
    "      shutil.copyfile(file_base + '.csv', file_base + '.scaled.csv')\n",
    "      continue\n",
    "    df_to_scale = pd.read_csv(file_base + '.csv')\n",
    "    new_num_rows = int(scale_factor * len(df_to_scale))\n",
    "    if scale_factor <= 1.0:\n",
    "      df_to_scale = df_to_scale.iloc[:new_num_rows]\n",
    "    else:\n",
    "      while len(df_to_scale) < new_num_rows:\n",
    "        df_to_scale = pd.concat([df_to_scale, df_to_scale[:min(new_num_rows - len(df_to_scale), len(df_to_scale))]])\n",
    "    df_to_scale.to_csv(file_base + '.scaled.csv', index=False)\n",
    "\n",
    "if 'INPUT_SCALE_FACTOR' in os.environ:\n",
    "  scale_input_data(float(os.environ['INPUT_SCALE_FACTOR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3b594320-8094-c257-7d7e-ed603b9bf591"
   },
   "source": [
    "The methods used to generate the filter terms involved looking at the most frequent words/client names for clues about what types of establishments were mentioned in this data set. \n",
    "\n",
    "Developing the filters took a fair amount of \"human\" sleuthing while looking at TF-IDF scores, frequency counts of Client names, as well as just general knowledge of common Spanish words used to refer to certain establishment types. Especially with all the noise provided by the Clients referred to only by a proper name, the filtered data is a proportionally small figure- but, significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ea1ed3af-7c78-af45-48eb-63318a2b7442"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "exec(os.environ['IREWR_IMPORTS'])\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "# ALEX: remove path printing\n",
    "# from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# Load in the Client Name data\n",
    "# Make sure all names uppercase (there are some mixed instances)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "vf = pd.read_csv('./input/cliente_tabla.scaled.csv',header=0)\n",
    "vf['NombreCliente'] = vf['NombreCliente'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "bd0d3505-f09a-a87a-cd21-2eed0ab908a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO IDENTIFICADO    281670\n",
       "LUPITA               4863\n",
       "MARY                 3016\n",
       "LA PASADITA          2426\n",
       "LA VENTANITA         2267\n",
       "                    ...  \n",
       "ORTIZ                 239\n",
       "RIVERA                238\n",
       "LA CURVA              238\n",
       "TANIA                 238\n",
       "JUAREZ                236\n",
       "Name: NombreCliente, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin with a scan of the Client Name Data based on Top Frequency Client Names\n",
    "# Notice there are a lot of Proper Names\n",
    "vf['NombreCliente'].value_counts()[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "90d7e98e-d2d2-bdb1-2ea9-cfeb284fff69"
   },
   "outputs": [],
   "source": [
    "# Let's also generate a list of individual word frequency across all names\n",
    "def tfidf_score_list(vf2, list_len):\n",
    "# ALEX: remove ML code\n",
    "#     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#     v = TfidfVectorizer()\n",
    "\n",
    "    vf2['New'] = 'na'\n",
    "    a = \" \".join(vf2['NombreCliente'])\n",
    "    vf2['New'][0] = a\n",
    "\n",
    "# ALEX: remove ML code\n",
    "#     tfidf = v.fit_transform(vf2['New'])\n",
    "\n",
    "#     feature_names = v.get_feature_names()\n",
    "\n",
    "#     freq = []\n",
    "#     doc = 0\n",
    "#     feature_index = tfidf[doc,:].nonzero()[1]\n",
    "#     tfidf_scores = zip(feature_index, [tfidf[doc, x] for x in feature_index])\n",
    "#     for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "#             freq.append((w.encode('utf-8'),s))\n",
    "    _ = vf2['New']\n",
    "    \n",
    "    del vf2['New']\n",
    "    \n",
    "# ALEX: remove non pandas code\n",
    "#     import numpy as np\n",
    "#     names = ['word','score']\n",
    "#     formats = ['S50','f8']\n",
    "#     dtype = dict(names = names, formats=formats)\n",
    "#     array = np.array(freq, dtype=dtype)\n",
    "\n",
    "#     b = np.sort(array, order='score')\n",
    "    \n",
    "#     if list_len > len(b)+1:\n",
    "#         list_len = len(b)+1\n",
    "#     for i in range(1,list_len):\n",
    "#         print(b[-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "df442457-7ff7-9fe3-c98f-cb3364c8abbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_373515/1840792958.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vf2['New'][0] = a\n"
     ]
    }
   ],
   "source": [
    "tfidf_score_list(vf, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b0b380ad-daeb-d162-3afa-cda2beb1f238"
   },
   "source": [
    "Again, notice the prevalence of personal names. By looking at a long enough list, however, we can start to see some other useful terms appear such as particles of speech (i.e. 'ag', 'los', 'san') or more useful words like \"super\", \"oxxo\", \"mini\", \"comodin\". If I found a word that I thought represent a type of establishment, I'd double check it by doing a single search. If that search was fruitful and had a good amount of relevant results, I'd add it to my filter. An example of a single term search is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "f99fdec9-2183-336b-4823-a12415cf0faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Cliente_ID                   NombreCliente\n",
      "78            1438           CAFETRIA PREPARATORIA\n",
      "1095          5045   CAFETERIA DE LA SECUNDARIA 13\n",
      "1098          5048               CAFETERIA PREPA 2\n",
      "1233          5416                       CAFETERIA\n",
      "1318          5612  CAFETERIA NORMAL DE PROFESORES\n",
      "...            ...                             ...\n",
      "934488     9678492         CAFETERIA LA CASA VIEJA\n",
      "934720     9693686        SECUNDARIA 7 CAFETERIA 2\n",
      "934786     9702948               NUEVO CAFE AZTECA\n",
      "934942     9711388                 CAFETERIA SALOM\n",
      "935214     9746888               CAFETERIA LA VACA\n",
      "\n",
      "[2508 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(vf[vf['NombreCliente'].str.contains('.*CAFE.*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de47e9ea-9257-3cd1-8fea-ae1e558571d8"
   },
   "source": [
    "The result is a filter derived from hand-picking the best, most common, most interesting terms I could determine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "15b70b9a-5eee-60fe-30c6-734f2427e354"
   },
   "outputs": [],
   "source": [
    "# --- Begin Filtering for specific terms\n",
    "\n",
    "# Note that the order of filtering is significant.\n",
    "# For example: \n",
    "# The regex of .*ERIA.* will assign \"FRUITERIA\" to 'Eatery' rather than 'Fresh Market'.\n",
    "# In other words, the first filters to occur have a bigger priority.\n",
    "\n",
    "def filter_specific(vf2):\n",
    "    \n",
    "    # Known Large Company / Special Group Types\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*REMISION.*','Consignment')\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace(['.*WAL MART.*','.*SAMS CLUB.*'],'Walmart', regex=True)\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*OXXO.*','Oxxo Store')\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*CONASUPO.*','Govt Store')\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*BIMBO.*','Bimbo Store')\n",
    "\n",
    "    \n",
    "\n",
    "    # General term search for a random assortment of words I picked from looking at\n",
    "    # their frequency of appearance in the data and common spanish words for these categories\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace(['.*COLEG.*','.*UNIV.*','.*ESCU.*','.*INSTI.*',\\\n",
    "                                                        '.*PREPAR.*'],'School', regex=True)\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*PUESTO.*','Post')\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace(['.*FARMA.*','.*HOSPITAL.*','.*CLINI.*'],'Hospital/Pharmacy', regex=True)\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace(['.*CAFE.*','.*CREMERIA.*','.*DULCERIA.*',\\\n",
    "                                                        '.*REST.*','.*BURGER.*','.*TACO.*', '.*TORTA.*',\\\n",
    "                                                        '.*TAQUER.*','.*HOT DOG.*',\\\n",
    "                                                        '.*COMEDOR.*', '.*ERIA.*','.*BURGU.*'],'Eatery', regex=True)\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*SUPER.*','Supermarket')\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace(['.*COMERCIAL.*','.*BODEGA.*','.*DEPOSITO.*',\\\n",
    "                                                            '.*ABARROTES.*','.*MERCADO.*','.*CAMBIO.*',\\\n",
    "                                                        '.*MARKET.*','.*MART .*','.*MINI .*',\\\n",
    "                                                        '.*PLAZA.*','.*MISC.*','.*ELEVEN.*','.*EXP.*',\\\n",
    "                                                         '.*SNACK.*', '.*PAPELERIA.*', '.*CARNICERIA.*',\\\n",
    "                                                         '.*LOCAL.*','.*COMODIN.*','.*PROVIDENCIA.*'\n",
    "                                                        ],'General Market/Mart'\\\n",
    "                                                       , regex=True)\n",
    "\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace(['.*VERDU.*','.*FRUT.*'],'Fresh Market', regex=True)\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace(['.*HOTEL.*','.*MOTEL.*'],'Hotel', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "75fe8a16-850a-58f2-05fc-aa1d57230a18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_373515/2161136115.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*REMISION.*','Consignment')\n",
      "/tmp/ipykernel_373515/2161136115.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*OXXO.*','Oxxo Store')\n",
      "/tmp/ipykernel_373515/2161136115.py:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*CONASUPO.*','Govt Store')\n",
      "/tmp/ipykernel_373515/2161136115.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*BIMBO.*','Bimbo Store')\n",
      "/tmp/ipykernel_373515/2161136115.py:23: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*PUESTO.*','Post')\n",
      "/tmp/ipykernel_373515/2161136115.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  vf2['NombreCliente'] = vf2['NombreCliente'].str.replace('.*SUPER.*','Supermarket')\n"
     ]
    }
   ],
   "source": [
    "filter_specific(vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "11333ead-d5e9-d2dd-42c0-c76a37557c3f"
   },
   "outputs": [],
   "source": [
    "# --- Begin filtering for more general terms\n",
    "# The idea here is to look for names with particles of speech that would\n",
    "# not appear in a person's name.\n",
    "# i.e. \"Individuals\" should not contain any participles or numbers in their names.\n",
    "def filter_participle(vf2):\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].replace([\n",
    "            '.*LA .*','.*EL .*','.*DE .*','.*LOS .*','.*DEL .*','.*Y .*', '.*SAN .*', '.*SANTA .*',\\\n",
    "            '.*AG .*','.*LAS .*','.*MI .*','.*MA .*', '.*II.*', '.*[0-9]+.*'\\\n",
    "    ],'Small Franchise', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "d8d886b1-f9f3-aa3b-969b-fc87af86a3b7"
   },
   "outputs": [],
   "source": [
    "filter_participle(vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "cbb3224c-176d-44f7-a836-7d679d125670"
   },
   "outputs": [],
   "source": [
    "# Any remaining entries should be \"Individual\" Named Clients, there are some outliers.\n",
    "# More specific filters could be used in order to reduce the percentage of outliers in this final set.\n",
    "def filter_remaining(vf2):\n",
    "    def function_word(data):\n",
    "        # Avoid the single-words created so far by checking for upper-case\n",
    "        if (data.isupper()) and (data != \"NO IDENTIFICADO\"): \n",
    "            return 'Individual'\n",
    "        else:\n",
    "            return data\n",
    "    vf2['NombreCliente'] = vf2['NombreCliente'].map(function_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "2183458d-79c4-f1ab-c95c-8b0c2d6b1245"
   },
   "outputs": [],
   "source": [
    "filter_remaining(vf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "246e11a0-1f67-a9f1-ddba-8952ca5e1ae6"
   },
   "source": [
    "With the filtering complete, let's look at the breakdown of how the data is classified now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "95fff309-9d78-da69-a9a1-fe0a804910f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Individual             353145\n",
       "NO IDENTIFICADO        281670\n",
       "Small Franchise        160501\n",
       "General Market/Mart     66416\n",
       "Eatery                  30419\n",
       "Supermarket             16019\n",
       "Oxxo Store               9313\n",
       "Hospital/Pharmacy        5798\n",
       "School                   5705\n",
       "Post                     2667\n",
       "Hotel                    1127\n",
       "Fresh Market             1069\n",
       "Govt Store                959\n",
       "Bimbo Store               320\n",
       "Walmart                   220\n",
       "Consignment                14\n",
       "Name: NombreCliente, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf['NombreCliente'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "42eab5d7-6f9d-330c-d3a2-0889a48b56a6"
   },
   "source": [
    "Finally, we can apply these new tags on the actual Training and Test data sets that have been provided!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "4d0c9cc6-7b74-a807-7d02-6f616ab0f250"
   },
   "outputs": [],
   "source": [
    "vf.to_csv('clustered_cln.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "a9a0c462-aa96-19dd-da6b-24b62210bd2a"
   },
   "outputs": [],
   "source": [
    "#trdf = pd.read_csv('./input/train.csv',header=0)\n",
    "#trdf_stores = trdf.merge(vf.drop_duplicates(subset=['Cliente_ID']), how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "1fdc94cd-eca3-4f3b-ad3b-467ea796b08e"
   },
   "outputs": [],
   "source": [
    "#tsdf = pd.read_csv('./input/test.csv',header=0)\n",
    "#tsdf_stores = tsdf.merge(vf.drop_duplicates(subset=['Cliente_ID']), how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a81b2b30-2d17-2e23-d2c2-da5e31569a5b"
   },
   "source": [
    "Write the data to file to save it for a new session...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "6c2b467e-a4e4-8baa-ca6c-624ab7bcd097"
   },
   "outputs": [],
   "source": [
    "#trdf.to_csv('./output/train_with_cnames.csv')\n",
    "#tsdf.to_csv('./output/test_with_cnames.csv')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 103,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}