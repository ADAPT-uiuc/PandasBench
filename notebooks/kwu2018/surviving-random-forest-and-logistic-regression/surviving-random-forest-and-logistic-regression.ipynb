{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scale_input_data(scale_factor):\n",
    "  file_bases = ['./input/train']\n",
    "  for file_base in file_bases:\n",
    "    import pandas as pd\n",
    "    import shutil\n",
    "    if scale_factor == 1.0:\n",
    "      shutil.copyfile(file_base + '.csv', file_base + '.scaled.csv')\n",
    "      continue\n",
    "    df_to_scale = pd.read_csv(file_base + '.csv')\n",
    "    new_num_rows = int(scale_factor * len(df_to_scale))\n",
    "    if scale_factor <= 1.0:\n",
    "      df_to_scale = df_to_scale.iloc[:new_num_rows]\n",
    "    else:\n",
    "      while len(df_to_scale) < new_num_rows:\n",
    "        df_to_scale = pd.concat([df_to_scale, df_to_scale[:min(new_num_rows - len(df_to_scale), len(df_to_scale))]])\n",
    "    df_to_scale.to_csv(file_base + '.scaled.csv', index=False)\n",
    "\n",
    "if 'INPUT_SCALE_FACTOR' in os.environ:\n",
    "  scale_input_data(float(os.environ['INPUT_SCALE_FACTOR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "873313bb-a293-a19f-fd9f-97293bbbdad6"
   },
   "source": [
    "## Modeling Titanic Surviors Using Random Forest and Logistic Regression\n",
    "with visualization and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "22bf7304-72ac-d7c9-4f5b-fa7fb085b191"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "exec(os.environ['IREWR_IMPORTS'])\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# FIRST-AUTHOR: remove plotting, ML code\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set(style=\"whitegrid\", color_codes=True)\n",
    "# %matplotlib inline\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import ExtraTreesClassifier   # used to get feature importance\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from sklearn import svm\n",
    "#from sklearn.modelselection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f3c80fe4-9f47-4e0c-7288-5d94096c0e71"
   },
   "source": [
    "## 2. Load and Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "11be7a58-9214-7769-d3a2-d6e2788a4c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "-------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "-------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load both training set and test set\n",
    "train_set = pd.read_csv(\"./input/train.scaled.csv\")\n",
    "test_set = pd.read_csv(\"./input/train.scaled.csv\")\n",
    "\n",
    "# Example the data\n",
    "train_set.info()\n",
    "print(\"-------------------------------------\")\n",
    "test_set.info()\n",
    "# print(\"-------------------------------------\")\n",
    "# print(train_set.head())\n",
    "# print(\"-------------------------------------\")\n",
    "# print(test_set.head())\n",
    "print(\"-------------------------------------\")\n",
    "train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cc689ba0-5129-aead-c881-74df4e331f62"
   },
   "source": [
    "### 2.1 Combined both data sets so we can handle feature engineering in one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "dc8e6f3d-d8a0-015b-1806-f8b41b008482"
   },
   "outputs": [],
   "source": [
    "# Add a empyt Survived column on the test set\n",
    "# Later on we will separate two sets using this column\n",
    "test_set['Survived'] = np.NaN\n",
    "alldata = pd.concat([train_set, test_set], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "af6caf8f-f7ef-a972-acc3-0424cb39e529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1782 entries, 0 to 1781\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1782 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1782 non-null   int64  \n",
      " 3   Name         1782 non-null   object \n",
      " 4   Sex          1782 non-null   object \n",
      " 5   Age          1428 non-null   float64\n",
      " 6   SibSp        1782 non-null   int64  \n",
      " 7   Parch        1782 non-null   int64  \n",
      " 8   Ticket       1782 non-null   object \n",
      " 9   Fare         1782 non-null   float64\n",
      " 10  Cabin        408 non-null    object \n",
      " 11  Embarked     1778 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 167.2+ KB\n"
     ]
    }
   ],
   "source": [
    "alldata.info() # we need to convert the Survived column back to int before model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6df4d384-3b3f-db67-499c-5a811c1352bc"
   },
   "source": [
    "### 2.2. Handle missing data/feature imputation\n",
    "#### 2.2.1. Cabin column\n",
    "We added Cabin after we have done few iterations of model fitting however It did not help to improve the model. So we dropped this feature before creating the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "a93a29bf-9956-c7ca-b999-238b21a0f063"
   },
   "outputs": [],
   "source": [
    "# replacing missing cabins with N (for No)\n",
    "# alldata['Cabin'].fillna('N',inplace=True)\n",
    "    \n",
    "# # only keep cabin letter as it might indicate the levels and positions of the cabins\n",
    "# alldata['Cabin'] = alldata['Cabin'].map(lambda x : x[0])\n",
    "# cabin_dummies = pd.get_dummies(alldata['Cabin'],prefix='Cabin')\n",
    "    \n",
    "# alldata = alldata.join(cabin_dummies)\n",
    "\n",
    "# Lets start to keep track of columns to be dropped\n",
    "# We keep the original column for now so we can compare the values of some of the transfered columns\n",
    "# to make sure that there is no bug. For dummy variables, this is most unlikely as it is created by a method call.\n",
    "# But some of transformation performed manually later might introduce bugs\n",
    "drop_list = ['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "603f7b27-ed11-74fd-ed33-300242fb2095"
   },
   "source": [
    "#### 2.2.2. A lot of missing data for Age column\n",
    "There are 177 missing values out 891 in the training set alone. Instead of random assigning values, we will try to intelligently guessing some of the values using the titles of the passengers in the Name column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a4f4339b-46ed-eb4e-2f20-883f932ead17"
   },
   "outputs": [],
   "source": [
    "# Create a Title column\n",
    "alldata['Title'] = alldata['Name'].apply(lambda x: re.sub('(.*, )|(\\\\..*)','', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b6c3ff4a-971c-e773-acbe-781fa6a7cdb8"
   },
   "outputs": [],
   "source": [
    "# print(alldata[alldata['Age'].isnull()].groupby('Title').size())\n",
    "# print('--------------------------------------------------------')\n",
    "# alldata[alldata['Age'].notnull()].groupby('Title')['Age'].agg({'Count': np.size, \n",
    "#                               'Min': np.min, 'Max': np.max, 'Avg': np.mean, 'Std': np.std})          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b6ae3c0f-b3ae-d551-6977-2461fe592cd2"
   },
   "outputs": [],
   "source": [
    "# Create a new Age2 column\n",
    "alldata['Age2'] = alldata['Age']\n",
    "\n",
    "# There are 8 empty Age column with title Master in the Name column\n",
    "# We will randomly pick between 0 and 14 as the ages for these 4 records\n",
    "kids_no_age = (alldata['Title'] == 'Master') & alldata.Age.isnull()\n",
    "# FIRST-AUTHOR: make notebook run\n",
    "# alldata.ix[kids_no_age, 'Age2'] = np.random.randint(0, 14, 8)\n",
    "alldata.loc[kids_no_age, 'Age2'] = np.random.randint(0, 14, alldata.loc[kids_no_age].shape[0])\n",
    "\n",
    "# Only one Dr has missing value, lets use the mean from doctor with ages\n",
    "dr_no_age = (alldata['Title'] == 'Dr') & alldata.Age.isnull()\n",
    "dr_with_age = (alldata['Title'] == 'Dr') & alldata.Age.notnull()\n",
    "# FIRST-AUTHOR: make notebook run\n",
    "# alldata.ix[dr_no_age, 'Age2'] = alldata[dr_with_age]['Age'].mean()\n",
    "alldata.loc[dr_no_age, 'Age2'] = alldata[dr_with_age]['Age'].mean()\n",
    "\n",
    "# Only one Ms has missing value and one with value\n",
    "ms_no_age = (alldata['Title'] == 'Ms') & alldata.Age.isnull()\n",
    "ms_with_age = (alldata['Title'] == 'Ms') & alldata.Age.notnull()\n",
    "# FIRST-AUTHOR: make notebook run\n",
    "# alldata.ix[ms_no_age, 'Age2'] = int(alldata[ms_with_age]['Age'].mean())\n",
    "alldata.loc[ms_no_age, 'Age2'] = int(alldata[ms_with_age]['Age'].mean())\n",
    "\n",
    "# Use average for each title grop to fill up the rest of null values\n",
    "# We could also combine SibSp and Parch columns to make more educated guess\n",
    "# But lets see how we do without that\n",
    "# Mr\n",
    "mr_with_age = (alldata['Title'] == 'Mr') & alldata.Age.notnull()\n",
    "min_mr_age = min(alldata[mr_with_age]['Age'])\n",
    "max_mr_age = max(alldata[mr_with_age]['Age'])               \n",
    "mr_no_age = (alldata['Title'] == 'Mr') & alldata.Age.isnull()\n",
    "# alldata.ix[mr_no_age, 'Age2'] =  np.random.randint(min_mr_age, max_mr_age, len(alldata.ix[mr_no_age]))\n",
    "# FIRST-AUTHOR: make notebook run\n",
    "# alldata.ix[mr_no_age, 'Age2'] = np.median(alldata[mr_with_age]['Age'])\n",
    "alldata.loc[mr_no_age, 'Age2'] = np.median(alldata[mr_with_age]['Age'])\n",
    "# Miss\n",
    "miss_with_age = (alldata['Title'] == 'Miss') & alldata.Age.notnull()\n",
    "miss_no_age = (alldata['Title'] == 'Miss') & alldata.Age.isnull()\n",
    "min_miss_age = min(alldata[miss_with_age]['Age'])\n",
    "max_miss_age = max(alldata[miss_with_age]['Age'])\n",
    "# alldata.ix[miss_no_age, 'Age2'] = np.random.randint(min_miss_age, max_miss_age, len(alldata.ix[miss_no_age]))\n",
    "# FIRST-AUTHOR: make notebook run\n",
    "# alldata.ix[miss_no_age, 'Age2'] = np.median(alldata[miss_with_age]['Age'])\n",
    "alldata.loc[miss_no_age, 'Age2'] = np.median(alldata[miss_with_age]['Age'])\n",
    "# Mrs\n",
    "mrs_with_age = (alldata['Title'] == 'Mrs') & alldata.Age.notnull()\n",
    "mrs_no_age = (alldata['Title'] == 'Mrs') & alldata.Age.isnull()\n",
    "min_mrs_age = min(alldata[mrs_with_age]['Age'])\n",
    "max_mrs_age = max(alldata[mrs_with_age]['Age'])\n",
    "# alldata.ix[mrs_no_age, 'Age2'] = np.random.randint(min_mrs_age, max_mrs_age, len(alldata.ix[mrs_no_age]))\n",
    "# FIRST-AUTHOR: make notebook run\n",
    "# alldata.ix[mrs_no_age, 'Age2'] = np.median(alldata[mrs_with_age]['Age'])\n",
    "alldata.loc[mrs_no_age, 'Age2'] = np.median(alldata[mrs_with_age]['Age'])\n",
    "\n",
    "alldata['Age2'] = alldata.Age2.astype(int)\n",
    "\n",
    "# Lets drop Age column late\n",
    "drop_list.append('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "32c86f9b-5605-6b57-946d-5d3e798b313c"
   },
   "source": [
    "#### 2.2.3. Missing fare (only one missing record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "2c89507b-e39c-3b1f-84b9-88660189f359"
   },
   "outputs": [],
   "source": [
    "alldata[\"Fare\"].fillna(alldata[\"Fare\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c6298f02-6514-a97d-bea8-2e47697b735f"
   },
   "source": [
    "## 3. Exploratory Analysis + Feature Engineering/Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "73ea6d4d-0130-3ed9-dd9e-57f62eb4a22a"
   },
   "source": [
    "### 3.1. Transfer Sex column\n",
    "Transfer Sex column to three dummy variables(Child, Adult_Female, Adult_Male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "332f1124-76a8-8b40-eca0-b06b5494ef73"
   },
   "outputs": [],
   "source": [
    "# As we see, Children(age < ~16) on aboard seem to have a high chances for Survival.\n",
    "# So, we can classify passengers as adult males, adult female, and Child\n",
    "def get_who(who):\n",
    "    return 'Child' if who.Age2 < 16 else who.Sex\n",
    "    \n",
    "alldata['Who'] = alldata[['Age2','Sex']].apply(get_who,axis=1)\n",
    "\n",
    "# adding a text Class column\n",
    "class_text = {1: 'First', 2: 'Second', 3: 'Third'}\n",
    "alldata['Class'] = alldata['Pclass'].map(class_text)\n",
    "\n",
    "# FIRST-AUTHOR: remove plotting\n",
    "# g = sns.factorplot(x=\"Who\", y=\"Survived\", col=\"Class\", \n",
    "#     data=alldata[alldata['Survived'].notnull()], saturation=.5,\n",
    "#     kind=\"bar\", ci=None, aspect=.6)\n",
    "# (g.set_axis_labels(\"\", \"Survival Rate\")\n",
    "# .set_xticklabels([\"Men\", \"Women\", \"Children\"])\n",
    "# .set_titles(\"{col_name} {col_var}\")\n",
    "# .despine(left=True))  \n",
    "_ = alldata[alldata['Survived'].notnull()]\n",
    "\n",
    "# Add Sex column to the drop list since we created Who column\n",
    "drop_list.append('Sex')\n",
    "\n",
    "# create dummy variables for Who column\n",
    "# drop Male as it has the lowest average of survived passengers\n",
    "who_dummies  = pd.get_dummies(alldata['Who'])\n",
    "who_dummies.columns = ['Child','Adult_Female','Adult_Male']\n",
    "who_dummies.drop(['Adult_Male'], axis=1, inplace=True)\n",
    "\n",
    "alldata = alldata.join(who_dummies.astype(int))\n",
    "\n",
    "drop_list.append('Class')\n",
    "drop_list.append('Who')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7a8dd1d3-bb8c-9a98-aa20-90f2e1103f5a"
   },
   "source": [
    "### 3.2. Fare column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "131e1ac3-1449-b8e9-94f6-9c067468f706"
   },
   "outputs": [],
   "source": [
    "alldata['Fare'] = alldata['Fare'].astype(int)\n",
    "\n",
    "# get fare for survived & not-survived passengers \n",
    "fare_not_survived = alldata[alldata['Survived'] == 0]['Fare']\n",
    "fare_survived     = alldata[alldata['Survived'] == 1]['Fare']\n",
    "\n",
    "# get average and std for fare of survived/not survived passengers\n",
    "#avgerage_fare = pd.DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
    "#std_fare      = pd.DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
    "\n",
    "# plot\n",
    "# fig, (axis1,axis2) = plt.subplots(ncols=2, figsize= (10,5))\n",
    "# FIRST-AUTHOR: remove plotting\n",
    "# figure1 = plt.figure(figsize=(12,5))\n",
    "# plt.hist([fare_survived, fare_not_survived], stacked=True, color = ['g','black'], \n",
    "#          label = ['Survived','Not Survived'], bins = 25)\n",
    "# plt.xlabel('Fare')\n",
    "# plt.ylabel('Number of Passengers')\n",
    "# plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e36ebbdb-ddb2-c185-a0fe-8a4ec8e7cb1a"
   },
   "source": [
    "### 3.3. Pclass Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "84927a1f-5390-01e7-81e7-ca6239c847b1"
   },
   "outputs": [],
   "source": [
    "# FIRST-AUTHOR: remove plotting\n",
    "# sns.factorplot('Pclass','Survived', order=[1,2,3], kind='bar', ci=False, data=alldata[alldata['Survived'].notnull()])\n",
    "_ = alldata[alldata['Survived'].notnull()]\n",
    "\n",
    "# create dummy variables for Pclass column, & drop 3rd class as it has the lowest average of survived passengers\n",
    "pclass_dummies  = pd.get_dummies(alldata['Pclass'])\n",
    "pclass_dummies.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "drop_list.append('Pclass')\n",
    "\n",
    "alldata = alldata.join(pclass_dummies.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "3969ed6e-6e6c-74fb-2df7-028e6b73665a"
   },
   "outputs": [],
   "source": [
    "### 3.4. Family Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "41742b48-ee58-ab99-268a-646b8bc5d075"
   },
   "outputs": [],
   "source": [
    "# Instead of having two columns Parch & SibSp\n",
    "# we can have only one column represent if the passenger had any family member aboard or not,\n",
    "# Meaning, if having any family member(whether parent, brother, ...etc) will increase chances of Survival or not.\n",
    "# So we are going to keep \n",
    "alldata['Family'] =  alldata[\"Parch\"] + alldata[\"SibSp\"]\n",
    "\n",
    "alldata['Family'] = alldata['Family'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "alldata['FamilySize'] =  alldata[\"Parch\"] + alldata[\"SibSp\"] + 1\n",
    "\n",
    "# plot the survivor count by family size and survivor rate by family size side-by-side\n",
    "# FIRST-AUTHOR: remove plotting\n",
    "# fig, (axis1,axis2) = plt.subplots(ncols=2, figsize= (10,5))\n",
    "\n",
    "# sns.countplot(x=\"FamilySize\", hue=\"Survived\", ax=axis1, data=alldata[alldata['Survived'].notnull()])\n",
    "# sns.factorplot(x=\"FamilySize\", y=\"Survived\",kind='bar', ax=axis2, ci=False, \n",
    "#                 data=alldata[alldata['Survived'].notnull()])\n",
    "_ = alldata[alldata['Survived'].notnull()]\n",
    "_ = alldata[alldata['Survived'].notnull()]\n",
    "\n",
    "# Use Family size (test score = 0.789) vs Family (test score = 0.756)\n",
    "drop_list.append('Family')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "80e2817d-8385-c418-6129-f0eeb006eed5"
   },
   "source": [
    "### 3.5. Encode Title column into numbers\n",
    "It seems that adding this feature does not improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "626127ba-c8ba-d384-c566-333514aa94bc"
   },
   "outputs": [],
   "source": [
    "# FIRST-AUTHOR: remove ML code\n",
    "# le = preprocessing.LabelEncoder()\n",
    "\n",
    "# alldata['Title2'] = le.fit_transform(alldata['Title'])\n",
    "alldata['Title2'] = alldata['Title']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "84308951-6f62-be4f-26f5-1d2c7302cf6f"
   },
   "source": [
    "### 3.7. Drop variables that will not be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "e7f36be1-ff83-6cae-a93c-7af01dc3870e"
   },
   "outputs": [],
   "source": [
    "drop_list += ['Title', 'Name','Ticket','Embarked', 'SibSp','Parch']\n",
    "alldata.drop(drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7b3def83-c56d-2446-75a2-c948792a83f4"
   },
   "source": [
    "### 3.8. More Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "a6b59dde-7e84-49a5-ca85-67f71e7ba6ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_333982/2659108856.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr = alldata[alldata['Survived'].notnull()].drop(['PassengerId'], axis = 1).corr()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age2</th>\n",
       "      <th>Child</th>\n",
       "      <th>Adult_Female</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "      <th>FamilySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257482</td>\n",
       "      <td>-0.078578</td>\n",
       "      <td>0.136884</td>\n",
       "      <td>0.506562</td>\n",
       "      <td>0.285904</td>\n",
       "      <td>0.093349</td>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099002</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.191044</td>\n",
       "      <td>0.591693</td>\n",
       "      <td>-0.116346</td>\n",
       "      <td>0.217052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age2</th>\n",
       "      <td>-0.078578</td>\n",
       "      <td>0.099002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.572913</td>\n",
       "      <td>0.066849</td>\n",
       "      <td>0.337534</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>-0.271249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Child</th>\n",
       "      <td>0.136884</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>-0.572913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.217481</td>\n",
       "      <td>-0.133146</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.441518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult_Female</th>\n",
       "      <td>0.506562</td>\n",
       "      <td>0.191044</td>\n",
       "      <td>0.066849</td>\n",
       "      <td>-0.217481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144043</td>\n",
       "      <td>0.060483</td>\n",
       "      <td>0.107192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_1</th>\n",
       "      <td>0.285904</td>\n",
       "      <td>0.591693</td>\n",
       "      <td>0.337534</td>\n",
       "      <td>-0.133146</td>\n",
       "      <td>0.144043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.288585</td>\n",
       "      <td>-0.046114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_2</th>\n",
       "      <td>0.093349</td>\n",
       "      <td>-0.116346</td>\n",
       "      <td>0.014698</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>0.060483</td>\n",
       "      <td>-0.288585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FamilySize</th>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.217052</td>\n",
       "      <td>-0.271249</td>\n",
       "      <td>0.441518</td>\n",
       "      <td>0.107192</td>\n",
       "      <td>-0.046114</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Survived      Fare      Age2     Child  Adult_Female   Class_1  \\\n",
       "Survived      1.000000  0.257482 -0.078578  0.136884      0.506562  0.285904   \n",
       "Fare          0.257482  1.000000  0.099002  0.003551      0.191044  0.591693   \n",
       "Age2         -0.078578  0.099002  1.000000 -0.572913      0.066849  0.337534   \n",
       "Child         0.136884  0.003551 -0.572913  1.000000     -0.217481 -0.133146   \n",
       "Adult_Female  0.506562  0.191044  0.066849 -0.217481      1.000000  0.144043   \n",
       "Class_1       0.285904  0.591693  0.337534 -0.133146      0.144043  1.000000   \n",
       "Class_2       0.093349 -0.116346  0.014698  0.009655      0.060483 -0.288585   \n",
       "FamilySize    0.016639  0.217052 -0.271249  0.441518      0.107192 -0.046114   \n",
       "\n",
       "               Class_2  FamilySize  \n",
       "Survived      0.093349    0.016639  \n",
       "Fare         -0.116346    0.217052  \n",
       "Age2          0.014698   -0.271249  \n",
       "Child         0.009655    0.441518  \n",
       "Adult_Female  0.060483    0.107192  \n",
       "Class_1      -0.288585   -0.046114  \n",
       "Class_2       1.000000   -0.038594  \n",
       "FamilySize   -0.038594    1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = alldata[alldata['Survived'].notnull()].drop(['PassengerId'], axis = 1).corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "f5e89445-d7f4-472b-d9f6-e01b50d7592b"
   },
   "outputs": [],
   "source": [
    "# FIRST-AUTHOR: remove plotting\n",
    "# sns.heatmap(corr, \n",
    "#             xticklabels=corr.columns.values,\n",
    "#             yticklabels=corr.columns.values)\n",
    "_ = corr.columns.values\n",
    "_ = corr.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd3387df-d31f-113f-1638-092725121ed2"
   },
   "source": [
    "### 3.9. Prepare the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "12589da8-f295-71f6-a7e5-15c4b7a513c0"
   },
   "outputs": [],
   "source": [
    "train = alldata[alldata['Survived'].notnull()].copy()\n",
    "test = alldata[alldata['Survived'].isnull()].copy()\n",
    "\n",
    "train.drop('PassengerId', axis=1, inplace = True)\n",
    "\n",
    "X_train = train.drop('Survived', axis=1)\n",
    "y_train= train['Survived'].astype('int') # when concatting train set and test set, the Survived column changed to float\n",
    "\n",
    "\n",
    "X_test  = test.drop(['Survived', 'PassengerId'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c30a81c-589e-2dc4-17c8-5a92ef40395a"
   },
   "source": [
    "#### 3.9.1. Feature Scaling\n",
    "For RF and LR classifiers, scaling does not make any difference. We will skip below step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "bd91ed46-6840-4fb4-6793-db5453cdeca3"
   },
   "outputs": [],
   "source": [
    "# Lets  scale all features to [0, 1] range\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# X_train = X_train / X_train.max()\n",
    "# X_test = X_test / X_test.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd085118-4758-f12a-cce4-a61effe8ba86"
   },
   "source": [
    "## 4. Modeling and Hyperparameter Turning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04d10419-7190-3adb-c716-c966665c012e"
   },
   "source": [
    "### 4.1. Random Forests with OOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "42b2b9ec-0d19-73e0-f922-c95204876edf"
   },
   "outputs": [],
   "source": [
    "# Random Forests with OOB\n",
    "# FIRST-AUTHOR: remove ML code, plotting\n",
    "# min_estimators = 30\n",
    "# max_estimators = 180\n",
    "\n",
    "# RANDOM_STATE = 2017\n",
    "\n",
    "# rf_clf = RandomForestClassifier(oob_score=True, warm_start=True, random_state=RANDOM_STATE)\n",
    "# error_rate = []\n",
    "# for i in range(min_estimators, max_estimators + 1):\n",
    "#     rf_clf.set_params(n_estimators=i)\n",
    "#     rf_clf.fit(X_train, y_train)\n",
    "    \n",
    "#     # Record the OOB error for each `n_estimators=i` setting.\n",
    "#     oob_error = 1 - rf_clf.oob_score_\n",
    "#     error_rate.append(oob_error)\n",
    "\n",
    "# label = \"RandomForestClassifier, max_features=None\"\n",
    "# # Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n",
    "# plt.plot(range(min_estimators, max_estimators + 1), error_rate, label=label)\n",
    "\n",
    "# plt.xlim(min_estimators, max_estimators)\n",
    "# plt.xlabel(\"n_estimators\")\n",
    "# plt.ylabel(\"OOB error rate\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.show()\n",
    "# rf_clf.score(X_train, y_train)\n",
    "# We got a test score of 0.75 for random forest which is less that we got from LR (0.79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "872639c2-6946-156e-03d8-64e60b5115fc"
   },
   "source": [
    "#### 4.2.1. Calculate Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "89907930-a1b1-e008-f4c0-507c2fed039a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title2</td>\n",
       "      <td>Title2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FamilySize</td>\n",
       "      <td>FamilySize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Class_2</td>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Class_1</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Child</td>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Age2</td>\n",
       "      <td>Age2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adult_Female</td>\n",
       "      <td>Adult_Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature    Importance\n",
       "0        Title2        Title2\n",
       "1          Fare          Fare\n",
       "2    FamilySize    FamilySize\n",
       "3       Class_2       Class_2\n",
       "4       Class_1       Class_1\n",
       "5         Child         Child\n",
       "6          Age2          Age2\n",
       "7  Adult_Female  Adult_Female"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use variable importance to validate our intuition\n",
    "# And to go back to perform further feature engineering\n",
    "# or to check code for potential bugs\n",
    "# FIRST-AUTHOR: remove ML code\n",
    "# et_clf = ExtraTreesClassifier(n_estimators=120)\n",
    "# et_clf = et_clf.fit(X_train, y_train)\n",
    "features = pd.DataFrame()\n",
    "features['Feature'] = X_train.columns\n",
    "# FIRST-AUTHOR: remove ML code\n",
    "# features['Importance'] = et_clf.feature_importances_\n",
    "features['Importance'] = X_train.columns\n",
    "features = features.sort_values('Importance',ascending=False)\\\n",
    "                    .reset_index(drop = True)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "29bc2716-5545-3202-a326-3a2e3638285c"
   },
   "source": [
    "### 4.3. Logistic Regression\n",
    "We got the highest score with this learner. We will use this one for the perdiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "c0d72683-3ce3-2840-2f9f-8c34b6984aab"
   },
   "outputs": [],
   "source": [
    "# FIRST-AUTHOR: remove ML code\n",
    "# log_reg = LogisticRegression()\n",
    "# log_reg.fit(X_train, y_train)\n",
    "# log_reg.score(X_train, y_train)\n",
    "#log_reg.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5fe1042-b2bc-6c02-0c4b-40e89b1ef57a"
   },
   "source": [
    "#### 4.3.1. Get correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "6fdf964e-5e94-758f-c308-aa882a3b0bc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult_Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Class_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FamilySize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Title2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature\n",
       "0          Fare\n",
       "1          Age2\n",
       "2         Child\n",
       "3  Adult_Female\n",
       "4       Class_1\n",
       "5       Class_2\n",
       "6    FamilySize\n",
       "7        Title2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff = pd.DataFrame()\n",
    "coeff['Feature'] = X_train.columns\n",
    "# FIRST-AUTHOR: remove ML code\n",
    "# coeff['Coefficient Estimate'] = pd.Series(log_reg.coef_[0])\n",
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9ec94e6b-1467-3e35-1cc8-3f4ac919ee32"
   },
   "source": [
    "## 5. Making Prediction\n",
    "We will use the model from logistic regression as it has highest test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "c6e0e26c-d69d-d149-b8a7-0caca72aacf7"
   },
   "outputs": [],
   "source": [
    "# rf_clf1 = RandomForestClassifier()\n",
    "# rf_clf1.set_params(n_estimators=120)\n",
    "# rf_clf1.fit(X_train, y_train)\n",
    "    \n",
    "# y_test = rf_clf1.predict(X_test)\n",
    "\n",
    "# rf_clf1.score(X_train, y_train)\n",
    "# FIRST-AUTHOR: remove ML code\n",
    "# y_test = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "a331714c-a00e-2596-732a-ebc0ff0c6fff"
   },
   "outputs": [],
   "source": [
    "# FIRST-AUTHOR: remove ML code\n",
    "# submission = pd.DataFrame({\n",
    "#         \"PassengerId\": test[\"PassengerId\"],\n",
    "#         \"Survived\": y_test\n",
    "#     })\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test[\"PassengerId\"],\n",
    "        \"Survived\": y_train\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "d10eb4b7-86a7-c1c9-983d-1e5e487e610f"
   },
   "outputs": [],
   "source": [
    "# we will try 3 or 5-fold cross validation with SVM at some later time\n",
    "# svc_clf = svm.SVC()\n",
    "\n",
    "# kfold = KFold(n_splits=5)\n",
    "\n",
    "# [svc_clf.fit(X_train[train], y_train[train]).score(X_train[test], y_train[test])\n",
    "#         for train, test in k_fold.split(X_train)]\n",
    "# y_test = svc.predict(X_test)\n",
    "\n",
    "# svc_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "aeac9333-7c22-33a4-47ef-ca40a8dc0a62"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 3,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}