{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scale_input_data(scale_factor):\n",
    "  file_bases = ['./input/train_V2', './input/test_V2']\n",
    "  for file_base in file_bases:\n",
    "    import pandas as pd\n",
    "    import shutil\n",
    "    if scale_factor == 1.0:\n",
    "      shutil.copyfile(file_base + '.csv', file_base + '.scaled.csv')\n",
    "      continue\n",
    "    df_to_scale = pd.read_csv(file_base + '.csv')\n",
    "    new_num_rows = int(scale_factor * len(df_to_scale))\n",
    "    if scale_factor <= 1.0:\n",
    "      df_to_scale = df_to_scale.iloc[:new_num_rows]\n",
    "    else:\n",
    "      while len(df_to_scale) < new_num_rows:\n",
    "        df_to_scale = pd.concat([df_to_scale, df_to_scale[:min(new_num_rows - len(df_to_scale), len(df_to_scale))]])\n",
    "    df_to_scale.to_csv(file_base + '.scaled.csv', index=False)\n",
    "\n",
    "if 'INPUT_SCALE_FACTOR' in os.environ:\n",
    "  scale_input_data(float(os.environ['INPUT_SCALE_FACTOR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e94bacf94b72dd3aa9f98a0739720aaeb0bb4592"
   },
   "source": [
    "# How to Score (0.0255 - 0.0245)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6ce5c887793b1e1e3966d948b393f39a1ec15c1"
   },
   "source": [
    "Before I start explaining the code, I have to say that the most of this code was taken from [[This kernel](https://www.kaggle.com/anycode/simple-nn-baseline-3)] by [anycode](https://www.kaggle.com/anycode) Kaggler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29449ddea25f9e4a474022e0707c5233eb862faa"
   },
   "source": [
    "**Fisrt :** Let's load the needed dependencies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "053e8ab055a5459dc7275032566f7c2ac093bda8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5BJracUTf2a_",
    "outputId": "40f7e71f-7f8f-40cc-b7fc-f777b2bb803a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "exec(os.environ['IREWR_IMPORTS'])\n",
    "\n",
    "# ALEX: remove plotting, ML code\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt  \n",
    "\n",
    "# from timeit import default_timer as timer\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# !pip install ultimate\n",
    "# from ultimate.mlp import MLP \n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# import gc, sys\n",
    "# gc.enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "25340d25393956af64192adf337cdc70f4b5b9f5",
    "colab": {},
    "colab_type": "code",
    "id": "L_dvgO8MmGNt"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove extra display code\n",
    "# def state(message,start = True, time = 0):\n",
    "#     if(start):\n",
    "#         print(f'Working on {message} ... ')\n",
    "#     else :\n",
    "#         print(f'Working on {message} took ({round(time , 3)}) Sec \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7318a8b680619e0e8afbd9c37a42875f2a4908cc",
    "colab": {},
    "colab_type": "code",
    "id": "LIvATfaPgK9t"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = \"./input/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "80d4c440be019b60242aeb51c283b6f1a50b36cd"
   },
   "source": [
    "** I explained the following code with comments, I hope you understand it well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "6635ac14017e4233225c622dc6d8c59f4e5676f5",
    "colab": {},
    "colab_type": "code",
    "id": "pb-1FR4SgNvh"
   },
   "outputs": [],
   "source": [
    "def feature_engineering(is_train=True):\n",
    "    # When this function is used for the training data, load train_V2.csv :\n",
    "    if is_train: \n",
    "        print(\"processing train_V2.csv\")\n",
    "        df = pd.read_csv(INPUT_DIR + 'train_V2.scaled.csv')\n",
    "        \n",
    "        # Only take the samples with matches that have more than 1 player \n",
    "        # there are matches with no players or just one player ( those samples could affect our model badly) \n",
    "        df = df[df['maxPlace'] > 1]\n",
    "    \n",
    "    # When this function is used for the test data, load test_V2.csv :\n",
    "    else:\n",
    "        print(\"processing test_V2.csv\")\n",
    "        df = pd.read_csv(INPUT_DIR + 'test_V2.scaled.csv')\n",
    "        \n",
    "    # Make a new feature indecating the total distance a player cut :\n",
    "# ALEX: remove extra display code\n",
    "#     state('totalDistance')\n",
    "#     s = timer()\n",
    "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
    "# ALEX: remove extra display code\n",
    "#     e = timer()\n",
    "#     state('totalDistance', False, e - s)\n",
    "          \n",
    "\n",
    "# ALEX: remove extra display code\n",
    "#     state('rankPoints')\n",
    "#     s = timer()\n",
    "    # Process the 'rankPoints' feature by replacing any value of (-1) to be (0) :\n",
    "    df['rankPoints'] = np.where(df['rankPoints'] <= 0 ,0 , df['rankPoints'])\n",
    "# ALEX: remove extra display code\n",
    "#     e = timer()                                  \n",
    "#     state('rankPoints', False, e-s)\n",
    "    \n",
    "\n",
    "    target = 'winPlacePerc'\n",
    "    # Get a list of the features to be used\n",
    "    features = list(df.columns)\n",
    "    \n",
    "    # Remove some features from the features list :\n",
    "    features.remove(\"Id\")\n",
    "    features.remove(\"matchId\")\n",
    "    features.remove(\"groupId\")\n",
    "    features.remove(\"matchDuration\")\n",
    "    features.remove(\"matchType\")\n",
    "    \n",
    "    y = None\n",
    "    \n",
    "    # If we are processing the training data, process the target\n",
    "    # (group the data by the match and the group then take the mean of the target) \n",
    "    if is_train: \n",
    "        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n",
    "        # Remove the target from the features list :\n",
    "        features.remove(target)\n",
    "    \n",
    "    # Make new features indicating the mean of the features ( grouped by match and group ) :\n",
    "    print(\"get group mean feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    \n",
    "    # If we are processing the training data let df_out = the grouped  'matchId' and 'groupId'\n",
    "    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n",
    "    # If we are processing the test data let df_out = 'matchId' and 'groupId' without grouping \n",
    "    else: df_out = df[['matchId','groupId']]\n",
    "    \n",
    "    # Merge agg and agg_rank (that we got before) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the max value of the features for each group ( grouped by match )\n",
    "    print(\"get group max feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the minimum value of the features for each group ( grouped by match )\n",
    "    print(\"get group min feature\")\n",
    "    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n",
    "    # Put the new features into a rank form ( max value will have the highest rank)\n",
    "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
    "    \n",
    "    # Merge the new (agg and agg_rank) with df_out :\n",
    "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
    "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the number of players in each group ( grouped by match )\n",
    "    print(\"get group size feature\")\n",
    "    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n",
    "     \n",
    "    # Merge the group_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
    "    \n",
    "    # Make new features indicating the mean value of each features for each match :\n",
    "    print(\"get match mean feature\")\n",
    "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
    "    \n",
    "    # Merge the new agg with df_out :\n",
    "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
    "    \n",
    "    # Make new features indicating the number of groups in each match :\n",
    "    print(\"get match size feature\")\n",
    "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
    "    \n",
    "    # Merge the match_size feature with df_out :\n",
    "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
    "    \n",
    "    # Drop matchId and groupId\n",
    "    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
    "    \n",
    "    # X is the output dataset (without the target) and y is the target :\n",
    "    X = np.array(df_out, dtype=np.float64)\n",
    "    \n",
    "    \n",
    "# ALEX: remove GC code\n",
    "#     del df, df_out, agg, agg_rank\n",
    "#     gc.collect()\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c05975ca8d9f84d6a401b4e02c1aea88a068d99"
   },
   "source": [
    "### Process and scale the training data  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "416aec24dd82c27e63c5af2d7d3b8039255c1006",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "colab_type": "code",
    "id": "ZAFoSDp1gSLu",
    "outputId": "bc27e575-4c67-4e2d-e861-ca9532d4c50b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing train_V2.csv\n",
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n"
     ]
    }
   ],
   "source": [
    "# ALEX: remove IPython commands\n",
    "# %%time\n",
    "# Process the training data :\n",
    "x_train, y = feature_engineering(True)\n",
    "# Scale the data to be in the range (-1 , 1)\n",
    "# ALEX: remove ML code\n",
    "# scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1), copy=False).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4919d7141d4a3bc97fd38abe573547d867e85471",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vfTGA9EzggdB",
    "outputId": "6bd921c4-11f7-46d4-9b24-fea309dfe352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (2026744, 170) 41270.1 0.0\n",
      "x_train (2026744, 170) 41270.1 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape, x_train.max(), x_train.min())\n",
    "# ALEX: remove ML code\n",
    "# scaler.transform(x_train)\n",
    "print(\"x_train\", x_train.shape, x_train.max(), x_train.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc6b1fd2c89520c6b666b908b7ece6dd32486dc0"
   },
   "source": [
    "### Scale the target to be in the range (-1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "98e247099cb92b3e0e3672f185e4a501c3003469",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LTigJv6XggWY",
    "outputId": "b539069c-2d32-40ef-d16f-74095c7923f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (2026744,) 1.0 -1.0\n"
     ]
    }
   ],
   "source": [
    "y = y * 2 - 1\n",
    "print(\"y\", y.shape, y.max(), y.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f2cec7ad02d49ebfc950f5d92913f6d510a7eba1"
   },
   "source": [
    "## Define an MLP model and train it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "68aa5465fcdaf005f293634fc1fb9282c1119fac"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove IPython commands, ML code\n",
    "# %%time\n",
    "# # create NN_model\n",
    "# NN_model = Sequential()\n",
    "# NN_model.add(Dense(x_train.shape[1],  input_dim = x_train.shape[1], activation='relu'))\n",
    "# NN_model.add(Dense(136, activation='relu'))\n",
    "# NN_model.add(Dense(136, activation='relu'))\n",
    "# NN_model.add(Dense(136, activation='relu'))\n",
    "# NN_model.add(Dense(136, activation='relu'))\n",
    "\n",
    "# # output Layer\n",
    "# NN_model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# # Compile the network :\n",
    "# NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "# NN_model.summary()\n",
    "_ = x_train.shape[1]\n",
    "_ = x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ba1a9f68626711f48217fa7c183406301ed5fe8c"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "# callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "d3cf8babc38cb0691d05ea488a384a5c047fa4fb"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove IPython commands, ML code\n",
    "# %%time\n",
    "# NN_model.fit(x=x_train, y=y, batch_size=1000,\n",
    "#              epochs=30, verbose=1, callbacks=callbacks_list,\n",
    "#              validation_split=0.15, validation_data=None, shuffle=True,\n",
    "#              class_weight=None, sample_weight=None, initial_epoch=0,\n",
    "#              steps_per_epoch=None, validation_steps=None)\n",
    "# del x_train, y\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7367e594d36776cf939ed9a75f5b1101ee62a3a"
   },
   "source": [
    "## Process the test data and scale it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "0ea711cf7886daf6edff5386c78ede1ee3ebfbac",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "QxYbGfSrggJJ",
    "outputId": "2d0f8b2a-cfbf-4804-b3c1-3fbca06f7649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing test_V2.csv\n",
      "get group mean feature\n",
      "get group max feature\n",
      "get group min feature\n",
      "get group size feature\n",
      "get match mean feature\n",
      "get match size feature\n",
      "x_test (1934174, 170) 40799.92 0.0\n",
      "x_test (1934174, 170) 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "x_test, _ = feature_engineering(False)\n",
    "# ALEX: remove ML code\n",
    "# scaler.transform(x_test)\n",
    "print(\"x_test\", x_test.shape, x_test.max(), x_test.min())\n",
    "np.clip(x_test, out=x_test, a_min=-1, a_max=1)\n",
    "print(\"x_test\", x_test.shape, x_test.max(), x_test.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0d48339d573f4c0987ba19eacce79e7335c82a0"
   },
   "source": [
    "### Predict the target using the test data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "25f10b259cdf4152eb2af45adf27536c637c9081",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "WOYIroTRggA1",
    "outputId": "896b0504-beae-47de-8e02-b4448400fb5e"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove IPython commands, ML code\n",
    "# %%time\n",
    "# pred = NN_model.predict(x_test)\n",
    "# del x_test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "674af22f065081b2cfbaf7eb61fe752ed1a461c2"
   },
   "source": [
    "### Reshape the predictions and put them in the right range(0 , 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c46e855cf0b13b462fe600c8190f262a0bc08e1e",
    "colab": {},
    "colab_type": "code",
    "id": "geRcvFyngc6L"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# pred = pred.reshape(-1)\n",
    "# pred = (pred + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ae2bf6549c7a64553d080912de6d18c5d34cf0fd",
    "colab": {},
    "colab_type": "code",
    "id": "FWdw5ggPgeXS"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(INPUT_DIR + 'test_V2.scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "2b847ce9c5d44d7ce176497d8efda8bf191655c1",
    "colab": {},
    "colab_type": "code",
    "id": "LxLZ53chgedw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix winPlacePerc\n"
     ]
    }
   ],
   "source": [
    "# ALEX: remove IPython commands, ML code\n",
    "# %%time\n",
    "pred = [0 for _ in range(len(df_test))]\n",
    "print(\"fix winPlacePerc\")\n",
    "for i in range(len(df_test)):\n",
    "# ALEX: remove ML code\n",
    "#     winPlacePerc = pred[i]\n",
    "    winPlacePerc = 0.5\n",
    "    maxPlace = int(df_test.iloc[i]['maxPlace'])\n",
    "    if maxPlace == 0:\n",
    "        winPlacePerc = 0.0\n",
    "    elif maxPlace == 1:\n",
    "        winPlacePerc = 1.0\n",
    "    else:\n",
    "        gap = 1.0 / (maxPlace - 1)\n",
    "        winPlacePerc = round(winPlacePerc / gap) * gap\n",
    "    \n",
    "    if winPlacePerc < 0: winPlacePerc = 0.0\n",
    "    if winPlacePerc > 1: winPlacePerc = 1.0    \n",
    "    pred[i] = winPlacePerc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "b0faac02c6cb92da18f259eb0cd1c7d6e8aa4b71",
    "colab": {},
    "colab_type": "code",
    "id": "rHWD8gmRgeke"
   },
   "outputs": [],
   "source": [
    "df_test['winPlacePerc'] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4521bf9f21fdd4d39252b3819eecd68aee015b0f"
   },
   "source": [
    "## Create the submission file : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "19a0da0d4d51894dc0d02dbbcd0b24a8e715439a",
    "colab": {},
    "colab_type": "code",
    "id": "pi1Mml_Rge8K"
   },
   "outputs": [],
   "source": [
    "submission = df_test[['Id', 'winPlacePerc']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be5818c11657c84475a79b9cad1861aea1e4b575"
   },
   "source": [
    " Finally, I hope you understand every line of this kernel, also if you have any note don't hesitate to put it in a comment ."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tryAKernal.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}