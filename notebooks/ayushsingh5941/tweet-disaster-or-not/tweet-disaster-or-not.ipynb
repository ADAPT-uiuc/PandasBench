{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scale_input_data(scale_factor):\n",
    "  file_bases = ['./input/train', './input/test']\n",
    "  for file_base in file_bases:\n",
    "    import pandas as pd\n",
    "    import shutil\n",
    "    if scale_factor == 1.0:\n",
    "      shutil.copyfile(file_base + '.csv', file_base + '.scaled.csv')\n",
    "      continue\n",
    "    df_to_scale = pd.read_csv(file_base + '.csv')\n",
    "    new_num_rows = int(scale_factor * len(df_to_scale))\n",
    "    if scale_factor <= 1.0:\n",
    "      df_to_scale = df_to_scale.iloc[:new_num_rows]\n",
    "    else:\n",
    "      while len(df_to_scale) < new_num_rows:\n",
    "        df_to_scale = pd.concat([df_to_scale, df_to_scale[:min(new_num_rows - len(df_to_scale), len(df_to_scale))]])\n",
    "    df_to_scale.to_csv(file_base + '.scaled.csv', index=False)\n",
    "\n",
    "if 'INPUT_SCALE_FACTOR' in os.environ:\n",
    "  scale_input_data(float(os.environ['INPUT_SCALE_FACTOR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "exec(os.environ['IREWR_IMPORTS'])\n",
    "import numpy as np\n",
    "import re\n",
    "# ALEX: remove ML code\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# from nltk.corpus import names, stopwords\n",
    "import unicodedata\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import classification_report\n",
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "id             int64\n",
       "keyword       object\n",
       "location      object\n",
       "text          object\n",
       "target         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train_df = pd.read_csv('./input/train.scaled.csv')\n",
    "tweet_test_df = pd.read_csv('./input/test.scaled.csv')\n",
    "Id = tweet_test_df['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Familiarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id keyword location  \\\n",
       "0           0   1     NaN      NaN   \n",
       "1           1   4     NaN      NaN   \n",
       "2           2   5     NaN      NaN   \n",
       "3           3   6     NaN      NaN   \n",
       "4           4   7     NaN      NaN   \n",
       "\n",
       "                                                text  target  \n",
       "0  Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1             Forest fire near La Ronge Sask. Canada       1  \n",
       "2  All residents asked to 'shelter in place' are ...       1  \n",
       "3  13,000 people receive #wildfires evacuation or...       1  \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword and location  contains lots of Missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0\n",
       "id              0\n",
       "keyword        31\n",
       "location      748\n",
       "text            0\n",
       "target          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2283 entries, 0 to 2282\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  2283 non-null   int64 \n",
      " 1   id          2283 non-null   int64 \n",
      " 2   keyword     2252 non-null   object\n",
      " 3   location    1535 non-null   object\n",
      " 4   text        2283 non-null   object\n",
      " 5   target      2283 non-null   int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 107.1+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2283, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7613 rows of tweets with 4 columns id, keyword, location and text all object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_imputation(data):\n",
    "    data['keyword'].fillna(' ', inplace=True)\n",
    "    data['location'].fillna(' ', inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train_df = data_imputation(tweet_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_test_df = data_imputation(tweet_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "id            0\n",
       "keyword       0\n",
       "location      0\n",
       "text          0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train_df['text'] = tweet_train_df['text'] +' '+ tweet_train_df['location'] +' '+ tweet_train_df['keyword']\n",
    "tweet_test_df['text'] = tweet_test_df['text'] +' '+ tweet_test_df['location'] +' '+ tweet_test_df['keyword']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the missing columns are filled with appropriate values, later maybe we will change value of keyword dynamically for each row accordingly for now it's Na.\n",
    "Missing locations are set to Unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Filtering\n",
    "Filtering Keyword, location and text columns by removing numbers, hashtags, names, Url and mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tweet_train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train_df.drop(['target', 'location', 'keyword', 'id'], axis=1, inplace=True)\n",
    "tweet_test_df.drop(['location', 'keyword', 'id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# all_names = set(names.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# tf_idf = TfidfVectorizer(min_df=0.1, max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_string(string):\n",
    "    # Removing all the digits\n",
    "    string = re.sub(r'\\d', '', string)\n",
    "    \n",
    "    # Removing accented data\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Removing Mentions\n",
    "    string = re.sub(r'@\\w+', ' ', string)\n",
    "    \n",
    "    # Removing links \n",
    "    string = re.sub(r'(https?:\\/\\/)?([\\da-zA-Z\\.-\\/\\#\\:]+)\\.([\\da-zA-Z\\.\\/\\:\\#]{0,9})([\\/\\w \\.-\\/\\:\\#]*)', ' ', string)\n",
    "    \n",
    "    # Removing all the digits special caharacters\n",
    "    string = re.sub(r'\\W', ' ', string)\n",
    "        \n",
    "    \n",
    "    # Removing double whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string, flags=re.I)\n",
    "    \n",
    "\n",
    "    \n",
    "    string = string.strip()\n",
    "    \n",
    "    #Removing all Single characters\n",
    "    string = re.sub(r'\\^[a-zA-Z]\\s+','' , string)\n",
    "    \n",
    "    \n",
    "    # Lemmetizing the string and removing stop words\n",
    "    string = string.split()\n",
    "# ALEX: remove ML code\n",
    "#     string = [lemmetizer.lemmatize(word) for word in string if word not in stop_words and word not in all_names]\n",
    "    string = ' '.join(string)\n",
    "    \n",
    "    # Lowercasing all data\n",
    "    string = string.lower()\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            data.iloc[i, j] = cleaned_string(data.iloc[i, j])\n",
    "    return data\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "text          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_cleaned_test_df = clean_text(tweet_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_cleaned_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond geese are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apocalypse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typhoon soudelor kills in china and taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 just happened a terrible car crash\n",
       "1  heard about earthquake is different cities sta...\n",
       "2  there is a forest fire at spot pond geese are ...\n",
       "3                                         apocalypse\n",
       "4         typhoon soudelor kills in china and taiwan"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_cleaned_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_cleaned_train_df = clean_text(tweet_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la ronge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  our deeds are the reason of this earthquake ma...\n",
       "1                          forest fire near la ronge\n",
       "2  all residents asked to shelter in place are be...\n",
       "3  people receive wildfires evacuation orders in ...\n",
       "4  just got sent this photo from ruby alaska as s..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_cleaned_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(tweet_cleaned_train_df['text'], target,random_state = 0)\n",
    "_ = tweet_cleaned_train_df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# catboost = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# pipeline_sgd = Pipeline([\n",
    "#     ('tfidf',  TfidfVectorizer()),\n",
    "#     ('nb', catboost,)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# model = pipeline_sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# y_predict = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# print(classification_report(y_valid, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALEX: remove ML code\n",
    "# y_pred_test = model.predict(tweet_cleaned_test_df['text'])\n",
    "y_pred_test = tweet_cleaned_test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving result on test set\n",
    "# ALEX: remove ML code\n",
    "output = pd.DataFrame({'Id': Id,\n",
    "                       'target': y_pred_test})\n",
    "\n",
    "output.to_csv(r'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}