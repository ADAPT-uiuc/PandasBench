{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def scale_input_data(scale_factor):\n",
    "  file_bases = ['./input/users', './input/tweets']\n",
    "  for file_base in file_bases:\n",
    "    import pandas as pd\n",
    "    import shutil\n",
    "    if scale_factor == 1.0:\n",
    "      shutil.copyfile(file_base + '.csv', file_base + '.scaled.csv')\n",
    "      continue\n",
    "    df_to_scale = pd.read_csv(file_base + '.csv')\n",
    "    new_num_rows = int(scale_factor * len(df_to_scale))\n",
    "    if scale_factor <= 1.0:\n",
    "      df_to_scale = df_to_scale.iloc[:new_num_rows]\n",
    "    else:\n",
    "      while len(df_to_scale) < new_num_rows:\n",
    "        df_to_scale = pd.concat([df_to_scale, df_to_scale[:min(new_num_rows - len(df_to_scale), len(df_to_scale))]])\n",
    "    df_to_scale.to_csv(file_base + '.scaled.csv', index=False)\n",
    "\n",
    "if 'INPUT_SCALE_FACTOR' in os.environ:\n",
    "  scale_input_data(float(os.environ['INPUT_SCALE_FACTOR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c2fe35de-fdb7-4297-a3fc-f31950ab8cf5",
    "_uuid": "b827fa543466affd20715310d6a699d93a8112ba"
   },
   "source": [
    "# Russian Tweet Network and Time Series Visualization\n",
    "\n",
    "The goal of this notebook is to clean the messy data -- filled to the brim with natural language -- and analyze it via time series analysis. Since a lot of this data is based in a contemporary political context, it's important to note how the data aligns with certain political events during the period in question. No machine learning classification will be done in this project for now: it's purely a visual exploration of the data to understand it.\n",
    "\n",
    "I would love to know any tips and tricks people have for working with time series data in python!\n",
    "\n",
    "TODO:\n",
    "3. Annotate TS plots with important political dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b92531de-e7f4-4a15-bbae-724c0b7e411b",
    "_uuid": "111ddf1ba432bd20b16563aa827fc09a71eb4bf4"
   },
   "outputs": [],
   "source": [
    "import numpy as np #linear algebra\n",
    "# import pandas as pd #data processing\n",
    "exec(os.environ['IREWR_IMPORTS'])\n",
    "\n",
    "# ALEX: remove plotting\n",
    "# import seaborn as sns #visualization\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt #visualization\n",
    "# %matplotlib inline\n",
    "# plt.style.use('bmh')\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c5925d05-c544-46d4-9a90-afa5ce60127f",
    "_uuid": "079cd56dcd60b66d55c129c080e3bad5c9ddb953"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>verified</th>\n",
       "      <th>lang</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>description</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18710816.0</td>\n",
       "      <td>near Utah Ave &amp; Lighthouse an</td>\n",
       "      <td>Robby Delaware</td>\n",
       "      <td>304.0</td>\n",
       "      <td>11484.0</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>RobbyDelaware</td>\n",
       "      <td>I support the free movement of people, ideas a...</td>\n",
       "      <td>Wed Jan 07 04:38:02 +0000 2009</td>\n",
       "      <td>17.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100345056.0</td>\n",
       "      <td>still \u2b06\ufe0fBlock\u2935\ufe0fCorner\u2b07\ufe0fstreet</td>\n",
       "      <td>#Ezekiel2517\u2728...</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>31858.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>SCOTTGOHARD</td>\n",
       "      <td>CELEBRITY TRAINER \u2728#424W147th\u2728 #CrossfitCoach ...</td>\n",
       "      <td>Tue Dec 29 23:15:22 +0000 2009</td>\n",
       "      <td>2774.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>247165706.0</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>B E C K S T E R\u2728</td>\n",
       "      <td>650.0</td>\n",
       "      <td>6742.0</td>\n",
       "      <td>Mountain Time (US &amp; Canada)</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>Beckster319</td>\n",
       "      <td>Rebecca Lynn Hirschfeld Actress.Model.Writer.A...</td>\n",
       "      <td>Fri Feb 04 06:38:45 +0000 2011</td>\n",
       "      <td>7273.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249538861.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chris Osborne</td>\n",
       "      <td>44.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>skatewake1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wed Feb 09 07:38:44 +0000 2011</td>\n",
       "      <td>227.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>449689677.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\u0420\u0430\u043c\u0437\u0430\u043d \u041a\u0430\u0434\u044b\u0440\u043e\u0432</td>\n",
       "      <td>94773.0</td>\n",
       "      <td>10877.0</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>False</td>\n",
       "      <td>ru</td>\n",
       "      <td>KadirovRussia</td>\n",
       "      <td>\u041f\u0430\u0440\u043e\u0434\u0438\u0439\u043d\u044b\u0439 \u0430\u043a\u043a\u0430\u0443\u043d\u0442. \u041e\u0437\u0432\u0443\u0447\u0438\u0432\u0430\u044e \u0442\u043e, \u0447\u0442\u043e \u043f\u043e\u043b\u0438\u0442\u0438\u043a\u0430...</td>\n",
       "      <td>Thu Dec 29 11:31:09 +0000 2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>691.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                       location              name  \\\n",
       "0   18710816.0  near Utah Ave & Lighthouse an    Robby Delaware   \n",
       "1  100345056.0  still \u2b06\ufe0fBlock\u2935\ufe0fCorner\u2b07\ufe0fstreet  #Ezekiel2517\u2728...   \n",
       "2  247165706.0                    Chicago, IL  B E C K S T E R\u2728   \n",
       "3  249538861.0                            NaN     Chris Osborne   \n",
       "4  449689677.0                            NaN    \u0420\u0430\u043c\u0437\u0430\u043d \u041a\u0430\u0434\u044b\u0440\u043e\u0432   \n",
       "\n",
       "   followers_count  statuses_count                    time_zone verified lang  \\\n",
       "0            304.0         11484.0   Pacific Time (US & Canada)    False   en   \n",
       "1           1053.0         31858.0                          NaN    False   en   \n",
       "2            650.0          6742.0  Mountain Time (US & Canada)    False   en   \n",
       "3             44.0           843.0                          NaN    False   en   \n",
       "4          94773.0         10877.0                       Moscow    False   ru   \n",
       "\n",
       "     screen_name                                        description  \\\n",
       "0  RobbyDelaware  I support the free movement of people, ideas a...   \n",
       "1    SCOTTGOHARD  CELEBRITY TRAINER \u2728#424W147th\u2728 #CrossfitCoach ...   \n",
       "2    Beckster319  Rebecca Lynn Hirschfeld Actress.Model.Writer.A...   \n",
       "3  skatewake1994                                                NaN   \n",
       "4  KadirovRussia  \u041f\u0430\u0440\u043e\u0434\u0438\u0439\u043d\u044b\u0439 \u0430\u043a\u043a\u0430\u0443\u043d\u0442. \u041e\u0437\u0432\u0443\u0447\u0438\u0432\u0430\u044e \u0442\u043e, \u0447\u0442\u043e \u043f\u043e\u043b\u0438\u0442\u0438\u043a\u0430...   \n",
       "\n",
       "                       created_at  favourites_count  friends_count  \\\n",
       "0  Wed Jan 07 04:38:02 +0000 2009              17.0          670.0   \n",
       "1  Tue Dec 29 23:15:22 +0000 2009            2774.0         1055.0   \n",
       "2  Fri Feb 04 06:38:45 +0000 2011            7273.0          896.0   \n",
       "3  Wed Feb 09 07:38:44 +0000 2011             227.0          154.0   \n",
       "4  Thu Dec 29 11:31:09 +0000 2011               0.0            7.0   \n",
       "\n",
       "   listed_count  \n",
       "0          13.0  \n",
       "1          35.0  \n",
       "2          30.0  \n",
       "3           1.0  \n",
       "4         691.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('./input/users.scaled.csv')\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59e34bc1-3a67-489d-a882-deb722cc596f",
    "_uuid": "40f4b74286bf2319fad14a3e53cd18c77a25579a"
   },
   "source": [
    "## Time Series Visualizations\n",
    "This first section looks at a number of metrics and places them in a time series visualization. The first set is merely a distribution of the number of statuses by certain users, and a distribution of the number of followers. Both plots are based on the users set. Following this, I format the date the twitter user was created and then show two bar plots for users created by year and by month. Finally, I show this same information in a single time series plot using the matplotlib.pyplot.plot function -- this is because the seaborn.tsplot function doesn't work very easily and requires a lot of tinkering to get it working properly. I gave up and chose to just go the easier route. I might change it to a seaborn.pointplot later on.\n",
    "\n",
    "The second section follows a similar process, but for the tweets dataset. I import the data, clean the date-time values, then extract the months and years and plot this in another time series chart using the matplotlib.pyplot.plot function. One important insight stands out immediately from these visualizations: the vast majority of users in this dataset created their accounts in 2013 or 2014, with a few trickling later on in 2015 and 2016, BUT the vast majority of tweets came during 2016, particularly during the fall. This timeline coincides with the post-convention general election campaigns along with a number of political events like the Wikileaks dump of DNC emails. Even following Election Day in November of 2016, a number of tweets still came in during the transition period and shortly thereafter. \n",
    "\n",
    "A couple of notes on the code:\n",
    "1. In the first section I queried the user data by those users with non-nan values, as the seaborn.distplot did not automatically clean these out and constantly returned an error: useful to note for later analysis. \n",
    "2. I used df.assign to create my new dataframe columns when working the date-time metrics. This was an easy and logically straightforward method of creating new values that didn't return errors such as the dreaded \"cannot be indexed on a slice\" error that Pandas will throw often. In addition, for the date-time data it was necessary to change the index of the dataframe to the date-time data. This made it easy to group the data by months and years. This is of course rather different from another method, which would have been to merely create two new columns -- one for months and one for years. However, I found that this made it more difficult to create a time series representation of the data; when I grouped the data by these two columns, as I originally tried, it created two indices, which constantly returned errors when attempting to plot it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ff50aefc-b927-4294-82fa-30fe39db4bc2",
    "_uuid": "ad4ed17cdb84b3ab863c423c0d1385a770198c0f"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove plotting\n",
    "# f, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "# sns.distplot(users[np.isfinite(users.statuses_count)].statuses_count, ax=ax[0])\n",
    "# sns.distplot(users[np.isfinite(users.followers_count)].followers_count, ax=ax[1])\n",
    "# plt.show()\n",
    "_ = users[np.isfinite(users.statuses_count)].statuses_count\n",
    "_ = users[np.isfinite(users.followers_count)].followers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "2c520829-d8e8-4780-93d9-56db6bfa6e14",
    "_uuid": "d52f4e3274bbbbc51d4bdd8729c930b8eaf65192"
   },
   "outputs": [],
   "source": [
    "form = '%a %b %d %H:%M:%S %z %Y'\n",
    "users = users.assign(date = users.created_at.map(\n",
    "    lambda x: datetime.strptime(str(x), form).date() if x is not np.nan else None))\n",
    "users = users.set_index(pd.DatetimeIndex(users.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "680501bb-1da4-4da7-82a2-1d58ecc06171",
    "_uuid": "ea7d5e98d68e353d5c96c3ed6a923164bc2c9c58"
   },
   "outputs": [],
   "source": [
    "monthseries = users.groupby(by=[users.index.month]).count()\n",
    "YearSeries = users.groupby([users.index.year]).count()\n",
    "# ALEX: remove plotting\n",
    "# f, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "# sns.barplot(monthseries.index, monthseries.id, ax=ax[0])\n",
    "# sns.barplot(YearSeries.index, YearSeries.id, ax=ax[1])\n",
    "# plt.show()\n",
    "_ = monthseries.index\n",
    "_ = monthseries.id\n",
    "_ = YearSeries.index\n",
    "_ = YearSeries.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "c8ee0962-a733-4f41-bec9-d0b21752e721",
    "_uuid": "ab3108f570efd4e9720ee7340be8777388301a58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    date\n",
       "2009.0  1.0      1\n",
       "        5.0      1\n",
       "        11.0     1\n",
       "        12.0     1\n",
       "2011.0  2.0      2\n",
       "        12.0     1\n",
       "2012.0  1.0      1\n",
       "        3.0      1\n",
       "        12.0     1\n",
       "2013.0  6.0     11\n",
       "        7.0     13\n",
       "        8.0     94\n",
       "        9.0     16\n",
       "        12.0     1\n",
       "2014.0  2.0      1\n",
       "        3.0      9\n",
       "        4.0     12\n",
       "        5.0     64\n",
       "        6.0     49\n",
       "        7.0      4\n",
       "        8.0      7\n",
       "        9.0      1\n",
       "        10.0     4\n",
       "        12.0     6\n",
       "2015.0  1.0      1\n",
       "        3.0     15\n",
       "        6.0      1\n",
       "        8.0      1\n",
       "        9.0      3\n",
       "        10.0     8\n",
       "        11.0    13\n",
       "        12.0     1\n",
       "2016.0  1.0      2\n",
       "        2.0      4\n",
       "        3.0      1\n",
       "        4.0      6\n",
       "        5.0      3\n",
       "        6.0      2\n",
       "        7.0     18\n",
       "        8.0      2\n",
       "        10.0     1\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TimeSeries = users.groupby([users.index.year, users.index.month]).count()\n",
    "# ALEX: remove plotting\n",
    "# plt.figure(figsize=(12,6))\n",
    "# TimeSeries.id.plot()\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylabel('Number of New Users')\n",
    "# plt.xlabel('Year, Month')\n",
    "# plt.show()\n",
    "TimeSeries.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "cbf74438-9308-4b07-adef-deabd6d73a47",
    "_uuid": "d910789a210c6427e552ffd73045332dbae3d8ad"
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('./input/tweets.scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "05d1e99b-4a8b-4cc1-8f9c-595c67504a31",
    "_uuid": "a494f99fe81560e1739cdf7e1b6f7c8ea7918b85"
   },
   "outputs": [],
   "source": [
    "form = '%Y-%m-%d %H:%M:%S'\n",
    "tweets = tweets.assign(date = tweets.created_str.map(\n",
    "    lambda x: datetime.strptime(str(x), form).date() if x is not np.nan else None))\n",
    "tweets = tweets.set_index(pd.DatetimeIndex(tweets.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "a065c00d-a6b9-4cbf-ac8b-f42b4475ad7b",
    "_uuid": "c5ebac95155144050c1592d40844870d64e4f944"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date    date\n",
       "2014.0  7.0        12\n",
       "        8.0         1\n",
       "        9.0         1\n",
       "        11.0      388\n",
       "        12.0      342\n",
       "2015.0  1.0      1423\n",
       "        2.0      1169\n",
       "        3.0      1840\n",
       "        4.0      1681\n",
       "        5.0      1449\n",
       "        6.0      1720\n",
       "        7.0      1301\n",
       "        8.0       874\n",
       "        9.0       292\n",
       "        10.0      980\n",
       "        11.0      788\n",
       "        12.0     3154\n",
       "2016.0  1.0      1407\n",
       "        2.0      5073\n",
       "        3.0      3779\n",
       "        4.0       443\n",
       "        5.0      1919\n",
       "        6.0      1043\n",
       "        7.0      7163\n",
       "        8.0     11599\n",
       "        9.0     25647\n",
       "        10.0    27983\n",
       "        11.0    21805\n",
       "        12.0    19963\n",
       "2017.0  1.0     21060\n",
       "        2.0     10149\n",
       "        3.0      8022\n",
       "        4.0      4591\n",
       "        5.0       637\n",
       "        6.0       474\n",
       "        7.0      3863\n",
       "        8.0      1345\n",
       "        9.0        16\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries = tweets.groupby([tweets.index.year, tweets.index.month]).count()\n",
    "# ALEX: remove plotting\n",
    "# plt.figure(figsize=(12,6))\n",
    "# timeseries.user_id.plot()\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.ylabel('Number of New Tweets')\n",
    "# plt.xlabel('Year, Month')\n",
    "# plt.show()\n",
    "timeseries.user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a45136cf-8d49-49b6-8c4a-55b08ad971a5",
    "_uuid": "6a651b091045df8dfa5088b92c775aefc5919994"
   },
   "source": [
    "## Textual Analysis, Cleaning, and Twitter Handle Networks\n",
    "This second section in the project was new ground for me. Textual analysis is something I haven't spent much time working with, and this dataset represented a good first start to it. Thankfully, I learned that Pandas has functions dedicated to dealing with text in a REGEX format. As the source code shows, I first made sure to copy the next I wanted to work with before doing anything to it. Then, I extracted twitter handles of tweets that were merely retweets from other people, and by extracting these handles I could determine who the most retweeted accounts were. Following this clean, I replaced a number of string formats with empty strings to make it easier to show in a word cloud the most important words. Https website links were removed, along with the twitter handles, RT, amp, and co. Without removing these they showed up in a large format in the word cloud.\n",
    "\n",
    "The word cloud itself is something also new to me. I followed some code found elsewhere online, created one long string of text from the previously cleaned set of text data, then plotted the word cloud image without axes. Clearly, Donald Trump, Trump, Obama, Hillary Clinton, and Hillary are the most used words in the dataset -- which follows since these were mostly politically motivated tweets. \n",
    "\n",
    "After creating the word cloud, I analyzed the retweeted users. I checked to see if any of these retweets were from other members of the dataset. Originally, I found that there weren't any: however, I realized I was conducting the analysis incorrectly. My retweets extracted included the @ symbol and the colon (:) symbol. I removed the colon symbol in order to get rid of anything that might still be in the string after it and leave just the @user_name string. After this, I got a single value of each name in the list of user_keys from the tweets dataset and the retweets already collected. I did this by doing a count of each unique username using df.value_counts() then getting the index of that dataframe (the df.value_counts().values returns the counted numbers rather than the names, a mistake I originally made). In order to make sure names lined up, I added a @ symbol to the beginning of each user_key obtained from the original dataset. From this, I obtained a list of user_names that were simultaneously PART of the dataset, and retweeted BY the dataset: this creates a networking cascade effect, which I then attempted to quantify.\n",
    "\n",
    "After extracting the user names from both sets, I was able to quantify it after a lot of trial and error: pandas.Index has an intersection function of a second set of values, such as index1.intersection(values) that allowed me to get a series of usernames along with the number of tweets contained in the dataset!\n",
    "\n",
    "Couple of things stand out: first off, the total number of retweets is ~37000, and the total number of retweets from users in the dataset is ~35000, so nearly all of the retweets are from users within the dataset. Second, that number is roughly 18% of the total malicious tweets dataset, so if there was a cascade effect it likely wasn't very large compared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "f0bbc434-6c14-4494-b265-e7a99015c605",
    "_uuid": "c56933d6267f5ee2ba7ccb866fa4066925ba5285"
   },
   "outputs": [],
   "source": [
    "tags = tweets.text.copy()\n",
    "\n",
    "# This code extracts where the retweet is from, as it follows a \"RT @XXXXX:\" format\n",
    "retweets = tags.str.extract('(@.*:)', expand=True)\n",
    "\n",
    "# Gets rid of website links\n",
    "tags = tags.replace('https.*$','',regex=True)\n",
    "# Gets rid of twitter handles\n",
    "tags = tags.replace('@.*:','',regex=True)\n",
    "# Gets rid of RT\n",
    "tags = tags.replace('RT|amp|co','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "a8477994-27a8-4a05-8402-ce88cbeb396d",
    "_uuid": "81533e42dfbdb3939b8a1942234f34810f8a8cf7"
   },
   "outputs": [],
   "source": [
    "# ALEX: remove plotting\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "text = ' '.join([str(x) for x in tags.values])\n",
    "\n",
    "# ALEX: remove plotting\n",
    "# wc = WordCloud(stopwords=STOPWORDS,background_color='white',max_words=200,scale=3).generate(text)\n",
    "# plt.figure(figsize=(15,15))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(wc)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "d078c245-b342-423e-8303-d41e5ed4d401",
    "_uuid": "551baf0b22d3e09e88181976946753eba47096a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    37807.000000\n",
      "mean         3.950485\n",
      "std         19.409811\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          2.000000\n",
      "max       2207.000000\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "retweets = retweets.replace(':.*','',regex=True)\n",
    "print(retweets[0].value_counts().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "f6a57638-3221-43ec-adfa-44202afa95ca",
    "_uuid": "bba8737d50d44cec2a8ac46a86705535b6936ba4"
   },
   "outputs": [],
   "source": [
    "user_retweeted = retweets[0].value_counts().index[~pd.isnull(retweets[0].value_counts().index)]\n",
    "retweeted_user = ['@'+x for x in tweets.user_key.value_counts().index]\n",
    "\n",
    "cascade = [x for x in retweeted_user if x in user_retweeted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "1b2e2ca9-e77d-46d8-9443-11f5faa25305",
    "_uuid": "dc18fb6f5a5cb681724b99c63a9a2742ac4bf8e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hyddrox            6813\n",
       "mrclydepratt       3263\n",
       "brianaregland      3261\n",
       "melanymelanin      3212\n",
       "mr_clampin         3010\n",
       "traceyhappymom     2990\n",
       "queenofthewo       2988\n",
       "heyits_toby        2909\n",
       "tpartynews         1892\n",
       "hollandpatrickk    1765\n",
       "cassishere          741\n",
       "wadeharriot         732\n",
       "happkendrahappy     451\n",
       "gloed_up            327\n",
       "rightnpr            267\n",
       "patriototus         165\n",
       "camosaseko          145\n",
       "holycrapchrix        92\n",
       "brightandglory       76\n",
       "blackmattersus       67\n",
       "lagonehoe            65\n",
       "dannythehappies      56\n",
       "cascaseyp            52\n",
       "hipppo_              52\n",
       "toneporter           44\n",
       "4mysquad             43\n",
       "maymaymyy            42\n",
       "heyheyhailey         42\n",
       "claudia42kern        39\n",
       "aantiracist          37\n",
       "erdollum             20\n",
       "abigailssilk         17\n",
       "nj_blacknews         17\n",
       "riogithief           10\n",
       "dontshootcom         10\n",
       "instotus              3\n",
       "jrrbrtt               2\n",
       "ssus_panther          1\n",
       "gwen_garland          1\n",
       "iris0_o               1\n",
       "handsome_henson       1\n",
       "wildharee             1\n",
       "portmela              1\n",
       "Name: user_key, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# easy method to remove the @ symbol again and make a clean user_key set\n",
    "cascade = pd.Series(cascade).replace('@','',regex=True)\n",
    "network = tweets.user_key.value_counts()\n",
    "# wish I knew of this previously, kept trying to join two pd.Series which pandas isn't a fan of\n",
    "network = network[network.index.intersection(cascade.values)]\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "aa5a9b55-af00-4e1d-b8af-b44d3cc5d69c",
    "_uuid": "22fe14ab3bf688dd75ed2735b6e7732c90e8a043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of retweets from users contained within the dataset: 35723\n",
      "Percentage of total dataset: 0.17555852606127323\n"
     ]
    }
   ],
   "source": [
    "print('Total number of retweets from users contained within the dataset: {}'.format(network.values.sum()))\n",
    "print('Percentage of total dataset: {}'.format(network.values.sum()/len(tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "41b94b01-aa7f-4eda-b4a5-3128e1bbf835",
    "_uuid": "316115b145632840baa36d9002b64b4e15fe6fb4"
   },
   "source": [
    "If you liked this notebook or can think of other things I might try and do with it let me know! I will likely come back to this if I come up with some other kind of ideas for it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}