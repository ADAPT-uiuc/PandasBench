{
  "max-mem-in-mb": 128,
  "max-mem-in-mb2": 131,
  "cells": [
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# %matplotlib inline\nimport numpy as np\n# import pandas as pd\nexec(os.environ['IREWR_IMPORTS'])\nimport re as re\n\ntrain = pd.read_csv('./input/train.scaled.csv', header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv('./input/test.scaled.csv' , header = 0, dtype={'Age': np.float64})\nfull_data = [train, test]\n\nprint (train.info())",
      "rewrite-ns": 3108784,
      "overhead-ns": 3108784,
      "exec-ns": 36088252,
      "total-ns": 39197036,
      "patts-hit": {},
      "rewritten": "import numpy as np\nexec(os.environ['IREWR_IMPORTS'])\nimport re as re\ntrain = pd.read_csv('./input/train.scaled.csv', header=0, dtype={'Age': np.\n    float64})\ntest = pd.read_csv('./input/test.scaled.csv', header=0, dtype={'Age': np.\n    float64})\nfull_data = [train, test]\nprint(train.info())\n"
    },
    {
      "raw": "print(len(train))",
      "rewrite-ns": 496177,
      "overhead-ns": 496177,
      "exec-ns": 362893,
      "total-ns": 859070,
      "patts-hit": {},
      "rewritten": "print(len(train))\n"
    },
    {
      "raw": "print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())",
      "rewrite-ns": 1098178,
      "overhead-ns": 1098178,
      "exec-ns": 6083713,
      "total-ns": 7181891,
      "patts-hit": {},
      "rewritten": "print(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n"
    },
    {
      "raw": "print (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())",
      "rewrite-ns": 1124318,
      "overhead-ns": 1124318,
      "exec-ns": 5693764,
      "total-ns": 6818082,
      "patts-hit": {},
      "rewritten": "print(train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())\n"
    },
    {
      "raw": "for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())",
      "rewrite-ns": 2182120,
      "overhead-ns": 2182120,
      "exec-ns": 6724925,
      "total-ns": 8907045,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nprint(train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=\n    False).mean())\n"
    },
    {
      "raw": "for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\nprint (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())",
      "rewrite-ns": 2394992,
      "overhead-ns": 2394992,
      "exec-ns": 7748454,
      "total-ns": 10143446,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\nprint(train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).\n    mean())\n"
    },
    {
      "raw": "for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())",
      "rewrite-ns": 1457472,
      "overhead-ns": 1457472,
      "exec-ns": 8269226,
      "total-ns": 9726698,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\nprint(train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False)\n    .mean())\n"
    },
    {
      "raw": "for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())",
      "rewrite-ns": 2150796,
      "overhead-ns": 2150796,
      "exec-ns": 10483241,
      "total-ns": 12634037,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint(train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'],\n    as_index=False).mean())\n"
    },
    {
      "raw": "for dataset in full_data:\n    age_avg \t   = dataset['Age'].mean()\n    age_std \t   = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n\nprint (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())",
      "rewrite-ns": 5734712,
      "overhead-ns": 5734712,
      "exec-ns": 11509871,
      "total-ns": 17244583,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg +\n        age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\nprint(train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'],\n    as_index=False).mean())\n"
    },
    {
      "raw": "for dataset in full_data:\n    dataset['Title'] = [x[1].split(\".\")[0].strip(\" \") for x in dataset['Name'].str.split(\",\")]\n\nprint(pd.crosstab(train['Title'], train['Sex']))",
      "rewrite-ns": 2585617,
      "overhead-ns": 2585617,
      "exec-ns": 29736390,
      "total-ns": 32322007,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    dataset['Title'] = [x[1].split('.')[0].strip(' ') for x in dataset[\n        'Name'].str.split(',')]\nprint(pd.crosstab(train['Title'], train['Sex']))\n"
    },
    {
      "raw": "for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nprint (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())",
      "rewrite-ns": 1713369,
      "overhead-ns": 1713369,
      "exec-ns": 16696452,
      "total-ns": 18409821,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt',\n        'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\nprint(train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n"
    },
    {
      "raw": "train_size = len(train)\ntest_size = len(test)\n\n# FIRST-AUTHOR: make notebook run\n# all_df = train.append(test)\nall_df = pd.concat([train, test])\nall_df = all_df[list(train.columns)]\n\nall_df.set_index(['PassengerId'], inplace=True) ## This is to make sure of a unique index for both train & test\n\n## Processing family information\nall_df['Last name'] = all_df['Name'].apply(lambda x: str.split(x, \",\")[0])\nall_df['Fare'].fillna(all_df['Fare'].mean(), inplace=True)\n\n# The Fare is actually for the whole family\nfare_df = all_df.loc[all_df['FamilySize']>1, [\"Last name\", \"Fare\", \"FamilySize\"]].iloc[:train_size]\nfare_diff = (((fare_df.groupby(['Last name', 'FamilySize']).max() \n - fare_df.groupby(['Last name', 'FamilySize']).min())!=0).sum()/train_size * 100)\nprint((\"Percentage of families with different fares is: %.1f\" %(fare_diff.values[0])) + '%')\n# The data shows only 1.7% has a different fare value between family memebers. It's some type of anomaly\n# Will use last name and fare to group passengers into families\n# First would like to show there is value in doing this\ntrain_temp_df = all_df.iloc[:train_size]\nfamily_df_grpby = train_temp_df[train_temp_df['FamilySize']>1][\n    ['Last name', 'Fare', 'FamilySize', 'Survived']].groupby(['Last name', 'Fare'])\nfamily_df = pd.DataFrame(data=family_df_grpby.size(), columns=['Size in train'])\nfamily_df['Survived total'] = family_df_grpby['Survived'].sum().astype(int)\nfamily_df['FamilySize'] = family_df_grpby['FamilySize'].mean().astype(int)\n#family_df = family_df[family_df['FamilySize']==8]\nprint(\"Whole family survived: %.1f\" \n      %(100*len(family_df[family_df['Size in train']==family_df['Survived total'] ])/len(family_df))+'%') \nprint(\"Whole family perished: %.1f\" \n      %(100*len(family_df[family_df['Survived total'] == 0])/len(family_df))+'%') \n## Majority family either all perished or all survived, this means we can use this as one feature to \n## predict survival\n\n# Now let's do the feature extraction\n# Intialize all 'Family survival', meaning there is no information on if any family members survived. \n# This number can be tuned I guess but I will use it to start with.\ngrp_partial_age = 0\ngrp_partial_cabin = 0\ngrp_age_diff_df = pd.DataFrame()\nall_df['Family survival'] = 0.5\nfor grp, grp_df in all_df[['Survived','Name', 'Last name', 'Fare', \n                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last name', 'Fare']):\n    if (len(grp_df) != 1):\n        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n        is_partial_age = (grp_missing_age != 0) & (grp_missing_age != len(grp_df))\n        grp_partial_age += is_partial_age\n        \n        sibsp_df = grp_df.loc[grp_df['SibSp']!=0, ['Age']]\n        #print(sibsp_df.info())\n        sibsp_age_diff = sibsp_df.max() - sibsp_df.min()\n# FIRST-AUTHOR: make notebook run\n#         grp_age_diff_df = grp_age_diff_df.append(sibsp_age_diff, ignore_index=True)\n        grp_age_diff_df = pd.concat([grp_age_diff_df, sibsp_age_diff])\n\n        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin != len(grp_df))\n\n\n        for PassID, row in grp_df.iterrows():\n            ## Find out if any family memebers survived or not\n            smax = grp_df.drop(PassID)['Survived'].max()\n            smin = grp_df.drop(PassID)['Survived'].min()\n\n            ## If any family memebers survived, put this feature as 1\n            if (smax==1.0): all_df.loc[PassID, 'Family survival'] = 1\n            ## Otherwise if any family memebers perished, put this feature as 0\n            elif (smin==0.0): all_df.loc[PassID, 'Family survival'] = 0\n\nprint(\"Number of passenger with family survival information: \" \n      +str(all_df[all_df['Family survival']!=0.5].shape[0]))\n\nprint('partial age group: ' + str(grp_partial_age))\nprint('partial cabin group: ' + str(grp_partial_cabin))\nprint(grp_age_diff_df.describe())",
      "rewrite-ns": 27009187,
      "overhead-ns": 27009187,
      "exec-ns": 11138146562,
      "total-ns": 11165155749,
      "patts-hit": {},
      "rewritten": "train_size = len(train)\ntest_size = len(test)\nall_df = pd.concat([train, test])\nall_df = all_df[list(train.columns)]\nall_df.set_index(['PassengerId'], inplace=True)\nall_df['Last name'] = all_df['Name'].apply(lambda x: str.split(x, ',')[0])\nall_df['Fare'].fillna(all_df['Fare'].mean(), inplace=True)\nfare_df = all_df.loc[all_df['FamilySize'] > 1, ['Last name', 'Fare',\n    'FamilySize']].iloc[:train_size]\nfare_diff = (fare_df.groupby(['Last name', 'FamilySize']).max() - fare_df.\n    groupby(['Last name', 'FamilySize']).min() != 0).sum() / train_size * 100\nprint('Percentage of families with different fares is: %.1f' % fare_diff.\n    values[0] + '%')\ntrain_temp_df = all_df.iloc[:train_size]\nfamily_df_grpby = train_temp_df[train_temp_df['FamilySize'] > 1][[\n    'Last name', 'Fare', 'FamilySize', 'Survived']].groupby(['Last name',\n    'Fare'])\nfamily_df = pd.DataFrame(data=family_df_grpby.size(), columns=['Size in train']\n    )\nfamily_df['Survived total'] = family_df_grpby['Survived'].sum().astype(int)\nfamily_df['FamilySize'] = family_df_grpby['FamilySize'].mean().astype(int)\nprint('Whole family survived: %.1f' % (100 * len(family_df[family_df[\n    'Size in train'] == family_df['Survived total']]) / len(family_df)) + '%')\nprint('Whole family perished: %.1f' % (100 * len(family_df[family_df[\n    'Survived total'] == 0]) / len(family_df)) + '%')\ngrp_partial_age = 0\ngrp_partial_cabin = 0\ngrp_age_diff_df = pd.DataFrame()\nall_df['Family survival'] = 0.5\nfor grp, grp_df in all_df[['Survived', 'Name', 'Last name', 'Fare', 'SibSp',\n    'Parch', 'Age', 'Cabin']].groupby(['Last name', 'Fare']):\n    if len(grp_df) != 1:\n        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n        is_partial_age = (grp_missing_age != 0) & (grp_missing_age != len(\n            grp_df))\n        grp_partial_age += is_partial_age\n        sibsp_df = grp_df.loc[grp_df['SibSp'] != 0, ['Age']]\n        sibsp_age_diff = sibsp_df.max() - sibsp_df.min()\n        grp_age_diff_df = pd.concat([grp_age_diff_df, sibsp_age_diff])\n        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin !=\n            len(grp_df))\n        for PassID, row in grp_df.iterrows():\n            smax = grp_df.drop(PassID)['Survived'].max()\n            smin = grp_df.drop(PassID)['Survived'].min()\n            if smax == 1.0:\n                all_df.loc[PassID, 'Family survival'] = 1\n            elif smin == 0.0:\n                all_df.loc[PassID, 'Family survival'] = 0\nprint('Number of passenger with family survival information: ' + str(all_df\n    [all_df['Family survival'] != 0.5].shape[0]))\nprint('partial age group: ' + str(grp_partial_age))\nprint('partial cabin group: ' + str(grp_partial_cabin))\nprint(grp_age_diff_df.describe())\n"
    },
    {
      "raw": "# First find out how many such groups exists that are not families and what is the chance of \n# passengers within the same group survive or perish together\ntrain_temp_df = all_df.iloc[:train_size]\nticket_grpby = train_temp_df.groupby('Ticket')\nticket_df = pd.DataFrame(data=ticket_grpby.size(), columns=['Size in train'])\nticket_df['Survived total'] = ticket_grpby['Survived'].sum().astype(int)\nticket_df['Not family'] = ticket_grpby['Last name'].unique().apply(len)\n#ticket_df['Pclass'] = ticket_grpby['Pclass'].median()\nticket_df = ticket_df[(ticket_df['Size in train'] > 1) & (ticket_df['Not family']>1)]\nprint('Number of groups in training set that is not family: '+ str(len(ticket_df)))\n#print(\"Groups in Pclass 2/3: \" + str(len(ticket_df[ticket_df['Pclass']!=1])))\nprint((\"Whole group perished: %.1f\" %(100/len(ticket_df)*len(ticket_df[ticket_df['Survived total']==0]))) + '%')\nprint((\"Whole group survived: %.1f\" \n       %(100/len(ticket_df)*len(ticket_df[ticket_df['Survived total']==ticket_df['Size in train']]))) + '%')\n\n## Looking at the output, one can see ~76% of group members stay together. So let's extract this feature.\n## We will overload the 'Family survival' column instead of creating a seperate feature.\ngrp_partial_age = 0\ngrp_partial_cabin = 0\ngrp_age_diff_df = pd.DataFrame(columns=['Age diff'])\nticket_grpby = all_df.groupby('Ticket')\nfor _, grp_df in ticket_grpby:\n    if (len(grp_df) > 1):\n        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n        grp_partial_age += (grp_missing_age != 0) & (grp_missing_age != len(grp_df))\n\n# FIRST-AUTHOR: make notebook run\n#         grp_age_diff_df = grp_age_diff_df.append(pd.DataFrame(data=[grp_df['Age'].max() \n#                                                                     - grp_df['Age'].min()]\n#                                                               , columns=['Age diff']))\n        grp_age_diff_df = pd.concat([grp_age_diff_df, pd.DataFrame(data=[grp_df['Age'].max() \n                                                                    - grp_df['Age'].min()]\n                                                              , columns=['Age diff'])])\n\n\n        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin != len(grp_df))\n        for PassID, row in grp_df.iterrows():\n            if (row['Family survival']==0)|(row['Family survival']==0.5):\n                smax = grp_df.drop(PassID)['Survived'].max()\n                smin = grp_df.drop(PassID)['Survived'].min()\n                if (smax==1.0): all_df.loc[PassID, 'Family survival'] = 1\n                elif (smin==0.0): all_df.loc[PassID, 'Family survival'] = 0\nprint('partial age group: ' + str(grp_partial_age))\nprint('partial cabin group: ' + str(grp_partial_cabin))\nprint(\"Number of passenger with family/group survival information: \" \n      +str(all_df[all_df['Family survival']!=0.5].shape[0]))\ntrain['Family survival'] = (all_df.iloc[:train_size]['Family survival'].values).astype(float)\ntest['Family survival'] = (all_df.iloc[train_size:]['Family survival'].values).astype(float)\nprint(grp_age_diff_df.describe())",
      "rewrite-ns": 16322738,
      "overhead-ns": 16322738,
      "exec-ns": 9804611656,
      "total-ns": 9820934394,
      "patts-hit": {},
      "rewritten": "train_temp_df = all_df.iloc[:train_size]\nticket_grpby = train_temp_df.groupby('Ticket')\nticket_df = pd.DataFrame(data=ticket_grpby.size(), columns=['Size in train'])\nticket_df['Survived total'] = ticket_grpby['Survived'].sum().astype(int)\nticket_df['Not family'] = ticket_grpby['Last name'].unique().apply(len)\nticket_df = ticket_df[(ticket_df['Size in train'] > 1) & (ticket_df[\n    'Not family'] > 1)]\nprint('Number of groups in training set that is not family: ' + str(len(\n    ticket_df)))\nprint('Whole group perished: %.1f' % (100 / len(ticket_df) * len(ticket_df[\n    ticket_df['Survived total'] == 0])) + '%')\nprint('Whole group survived: %.1f' % (100 / len(ticket_df) * len(ticket_df[\n    ticket_df['Survived total'] == ticket_df['Size in train']])) + '%')\ngrp_partial_age = 0\ngrp_partial_cabin = 0\ngrp_age_diff_df = pd.DataFrame(columns=['Age diff'])\nticket_grpby = all_df.groupby('Ticket')\nfor _, grp_df in ticket_grpby:\n    if len(grp_df) > 1:\n        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n        grp_partial_age += (grp_missing_age != 0) & (grp_missing_age != len\n            (grp_df))\n        grp_age_diff_df = pd.concat([grp_age_diff_df, pd.DataFrame(data=[\n            grp_df['Age'].max() - grp_df['Age'].min()], columns=['Age diff'])])\n        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin !=\n            len(grp_df))\n        for PassID, row in grp_df.iterrows():\n            if (row['Family survival'] == 0) | (row['Family survival'] == 0.5):\n                smax = grp_df.drop(PassID)['Survived'].max()\n                smin = grp_df.drop(PassID)['Survived'].min()\n                if smax == 1.0:\n                    all_df.loc[PassID, 'Family survival'] = 1\n                elif smin == 0.0:\n                    all_df.loc[PassID, 'Family survival'] = 0\nprint('partial age group: ' + str(grp_partial_age))\nprint('partial cabin group: ' + str(grp_partial_cabin))\nprint('Number of passenger with family/group survival information: ' + str(\n    all_df[all_df['Family survival'] != 0.5].shape[0]))\ntrain['Family survival'] = all_df.iloc[:train_size]['Family survival'\n    ].values.astype(float)\ntest['Family survival'] = all_df.iloc[train_size:]['Family survival'\n    ].values.astype(float)\nprint(grp_age_diff_df.describe())\n"
    },
    {
      "raw": "for dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n\n# Feature Selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n                 'Parch', 'FamilySize']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\ntest  = test.drop(drop_elements, axis = 1)\n\nprint (train.head(10))\n\ntrain = train.values\ntest  = test.values",
      "rewrite-ns": 3927737,
      "overhead-ns": 3927737,
      "exec-ns": 21018678,
      "total-ns": 24946415,
      "patts-hit": {},
      "rewritten": "for dataset in full_data:\n    dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n    title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}\n        ).astype(int)\n    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'\n        ] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'\n        ] = 2\n    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[dataset['Age'] > 64, 'Age'] = 4\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch',\n    'FamilySize']\ntrain = train.drop(drop_elements, axis=1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis=1)\ntest = test.drop(drop_elements, axis=1)\nprint(train.head(10))\ntrain = train.values\ntest = test.values\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting, ML code\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# from sklearn.model_selection import StratifiedShuffleSplit\n# from sklearn.metrics import accuracy_score, log_loss\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.svm import SVC\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n# from sklearn.naive_bayes import GaussianNB\n# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n# from sklearn.linear_model import LogisticRegression\n\n# FIRST-AUTHOR: remove ML code\n# classifiers = [\n#     KNeighborsClassifier(3),\n#     SVC(probability=True),\n#     DecisionTreeClassifier(),\n#     RandomForestClassifier(),\n# \tAdaBoostClassifier(),\n#     GradientBoostingClassifier(),\n#     GaussianNB(),\n#     LinearDiscriminantAnalysis(),\n#     QuadraticDiscriminantAnalysis(),\n#     LogisticRegression()]\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog \t = pd.DataFrame(columns=log_cols)\n\n# FIRST-AUTHOR: remove ML code\n# sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n\nX = train[0::, 1::]\ny = train[0::, 0]\n\n# FIRST-AUTHOR: remove ML code, plotting\n# acc_dict = {}\n\n# for train_index, test_index in sss.split(X, y):\n# \tX_train, X_test = X[train_index], X[test_index]\n# \ty_train, y_test = y[train_index], y[test_index]\n\t\n# \tfor clf in classifiers:\n# \t\tname = clf.__class__.__name__\n# \t\tclf.fit(X_train, y_train)\n# \t\ttrain_predictions = clf.predict(X_test)\n# \t\tacc = accuracy_score(y_test, train_predictions)\n# \t\tif name in acc_dict:\n# \t\t\tacc_dict[name] += acc\n# \t\telse:\n# \t\t\tacc_dict[name] = acc\n\n# for clf in acc_dict:\n# \tacc_dict[clf] = acc_dict[clf] / 10.0\n# \tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n# # FIRST-AUTHOR: make notebook run\n# # \tlog = log.append(log_entry)\n# \tlog = pd.concat([log, log_entry])\n\n# plt.xlabel('Accuracy')\n# plt.title('Classifier Accuracy')\n\n# sns.set_color_codes(\"muted\")\n# sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")",
      "rewrite-ns": 1409680,
      "overhead-ns": 1409680,
      "exec-ns": 1103907,
      "total-ns": 2513587,
      "patts-hit": {},
      "rewritten": "log_cols = ['Classifier', 'Accuracy']\nlog = pd.DataFrame(columns=log_cols)\nX = train[0:, 1:]\ny = train[0:, 0]\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# candidate_classifier = SVC()\n# candidate_classifier.fit(train[0::, 1::], train[0::, 0])\n# result = candidate_classifier.predict(test)\n_ = train[0::, 1::]\n_ = train[0::, 0]\nresult = train[:,0]\n# FIRST-AUTHOR: make notebook run with input scaling\n# result_df = pd.DataFrame(columns=['PassengerId', 'Survived'], \n#                          data=np.array([range(892, 1310), result]).T.astype(int))\nresult_df = pd.DataFrame(columns=['PassengerId', 'Survived'], \n                         data=np.array([range(892, result.shape[0] + 892), result]).T.astype(int))\nresult_df.to_csv(\"prediction.csv\", index=False)",
      "rewrite-ns": 2732742,
      "overhead-ns": 2732742,
      "exec-ns": 10586893,
      "total-ns": 13319635,
      "patts-hit": {},
      "rewritten": "_ = train[0:, 1:]\n_ = train[0:, 0]\nresult = train[:, 0]\nresult_df = pd.DataFrame(columns=['PassengerId', 'Survived'], data=np.array\n    ([range(892, result.shape[0] + 892), result]).T.astype(int))\nresult_df.to_csv('prediction.csv', index=False)\n"
    },
    {
      "raw": "",
      "rewrite-ns": 12392,
      "overhead-ns": 12392,
      "exec-ns": 86309,
      "total-ns": 98701,
      "patts-hit": {},
      "rewritten": ""
    }
  ],
  "total-time-in-sec": 21.190412197,
  "max-disk-in-mb": 0
}