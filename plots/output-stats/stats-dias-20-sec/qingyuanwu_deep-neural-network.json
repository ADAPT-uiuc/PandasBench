{
  "max-mem-in-mb": 1003,
  "max-mem-in-mb2": 1861,
  "cells": [
    {
      "raw": "import numpy as np\n# import pandas as pd\nexec(os.environ['IREWR_IMPORTS'])\n\n# ALEX: remove plotting, ML code\n# import seaborn as sns\n# import matplotlib.pyplot as plt  \n\n# from timeit import default_timer as timer\n# from sklearn import preprocessing\n\n# !pip install ultimate\n# from ultimate.mlp import MLP \n\n# from keras.models import Sequential\n# from keras.layers import Dense\n# from keras.callbacks import ModelCheckpoint\n\n# import gc, sys\n# gc.enable()\n",
      "rewrite-ns": 682566,
      "overhead-ns": 682566,
      "exec-ns": 390711,
      "total-ns": 1073277,
      "patts-hit": {},
      "rewritten": "import numpy as np\nexec(os.environ['IREWR_IMPORTS'])\n"
    },
    {
      "raw": "# ALEX: remove extra display code\n# def state(message,start = True, time = 0):\n#     if(start):\n#         print(f'Working on {message} ... ')\n#     else :\n#         print(f'Working on {message} took ({round(time , 3)}) Sec \\n')",
      "rewrite-ns": 19690,
      "overhead-ns": 19690,
      "exec-ns": 104156,
      "total-ns": 123846,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "INPUT_DIR = \"./input/\"",
      "rewrite-ns": 274586,
      "overhead-ns": 274586,
      "exec-ns": 270593,
      "total-ns": 545179,
      "patts-hit": {},
      "rewritten": "INPUT_DIR = './input/'\n"
    },
    {
      "raw": "def feature_engineering(is_train=True):\n    # When this function is used for the training data, load train_V2.csv :\n    if is_train: \n        print(\"processing train_V2.csv\")\n        df = pd.read_csv(INPUT_DIR + 'train_V2.scaled.csv')\n        \n        # Only take the samples with matches that have more than 1 player \n        # there are matches with no players or just one player ( those samples could affect our model badly) \n        df = df[df['maxPlace'] > 1]\n    \n    # When this function is used for the test data, load test_V2.csv :\n    else:\n        print(\"processing test_V2.csv\")\n        df = pd.read_csv(INPUT_DIR + 'test_V2.scaled.csv')\n        \n    # Make a new feature indecating the total distance a player cut :\n# ALEX: remove extra display code\n#     state('totalDistance')\n#     s = timer()\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n# ALEX: remove extra display code\n#     e = timer()\n#     state('totalDistance', False, e - s)\n          \n\n# ALEX: remove extra display code\n#     state('rankPoints')\n#     s = timer()\n    # Process the 'rankPoints' feature by replacing any value of (-1) to be (0) :\n    df['rankPoints'] = np.where(df['rankPoints'] <= 0 ,0 , df['rankPoints'])\n# ALEX: remove extra display code\n#     e = timer()                                  \n#     state('rankPoints', False, e-s)\n    \n\n    target = 'winPlacePerc'\n    # Get a list of the features to be used\n    features = list(df.columns)\n    \n    # Remove some features from the features list :\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchDuration\")\n    features.remove(\"matchType\")\n    \n    y = None\n    \n    # If we are processing the training data, process the target\n    # (group the data by the match and the group then take the mean of the target) \n    if is_train: \n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n        # Remove the target from the features list :\n        features.remove(target)\n    \n    # Make new features indicating the mean of the features ( grouped by match and group ) :\n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    \n    # If we are processing the training data let df_out = the grouped  'matchId' and 'groupId'\n    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n    # If we are processing the test data let df_out = 'matchId' and 'groupId' without grouping \n    else: df_out = df[['matchId','groupId']]\n    \n    # Merge agg and agg_rank (that we got before) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the max value of the features for each group ( grouped by match )\n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    # Merge the new (agg and agg_rank) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the minimum value of the features for each group ( grouped by match )\n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    # Merge the new (agg and agg_rank) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the number of players in each group ( grouped by match )\n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n     \n    # Merge the group_size feature with df_out :\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the mean value of each features for each match :\n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    \n    # Merge the new agg with df_out :\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n    # Make new features indicating the number of groups in each match :\n    print(\"get match size feature\")\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    \n    # Merge the match_size feature with df_out :\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n    # Drop matchId and groupId\n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n    \n    # X is the output dataset (without the target) and y is the target :\n    X = np.array(df_out, dtype=np.float64)\n    \n    \n# ALEX: remove GC code\n#     del df, df_out, agg, agg_rank\n#     gc.collect()\n\n    return X, y\n",
      "rewrite-ns": 26280899,
      "overhead-ns": 26280899,
      "exec-ns": 5053751,
      "total-ns": 31334650,
      "patts-hit": {},
      "rewritten": "def feature_engineering(is_train=True):\n    if is_train:\n        print('processing train_V2.csv')\n        df = pd.read_csv(INPUT_DIR + 'train_V2.scaled.csv')\n        df = df[df['maxPlace'] > 1]\n    else:\n        print('processing test_V2.csv')\n        df = pd.read_csv(INPUT_DIR + 'test_V2.scaled.csv')\n    df['totalDistance'] = df['rideDistance'] + df['walkDistance'] + df[\n        'swimDistance']\n    df['rankPoints'] = np.where(df['rankPoints'] <= 0, 0, df['rankPoints'])\n    target = 'winPlacePerc'\n    features = list(df.columns)\n    features.remove('Id')\n    features.remove('matchId')\n    features.remove('groupId')\n    features.remove('matchDuration')\n    features.remove('matchType')\n    y = None\n    if is_train:\n        y = np.array(df.groupby(['matchId', 'groupId'])[target].agg('mean'),\n            dtype=np.float64)\n        features.remove(target)\n    print('get group mean feature')\n    agg = df.groupby(['matchId', 'groupId'])[features].agg('mean')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    if is_train:\n        df_out = agg.reset_index()[['matchId', 'groupId']]\n    else:\n        df_out = df[['matchId', 'groupId']]\n    df_out = df_out.merge(agg.reset_index(), suffixes=['', ''], how='left',\n        on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=['_mean', '_mean_rank'], how=\n        'left', on=['matchId', 'groupId'])\n    print('get group max feature')\n    agg = df.groupby(['matchId', 'groupId'])[features].agg('max')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=['', ''], how='left',\n        on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=['_max', '_max_rank'], how=\n        'left', on=['matchId', 'groupId'])\n    print('get group min feature')\n    agg = df.groupby(['matchId', 'groupId'])[features].agg('min')\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    df_out = df_out.merge(agg.reset_index(), suffixes=['', ''], how='left',\n        on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=['_min', '_min_rank'], how=\n        'left', on=['matchId', 'groupId'])\n    print('get group size feature')\n    agg = df.groupby(['matchId', 'groupId']).size().reset_index(name=\n        'group_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    print('get match mean feature')\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    df_out = df_out.merge(agg, suffixes=['', '_match_mean'], how='left', on\n        =['matchId'])\n    print('get match size feature')\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    df_out.drop(['matchId', 'groupId'], axis=1, inplace=True)\n    X = np.array(df_out, dtype=np.float64)\n    return X, y\n"
    },
    {
      "raw": "# ALEX: remove IPython commands\n# %%time\n# Process the training data :\nx_train, y = feature_engineering(True)\n# Scale the data to be in the range (-1 , 1)\n# ALEX: remove ML code\n# scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1), copy=False).fit(x_train)",
      "rewrite-ns": 551162,
      "overhead-ns": 551162,
      "exec-ns": 10576825855,
      "total-ns": 10577377017,
      "patts-hit": {},
      "rewritten": "x_train, y = feature_engineering(True)\n"
    },
    {
      "raw": "print(\"x_train\", x_train.shape, x_train.max(), x_train.min())\n# ALEX: remove ML code\n# scaler.transform(x_train)\nprint(\"x_train\", x_train.shape, x_train.max(), x_train.min())",
      "rewrite-ns": 1403339,
      "overhead-ns": 1403339,
      "exec-ns": 120863205,
      "total-ns": 122266544,
      "patts-hit": {},
      "rewritten": "print('x_train', x_train.shape, x_train.max(), x_train.min())\nprint('x_train', x_train.shape, x_train.max(), x_train.min())\n"
    },
    {
      "raw": "y = y * 2 - 1\nprint(\"y\", y.shape, y.max(), y.min())",
      "rewrite-ns": 1180910,
      "overhead-ns": 1180910,
      "exec-ns": 1268452,
      "total-ns": 2449362,
      "patts-hit": {},
      "rewritten": "y = y * 2 - 1\nprint('y', y.shape, y.max(), y.min())\n"
    },
    {
      "raw": "# ALEX: remove IPython commands, ML code\n# %%time\n# # create NN_model\n# NN_model = Sequential()\n# NN_model.add(Dense(x_train.shape[1],  input_dim = x_train.shape[1], activation='relu'))\n# NN_model.add(Dense(136, activation='relu'))\n# NN_model.add(Dense(136, activation='relu'))\n# NN_model.add(Dense(136, activation='relu'))\n# NN_model.add(Dense(136, activation='relu'))\n\n# # output Layer\n# NN_model.add(Dense(1, activation='linear'))\n\n# # Compile the network :\n# NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n# NN_model.summary()\n_ = x_train.shape[1]\n_ = x_train.shape[1]\n",
      "rewrite-ns": 668490,
      "overhead-ns": 668490,
      "exec-ns": 253803,
      "total-ns": 922293,
      "patts-hit": {},
      "rewritten": "_ = x_train.shape[1]\n_ = x_train.shape[1]\n"
    },
    {
      "raw": "# ALEX: remove ML code\n# checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n# checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n# callbacks_list = [checkpoint]\n",
      "rewrite-ns": 13790,
      "overhead-ns": 13790,
      "exec-ns": 74670,
      "total-ns": 88460,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# ALEX: remove IPython commands, ML code\n# %%time\n# NN_model.fit(x=x_train, y=y, batch_size=1000,\n#              epochs=30, verbose=1, callbacks=callbacks_list,\n#              validation_split=0.15, validation_data=None, shuffle=True,\n#              class_weight=None, sample_weight=None, initial_epoch=0,\n#              steps_per_epoch=None, validation_steps=None)\n# del x_train, y\n# gc.collect()",
      "rewrite-ns": 12632,
      "overhead-ns": 12632,
      "exec-ns": 64104,
      "total-ns": 76736,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "x_test, _ = feature_engineering(False)\n# ALEX: remove ML code\n# scaler.transform(x_test)\nprint(\"x_test\", x_test.shape, x_test.max(), x_test.min())\nnp.clip(x_test, out=x_test, a_min=-1, a_max=1)\nprint(\"x_test\", x_test.shape, x_test.max(), x_test.min())",
      "rewrite-ns": 2068684,
      "overhead-ns": 2068684,
      "exec-ns": 4009617327,
      "total-ns": 4011686011,
      "patts-hit": {},
      "rewritten": "x_test, _ = feature_engineering(False)\nprint('x_test', x_test.shape, x_test.max(), x_test.min())\nnp.clip(x_test, out=x_test, a_min=-1, a_max=1)\nprint('x_test', x_test.shape, x_test.max(), x_test.min())\n"
    },
    {
      "raw": "# ALEX: remove IPython commands, ML code\n# %%time\n# pred = NN_model.predict(x_test)\n# del x_test\n# gc.collect()",
      "rewrite-ns": 27522,
      "overhead-ns": 27522,
      "exec-ns": 184440,
      "total-ns": 211962,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# ALEX: remove ML code\n# pred = pred.reshape(-1)\n# pred = (pred + 1) / 2",
      "rewrite-ns": 13819,
      "overhead-ns": 13819,
      "exec-ns": 79712,
      "total-ns": 93531,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "df_test = pd.read_csv(INPUT_DIR + 'test_V2.scaled.csv')",
      "rewrite-ns": 581579,
      "overhead-ns": 581579,
      "exec-ns": 289245446,
      "total-ns": 289827025,
      "patts-hit": {},
      "rewritten": "df_test = pd.read_csv(INPUT_DIR + 'test_V2.scaled.csv')\n"
    },
    {
      "raw": "# ALEX: remove IPython commands, ML code\n# %%time\npred = [0 for _ in range(len(df_test))]\nprint(\"fix winPlacePerc\")\nfor i in range(len(df_test)):\n# ALEX: remove ML code\n#     winPlacePerc = pred[i]\n    winPlacePerc = 0.5\n    maxPlace = int(df_test.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    pred[i] = winPlacePerc",
      "rewrite-ns": 3750088,
      "overhead-ns": 3750088,
      "exec-ns": 10460444439,
      "total-ns": 10464194527,
      "patts-hit": {},
      "rewritten": "pred = [(0) for _ in range(len(df_test))]\nprint('fix winPlacePerc')\nfor i in range(len(df_test)):\n    winPlacePerc = 0.5\n    maxPlace = int(df_test.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    if winPlacePerc < 0:\n        winPlacePerc = 0.0\n    if winPlacePerc > 1:\n        winPlacePerc = 1.0\n    pred[i] = winPlacePerc\n"
    },
    {
      "raw": "df_test['winPlacePerc'] = pred",
      "rewrite-ns": 491582,
      "overhead-ns": 491582,
      "exec-ns": 12297373,
      "total-ns": 12788955,
      "patts-hit": {},
      "rewritten": "df_test['winPlacePerc'] = pred\n"
    },
    {
      "raw": "submission = df_test[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)",
      "rewrite-ns": 791592,
      "overhead-ns": 791592,
      "exec-ns": 243488872,
      "total-ns": 244280464,
      "patts-hit": {},
      "rewritten": "submission = df_test[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)\n"
    }
  ],
  "total-time-in-sec": 25.759339839,
  "max-disk-in-mb": 0
}