{
  "max-mem-in-mb": 7277,
  "max-mem-in-mb2": 8561,
  "cells": [
    {
      "raw": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n\n# ALEX: remove ML code\n# import xgboost as xgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# ALEX: remove path printing\n# from subprocess import check_output\n# print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "rewrite-ns": 791806,
      "overhead-ns": 791806,
      "exec-ns": 512800243,
      "total-ns": 513592049,
      "patts-hit": {},
      "rewritten": "import numpy as np\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n"
    },
    {
      "raw": "#Since training data is huge, so I am planning to read few millions of rows from the csv file.\ntrain = pd.read_csv(\"./input/train.csv\", nrows=nrows, parse_dates=['date'],index_col='id')\n\n#print the last 10 rows of the data, this will help us to think what we can dow with the data.\ntrain.tail(5)",
      "rewrite-ns": 771625,
      "overhead-ns": 771625,
      "exec-ns": 7513097555,
      "total-ns": 7513869180,
      "patts-hit": {},
      "rewritten": "train = pd.read_csv('./input/train.csv', nrows=nrows, parse_dates=['date'],\n    index_col='id')\ntrain.tail(5)\n"
    },
    {
      "raw": "items = pd.read_csv(\"./input/items.scaled.csv\")",
      "rewrite-ns": 501581,
      "overhead-ns": 501581,
      "exec-ns": 2240960,
      "total-ns": 2742541,
      "patts-hit": {},
      "rewritten": "items = pd.read_csv('./input/items.scaled.csv')\n"
    },
    {
      "raw": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)",
      "rewrite-ns": 682983,
      "overhead-ns": 682983,
      "exec-ns": 3884235547,
      "total-ns": 3884918530,
      "patts-hit": {},
      "rewritten": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)\n"
    },
    {
      "raw": "#Lets find out most popular item ordered by people across the 6 millions rows we have read.\n#We will group by item_nbr and add the unit sales.\ndf = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\n#In order to find top 10 popular items we will sort the numpy array and pick the top 10 from\n#the list.\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n\n#Plot the highest list of items.\n# ALEX: remove plotting\n# df_highest.plot(kind='bar',figsize = (10,10),  title = \"Top 10 items sold across all stores\")\n# plt.show()",
      "rewrite-ns": 1365040,
      "overhead-ns": 1365040,
      "exec-ns": 354074697,
      "total-ns": 355439737,
      "patts-hit": {},
      "rewritten": "df = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n"
    },
    {
      "raw": "#Next we find lowest/less demand product. We use nsmallest to find the bottom 10 items,\n#probably it doesn;t matter even if we stock them.\ndf_lowest = df.nsmallest(n=10)\n# ALEX: remove plotting\n# df_lowest.plot(kind='bar',figsize = (10,10),  title = \"Bottom 10 items sold\")\n# plt.show()",
      "rewrite-ns": 465689,
      "overhead-ns": 465689,
      "exec-ns": 992090,
      "total-ns": 1457779,
      "patts-hit": {},
      "rewritten": "df_lowest = df.nsmallest(n=10)\n"
    },
    {
      "raw": "#Next we could find out popular items in a given year. This will be useful to find out \n#if there were any new items introduced in the recent times.\n#In order to do that we need to covert the date field into python date format and then\n# extract various fields from it.\n\ntrain_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] =train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year",
      "rewrite-ns": 2342956,
      "overhead-ns": 2342956,
      "exec-ns": 2813920850,
      "total-ns": 2816263806,
      "patts-hit": {},
      "rewritten": "train_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] = train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year\n"
    },
    {
      "raw": "train_items.drop('date', axis=1, inplace=True)",
      "rewrite-ns": 569570,
      "overhead-ns": 569570,
      "exec-ns": 1193987208,
      "total-ns": 1194556778,
      "patts-hit": {},
      "rewritten": "train_items.drop('date', axis=1, inplace=True)\n"
    },
    {
      "raw": "#Lets print out new training dataset\nprint (train_items.tail(2))",
      "rewrite-ns": 499235,
      "overhead-ns": 499235,
      "exec-ns": 7235750,
      "total-ns": 7734985,
      "patts-hit": {},
      "rewritten": "print(train_items.tail(2))\n"
    },
    {
      "raw": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])['unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n#Plot the highest list of items.\n# ALEX: remove plotting\n# df_year_highest.plot(kind='bar',figsize = (10,10),  title = \"Top items sold Quarterly\")\n# plt.show()",
      "rewrite-ns": 1326733,
      "overhead-ns": 1326733,
      "exec-ns": 967117844,
      "total-ns": 968444577,
      "patts-hit": {},
      "rewritten": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])[\n    'unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n# ALEX: remove plotting\n# plt.pie(df_items_highest, labels=df_items_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_highest.index\n",
      "rewrite-ns": 1474122,
      "overhead-ns": 1474122,
      "exec-ns": 944872239,
      "total-ns": 946346361,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n_ = df_items_highest.index\n"
    },
    {
      "raw": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']",
      "rewrite-ns": 647584,
      "overhead-ns": 647584,
      "exec-ns": 3743599455,
      "total-ns": 3744247039,
      "patts-hit": {},
      "rewritten": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,12))\n# #print (grocery_info.tail(2))\n# plt.plot(grocery_info['day_item_purchased'],grocery_info['unit_sales'])\n# plt.show()\n_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']",
      "rewrite-ns": 614736,
      "overhead-ns": 614736,
      "exec-ns": 418531,
      "total-ns": 1033267,
      "patts-hit": {},
      "rewritten": "_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family','perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n# ALEX: remove plotting\n# plt.pie(df_items_perish_highest, labels=df_items_perish_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_perish_highest.index",
      "rewrite-ns": 1489064,
      "overhead-ns": 1489064,
      "exec-ns": 1505266222,
      "total-ns": 1506755286,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family', 'perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n_ = df_items_perish_highest.index\n"
    },
    {
      "raw": "transaction = pd.read_csv(\"./input/transactions.scaled.csv\")",
      "rewrite-ns": 433682,
      "overhead-ns": 433682,
      "exec-ns": 13260242,
      "total-ns": 13693924,
      "patts-hit": {},
      "rewritten": "transaction = pd.read_csv('./input/transactions.scaled.csv')\n"
    },
    {
      "raw": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] =transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint (transaction.tail(2))",
      "rewrite-ns": 2718576,
      "overhead-ns": 2718576,
      "exec-ns": 19249088,
      "total-ns": 21967664,
      "patts-hit": {},
      "rewritten": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] = transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint(transaction.tail(2))\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(25,25))\n# plt.plot(transaction['date'],transaction['transactions'])\n# plt.show()\n_ = transaction['date']\n_ = transaction['transactions']\n",
      "rewrite-ns": 562717,
      "overhead-ns": 562717,
      "exec-ns": 319594,
      "total-ns": 882311,
      "patts-hit": {},
      "rewritten": "_ = transaction['date']\n_ = transaction['transactions']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(8,12))\ntrans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# ALEX: remove plotting\n# trans_day.plot(kind='bar')\n# plt.show()",
      "rewrite-ns": 679133,
      "overhead-ns": 679133,
      "exec-ns": 1467902,
      "total-ns": 2147035,
      "patts-hit": {},
      "rewritten": "trans_day = transaction['transactions'].groupby(transaction[\n    'year_item_purchased']).sum()\n"
    },
    {
      "raw": "stores = pd.read_csv(\"./input/stores.scaled.csv\")\nprint (stores.head())",
      "rewrite-ns": 693833,
      "overhead-ns": 693833,
      "exec-ns": 4659221,
      "total-ns": 5353054,
      "patts-hit": {},
      "rewritten": "stores = pd.read_csv('./input/stores.scaled.csv')\nprint(stores.head())\n"
    },
    {
      "raw": "#Lets find out number of cities in each state, which in nothing but finding out number of stores in each\n#in each state.\ndf = stores['city'].groupby(stores['state']).count()\n# ALEX: remove plotting\n# df.plot(kind='bar', figsize = (12,8), yticks=np.arange(min(df), max(df)+1, 1.0), title = \"Number of cities in each state\")\n# plt.show()\n_ = min(df)\n_ = max(df)",
      "rewrite-ns": 1153192,
      "overhead-ns": 1153192,
      "exec-ns": 829222,
      "total-ns": 1982414,
      "patts-hit": {},
      "rewritten": "df = stores['city'].groupby(stores['state']).count()\n_ = min(df)\n_ = max(df)\n"
    },
    {
      "raw": "#Looks like onpromotion field is always NaN, if so we will get rid of that columns \n#from the training data\nprint(train['onpromotion'].notnull().any())\ntrain_new=train.drop('onpromotion',axis=1)\nprint(train_new.tail(5))",
      "rewrite-ns": 1263168,
      "overhead-ns": 1263168,
      "exec-ns": 694926436,
      "total-ns": 696189604,
      "patts-hit": {},
      "rewritten": "print(train['onpromotion'].notnull().any())\ntrain_new = train.drop('onpromotion', axis=1)\nprint(train_new.tail(5))\n"
    },
    {
      "raw": "oils = pd.read_csv(\"./input/oil.scaled.csv\")\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] =oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year",
      "rewrite-ns": 2695085,
      "overhead-ns": 2695085,
      "exec-ns": 4128129,
      "total-ns": 6823214,
      "patts-hit": {},
      "rewritten": "oils = pd.read_csv('./input/oil.scaled.csv')\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] = oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(25,25))\n# #trans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# plt.plot(oils['date'],oils['dcoilwtico'])\n# #trans_day.plot(kind='bar')\n# plt.show()\n_ = oils['date']\n_ = oils['dcoilwtico']",
      "rewrite-ns": 566754,
      "overhead-ns": 566754,
      "exec-ns": 329827,
      "total-ns": 896581,
      "patts-hit": {},
      "rewritten": "_ = oils['date']\n_ = oils['dcoilwtico']\n"
    }
  ],
  "total-time-in-sec": 24.207337716,
  "max-disk-in-mb": 0
}