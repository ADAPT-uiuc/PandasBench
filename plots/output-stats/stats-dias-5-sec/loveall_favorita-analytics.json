{
  "max-mem-in-mb": 1881,
  "max-mem-in-mb2": 2156,
  "cells": [
    {
      "raw": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n\n# ALEX: remove ML code\n# import xgboost as xgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# ALEX: remove path printing\n# from subprocess import check_output\n# print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "rewrite-ns": 818002,
      "overhead-ns": 818002,
      "exec-ns": 533372876,
      "total-ns": 534190878,
      "patts-hit": {},
      "rewritten": "import numpy as np\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n"
    },
    {
      "raw": "#Since training data is huge, so I am planning to read few millions of rows from the csv file.\ntrain = pd.read_csv(\"./input/train.csv\", nrows=nrows, parse_dates=['date'],index_col='id')\n\n#print the last 10 rows of the data, this will help us to think what we can dow with the data.\ntrain.tail(5)",
      "rewrite-ns": 789440,
      "overhead-ns": 789440,
      "exec-ns": 2216223517,
      "total-ns": 2217012957,
      "patts-hit": {},
      "rewritten": "train = pd.read_csv('./input/train.csv', nrows=nrows, parse_dates=['date'],\n    index_col='id')\ntrain.tail(5)\n"
    },
    {
      "raw": "items = pd.read_csv(\"./input/items.scaled.csv\")",
      "rewrite-ns": 512323,
      "overhead-ns": 512323,
      "exec-ns": 1736534,
      "total-ns": 2248857,
      "patts-hit": {},
      "rewritten": "items = pd.read_csv('./input/items.scaled.csv')\n"
    },
    {
      "raw": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)",
      "rewrite-ns": 612889,
      "overhead-ns": 612889,
      "exec-ns": 650997494,
      "total-ns": 651610383,
      "patts-hit": {},
      "rewritten": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)\n"
    },
    {
      "raw": "#Lets find out most popular item ordered by people across the 6 millions rows we have read.\n#We will group by item_nbr and add the unit sales.\ndf = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\n#In order to find top 10 popular items we will sort the numpy array and pick the top 10 from\n#the list.\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n\n#Plot the highest list of items.\n# ALEX: remove plotting\n# df_highest.plot(kind='bar',figsize = (10,10),  title = \"Top 10 items sold across all stores\")\n# plt.show()",
      "rewrite-ns": 1348769,
      "overhead-ns": 1348769,
      "exec-ns": 82452962,
      "total-ns": 83801731,
      "patts-hit": {},
      "rewritten": "df = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n"
    },
    {
      "raw": "#Next we find lowest/less demand product. We use nsmallest to find the bottom 10 items,\n#probably it doesn;t matter even if we stock them.\ndf_lowest = df.nsmallest(n=10)\n# ALEX: remove plotting\n# df_lowest.plot(kind='bar',figsize = (10,10),  title = \"Bottom 10 items sold\")\n# plt.show()",
      "rewrite-ns": 474891,
      "overhead-ns": 474891,
      "exec-ns": 2053726,
      "total-ns": 2528617,
      "patts-hit": {},
      "rewritten": "df_lowest = df.nsmallest(n=10)\n"
    },
    {
      "raw": "#Next we could find out popular items in a given year. This will be useful to find out \n#if there were any new items introduced in the recent times.\n#In order to do that we need to covert the date field into python date format and then\n# extract various fields from it.\n\ntrain_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] =train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year",
      "rewrite-ns": 2347342,
      "overhead-ns": 2347342,
      "exec-ns": 660616032,
      "total-ns": 662963374,
      "patts-hit": {},
      "rewritten": "train_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] = train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year\n"
    },
    {
      "raw": "train_items.drop('date', axis=1, inplace=True)",
      "rewrite-ns": 544318,
      "overhead-ns": 544318,
      "exec-ns": 178377556,
      "total-ns": 178921874,
      "patts-hit": {},
      "rewritten": "train_items.drop('date', axis=1, inplace=True)\n"
    },
    {
      "raw": "#Lets print out new training dataset\nprint (train_items.tail(2))",
      "rewrite-ns": 492340,
      "overhead-ns": 492340,
      "exec-ns": 7089044,
      "total-ns": 7581384,
      "patts-hit": {},
      "rewritten": "print(train_items.tail(2))\n"
    },
    {
      "raw": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])['unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n#Plot the highest list of items.\n# ALEX: remove plotting\n# df_year_highest.plot(kind='bar',figsize = (10,10),  title = \"Top items sold Quarterly\")\n# plt.show()",
      "rewrite-ns": 1314629,
      "overhead-ns": 1314629,
      "exec-ns": 245423099,
      "total-ns": 246737728,
      "patts-hit": {},
      "rewritten": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])[\n    'unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n# ALEX: remove plotting\n# plt.pie(df_items_highest, labels=df_items_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_highest.index\n",
      "rewrite-ns": 1470726,
      "overhead-ns": 1470726,
      "exec-ns": 227421607,
      "total-ns": 228892333,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n_ = df_items_highest.index\n"
    },
    {
      "raw": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']",
      "rewrite-ns": 630177,
      "overhead-ns": 630177,
      "exec-ns": 495459408,
      "total-ns": 496089585,
      "patts-hit": {},
      "rewritten": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,12))\n# #print (grocery_info.tail(2))\n# plt.plot(grocery_info['day_item_purchased'],grocery_info['unit_sales'])\n# plt.show()\n_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']",
      "rewrite-ns": 613474,
      "overhead-ns": 613474,
      "exec-ns": 403436,
      "total-ns": 1016910,
      "patts-hit": {},
      "rewritten": "_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family','perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n# ALEX: remove plotting\n# plt.pie(df_items_perish_highest, labels=df_items_perish_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_perish_highest.index",
      "rewrite-ns": 1493569,
      "overhead-ns": 1493569,
      "exec-ns": 370335407,
      "total-ns": 371828976,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family', 'perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n_ = df_items_perish_highest.index\n"
    },
    {
      "raw": "transaction = pd.read_csv(\"./input/transactions.scaled.csv\")",
      "rewrite-ns": 432904,
      "overhead-ns": 432904,
      "exec-ns": 4790934,
      "total-ns": 5223838,
      "patts-hit": {},
      "rewritten": "transaction = pd.read_csv('./input/transactions.scaled.csv')\n"
    },
    {
      "raw": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] =transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint (transaction.tail(2))",
      "rewrite-ns": 2721486,
      "overhead-ns": 2721486,
      "exec-ns": 11360910,
      "total-ns": 14082396,
      "patts-hit": {},
      "rewritten": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] = transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint(transaction.tail(2))\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(25,25))\n# plt.plot(transaction['date'],transaction['transactions'])\n# plt.show()\n_ = transaction['date']\n_ = transaction['transactions']\n",
      "rewrite-ns": 550269,
      "overhead-ns": 550269,
      "exec-ns": 286814,
      "total-ns": 837083,
      "patts-hit": {},
      "rewritten": "_ = transaction['date']\n_ = transaction['transactions']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(8,12))\ntrans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# ALEX: remove plotting\n# trans_day.plot(kind='bar')\n# plt.show()",
      "rewrite-ns": 663358,
      "overhead-ns": 663358,
      "exec-ns": 885589,
      "total-ns": 1548947,
      "patts-hit": {},
      "rewritten": "trans_day = transaction['transactions'].groupby(transaction[\n    'year_item_purchased']).sum()\n"
    },
    {
      "raw": "stores = pd.read_csv(\"./input/stores.scaled.csv\")\nprint (stores.head())",
      "rewrite-ns": 665234,
      "overhead-ns": 665234,
      "exec-ns": 4291110,
      "total-ns": 4956344,
      "patts-hit": {},
      "rewritten": "stores = pd.read_csv('./input/stores.scaled.csv')\nprint(stores.head())\n"
    },
    {
      "raw": "#Lets find out number of cities in each state, which in nothing but finding out number of stores in each\n#in each state.\ndf = stores['city'].groupby(stores['state']).count()\n# ALEX: remove plotting\n# df.plot(kind='bar', figsize = (12,8), yticks=np.arange(min(df), max(df)+1, 1.0), title = \"Number of cities in each state\")\n# plt.show()\n_ = min(df)\n_ = max(df)",
      "rewrite-ns": 1120817,
      "overhead-ns": 1120817,
      "exec-ns": 721555,
      "total-ns": 1842372,
      "patts-hit": {},
      "rewritten": "df = stores['city'].groupby(stores['state']).count()\n_ = min(df)\n_ = max(df)\n"
    },
    {
      "raw": "#Looks like onpromotion field is always NaN, if so we will get rid of that columns \n#from the training data\nprint(train['onpromotion'].notnull().any())\ntrain_new=train.drop('onpromotion',axis=1)\nprint(train_new.tail(5))",
      "rewrite-ns": 1284657,
      "overhead-ns": 1284657,
      "exec-ns": 77812535,
      "total-ns": 79097192,
      "patts-hit": {},
      "rewritten": "print(train['onpromotion'].notnull().any())\ntrain_new = train.drop('onpromotion', axis=1)\nprint(train_new.tail(5))\n"
    },
    {
      "raw": "oils = pd.read_csv(\"./input/oil.scaled.csv\")\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] =oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year",
      "rewrite-ns": 2733894,
      "overhead-ns": 2733894,
      "exec-ns": 3661122,
      "total-ns": 6395016,
      "patts-hit": {},
      "rewritten": "oils = pd.read_csv('./input/oil.scaled.csv')\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] = oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(25,25))\n# #trans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# plt.plot(oils['date'],oils['dcoilwtico'])\n# #trans_day.plot(kind='bar')\n# plt.show()\n_ = oils['date']\n_ = oils['dcoilwtico']",
      "rewrite-ns": 568177,
      "overhead-ns": 568177,
      "exec-ns": 313976,
      "total-ns": 882153,
      "patts-hit": {},
      "rewritten": "_ = oils['date']\n_ = oils['dcoilwtico']\n"
    }
  ],
  "total-time-in-sec": 5.800290928,
  "max-disk-in-mb": 0
}