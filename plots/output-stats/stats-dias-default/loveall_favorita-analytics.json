{
  "max-mem-in-mb": 7473,
  "max-mem-in-mb2": 8919,
  "cells": [
    {
      "raw": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n\n# FIRST-AUTHOR: remove ML code\n# import xgboost as xgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# FIRST-AUTHOR: remove path printing\n# from subprocess import check_output\n# print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "rewrite-ns": 575991,
      "overhead-ns": 575991,
      "exec-ns": 397081872,
      "total-ns": 397657863,
      "patts-hit": {},
      "rewritten": "import numpy as np\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n"
    },
    {
      "raw": "#Since training data is huge, so I am planning to read few millions of rows from the csv file.\ntrain = pd.read_csv(\"./input/train.csv\", nrows=nrows, parse_dates=['date'],index_col='id')\n\n#print the last 10 rows of the data, this will help us to think what we can dow with the data.\ntrain.tail(5)",
      "rewrite-ns": 760809,
      "overhead-ns": 760809,
      "exec-ns": 8016393231,
      "total-ns": 8017154040,
      "patts-hit": {},
      "rewritten": "train = pd.read_csv('./input/train.csv', nrows=nrows, parse_dates=['date'],\n    index_col='id')\ntrain.tail(5)\n"
    },
    {
      "raw": "items = pd.read_csv(\"./input/items.scaled.csv\")",
      "rewrite-ns": 513620,
      "overhead-ns": 513620,
      "exec-ns": 2290510,
      "total-ns": 2804130,
      "patts-hit": {},
      "rewritten": "items = pd.read_csv('./input/items.scaled.csv')\n"
    },
    {
      "raw": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)",
      "rewrite-ns": 691302,
      "overhead-ns": 691302,
      "exec-ns": 4061787477,
      "total-ns": 4062478779,
      "patts-hit": {},
      "rewritten": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)\n"
    },
    {
      "raw": "#Lets find out most popular item ordered by people across the 6 millions rows we have read.\n#We will group by item_nbr and add the unit sales.\ndf = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\n#In order to find top 10 popular items we will sort the numpy array and pick the top 10 from\n#the list.\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n\n#Plot the highest list of items.\n# FIRST-AUTHOR: remove plotting\n# df_highest.plot(kind='bar',figsize = (10,10),  title = \"Top 10 items sold across all stores\")\n# plt.show()",
      "rewrite-ns": 1348520,
      "overhead-ns": 1348520,
      "exec-ns": 373660172,
      "total-ns": 375008692,
      "patts-hit": {},
      "rewritten": "df = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n"
    },
    {
      "raw": "#Next we find lowest/less demand product. We use nsmallest to find the bottom 10 items,\n#probably it doesn;t matter even if we stock them.\ndf_lowest = df.nsmallest(n=10)\n# FIRST-AUTHOR: remove plotting\n# df_lowest.plot(kind='bar',figsize = (10,10),  title = \"Bottom 10 items sold\")\n# plt.show()",
      "rewrite-ns": 515777,
      "overhead-ns": 515777,
      "exec-ns": 1083610,
      "total-ns": 1599387,
      "patts-hit": {},
      "rewritten": "df_lowest = df.nsmallest(n=10)\n"
    },
    {
      "raw": "#Next we could find out popular items in a given year. This will be useful to find out \n#if there were any new items introduced in the recent times.\n#In order to do that we need to covert the date field into python date format and then\n# extract various fields from it.\n\ntrain_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] =train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year",
      "rewrite-ns": 2392186,
      "overhead-ns": 2392186,
      "exec-ns": 2990100254,
      "total-ns": 2992492440,
      "patts-hit": {},
      "rewritten": "train_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] = train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year\n"
    },
    {
      "raw": "train_items.drop('date', axis=1, inplace=True)",
      "rewrite-ns": 576285,
      "overhead-ns": 576285,
      "exec-ns": 1230952390,
      "total-ns": 1231528675,
      "patts-hit": {},
      "rewritten": "train_items.drop('date', axis=1, inplace=True)\n"
    },
    {
      "raw": "#Lets print out new training dataset\nprint (train_items.tail(2))",
      "rewrite-ns": 505688,
      "overhead-ns": 505688,
      "exec-ns": 7411258,
      "total-ns": 7916946,
      "patts-hit": {},
      "rewritten": "print(train_items.tail(2))\n"
    },
    {
      "raw": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])['unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n#Plot the highest list of items.\n# FIRST-AUTHOR: remove plotting\n# df_year_highest.plot(kind='bar',figsize = (10,10),  title = \"Top items sold Quarterly\")\n# plt.show()",
      "rewrite-ns": 1346242,
      "overhead-ns": 1346242,
      "exec-ns": 1032144975,
      "total-ns": 1033491217,
      "patts-hit": {},
      "rewritten": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])[\n    'unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n# FIRST-AUTHOR: remove plotting\n# plt.pie(df_items_highest, labels=df_items_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_highest.index\n",
      "rewrite-ns": 1484987,
      "overhead-ns": 1484987,
      "exec-ns": 1028720291,
      "total-ns": 1030205278,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n_ = df_items_highest.index\n"
    },
    {
      "raw": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']",
      "rewrite-ns": 654874,
      "overhead-ns": 654874,
      "exec-ns": 3920394067,
      "total-ns": 3921048941,
      "patts-hit": {},
      "rewritten": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(12,12))\n# #print (grocery_info.tail(2))\n# plt.plot(grocery_info['day_item_purchased'],grocery_info['unit_sales'])\n# plt.show()\n_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']",
      "rewrite-ns": 619578,
      "overhead-ns": 619578,
      "exec-ns": 430327,
      "total-ns": 1049905,
      "patts-hit": {},
      "rewritten": "_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family','perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n# FIRST-AUTHOR: remove plotting\n# plt.pie(df_items_perish_highest, labels=df_items_perish_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_perish_highest.index",
      "rewrite-ns": 1494205,
      "overhead-ns": 1494205,
      "exec-ns": 1628561812,
      "total-ns": 1630056017,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family', 'perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n_ = df_items_perish_highest.index\n"
    },
    {
      "raw": "transaction = pd.read_csv(\"./input/transactions.scaled.csv\")",
      "rewrite-ns": 436508,
      "overhead-ns": 436508,
      "exec-ns": 14965380,
      "total-ns": 15401888,
      "patts-hit": {},
      "rewritten": "transaction = pd.read_csv('./input/transactions.scaled.csv')\n"
    },
    {
      "raw": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] =transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint (transaction.tail(2))",
      "rewrite-ns": 2732636,
      "overhead-ns": 2732636,
      "exec-ns": 20128973,
      "total-ns": 22861609,
      "patts-hit": {},
      "rewritten": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] = transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint(transaction.tail(2))\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(25,25))\n# plt.plot(transaction['date'],transaction['transactions'])\n# plt.show()\n_ = transaction['date']\n_ = transaction['transactions']\n",
      "rewrite-ns": 570190,
      "overhead-ns": 570190,
      "exec-ns": 334121,
      "total-ns": 904311,
      "patts-hit": {},
      "rewritten": "_ = transaction['date']\n_ = transaction['transactions']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(8,12))\ntrans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# FIRST-AUTHOR: remove plotting\n# trans_day.plot(kind='bar')\n# plt.show()",
      "rewrite-ns": 703815,
      "overhead-ns": 703815,
      "exec-ns": 1588346,
      "total-ns": 2292161,
      "patts-hit": {},
      "rewritten": "trans_day = transaction['transactions'].groupby(transaction[\n    'year_item_purchased']).sum()\n"
    },
    {
      "raw": "stores = pd.read_csv(\"./input/stores.scaled.csv\")\nprint (stores.head())",
      "rewrite-ns": 709779,
      "overhead-ns": 709779,
      "exec-ns": 4723705,
      "total-ns": 5433484,
      "patts-hit": {},
      "rewritten": "stores = pd.read_csv('./input/stores.scaled.csv')\nprint(stores.head())\n"
    },
    {
      "raw": "#Lets find out number of cities in each state, which in nothing but finding out number of stores in each\n#in each state.\ndf = stores['city'].groupby(stores['state']).count()\n# FIRST-AUTHOR: remove plotting\n# df.plot(kind='bar', figsize = (12,8), yticks=np.arange(min(df), max(df)+1, 1.0), title = \"Number of cities in each state\")\n# plt.show()\n_ = min(df)\n_ = max(df)",
      "rewrite-ns": 1152269,
      "overhead-ns": 1152269,
      "exec-ns": 876913,
      "total-ns": 2029182,
      "patts-hit": {},
      "rewritten": "df = stores['city'].groupby(stores['state']).count()\n_ = min(df)\n_ = max(df)\n"
    },
    {
      "raw": "#Looks like onpromotion field is always NaN, if so we will get rid of that columns \n#from the training data\nprint(train['onpromotion'].notnull().any())\ntrain_new=train.drop('onpromotion',axis=1)\nprint(train_new.tail(5))",
      "rewrite-ns": 1291433,
      "overhead-ns": 1291433,
      "exec-ns": 779031715,
      "total-ns": 780323148,
      "patts-hit": {},
      "rewritten": "print(train['onpromotion'].notnull().any())\ntrain_new = train.drop('onpromotion', axis=1)\nprint(train_new.tail(5))\n"
    },
    {
      "raw": "oils = pd.read_csv(\"./input/oil.scaled.csv\")\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] =oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year",
      "rewrite-ns": 2704860,
      "overhead-ns": 2704860,
      "exec-ns": 4212940,
      "total-ns": 6917800,
      "patts-hit": {},
      "rewritten": "oils = pd.read_csv('./input/oil.scaled.csv')\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] = oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(25,25))\n# #trans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# plt.plot(oils['date'],oils['dcoilwtico'])\n# #trans_day.plot(kind='bar')\n# plt.show()\n_ = oils['date']\n_ = oils['dcoilwtico']",
      "rewrite-ns": 584811,
      "overhead-ns": 584811,
      "exec-ns": 349197,
      "total-ns": 934008,
      "patts-hit": {},
      "rewritten": "_ = oils['date']\n_ = oils['dcoilwtico']\n"
    }
  ],
  "total-time-in-sec": 25.541589901,
  "max-disk-in-mb": 0
}