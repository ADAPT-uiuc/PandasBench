{
  "max-mem-in-mb": 117,
  "max-mem-in-mb2": 121,
  "cells": [
    {
      "raw": "# import pandas as pd\nexec(os.environ['IREWR_IMPORTS'])\nimport numpy as np\nimport re\n# FIRST-AUTHOR: remove ML code\n# from nltk.stem import WordNetLemmatizer\n# from nltk.corpus import names, stopwords\nimport unicodedata\n# from sklearn.model_selection import train_test_split\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.pipeline import Pipeline\n# from sklearn.metrics import classification_report\n# from sklearn.linear_model import LogisticRegression",
      "rewrite-ns": 645439,
      "overhead-ns": 645439,
      "exec-ns": 319093,
      "total-ns": 964532,
      "patts-hit": {},
      "rewritten": "exec(os.environ['IREWR_IMPORTS'])\nimport numpy as np\nimport re\nimport unicodedata\n"
    },
    {
      "raw": "",
      "rewrite-ns": 13027,
      "overhead-ns": 13027,
      "exec-ns": 70162,
      "total-ns": 83189,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "tweet_train_df = pd.read_csv('./input/train.scaled.csv')\ntweet_test_df = pd.read_csv('./input/test.scaled.csv')\nId = tweet_test_df['id']",
      "rewrite-ns": 910747,
      "overhead-ns": 910747,
      "exec-ns": 20302910,
      "total-ns": 21213657,
      "patts-hit": {},
      "rewritten": "tweet_train_df = pd.read_csv('./input/train.scaled.csv')\ntweet_test_df = pd.read_csv('./input/test.scaled.csv')\nId = tweet_test_df['id']\n"
    },
    {
      "raw": "tweet_train_df.head()",
      "rewrite-ns": 80620,
      "overhead-ns": 80620,
      "exec-ns": 5369617,
      "total-ns": 5450237,
      "patts-hit": {},
      "rewritten": "tweet_train_df.head()\n"
    },
    {
      "raw": "tweet_train_df.isna().sum()",
      "rewrite-ns": 371325,
      "overhead-ns": 371325,
      "exec-ns": 3028136,
      "total-ns": 3399461,
      "patts-hit": {},
      "rewritten": "tweet_train_df.isna().sum()\n"
    },
    {
      "raw": "tweet_train_df.info()",
      "rewrite-ns": 73141,
      "overhead-ns": 73141,
      "exec-ns": 4946702,
      "total-ns": 5019843,
      "patts-hit": {},
      "rewritten": "tweet_train_df.info()\n"
    },
    {
      "raw": "tweet_train_df.shape",
      "rewrite-ns": 51402,
      "overhead-ns": 51402,
      "exec-ns": 449722,
      "total-ns": 501124,
      "patts-hit": {},
      "rewritten": "tweet_train_df.shape\n"
    },
    {
      "raw": "def data_imputation(data):\n    data['keyword'].fillna(' ', inplace=True)\n    data['location'].fillna(' ', inplace=True)\n    return data",
      "rewrite-ns": 1454066,
      "overhead-ns": 1454066,
      "exec-ns": 361723,
      "total-ns": 1815789,
      "patts-hit": {},
      "rewritten": "def data_imputation(data):\n    data['keyword'].fillna(' ', inplace=True)\n    data['location'].fillna(' ', inplace=True)\n    return data\n"
    },
    {
      "raw": "tweet_train_df = data_imputation(tweet_train_df)",
      "rewrite-ns": 302100,
      "overhead-ns": 302100,
      "exec-ns": 1108822,
      "total-ns": 1410922,
      "patts-hit": {},
      "rewritten": "tweet_train_df = data_imputation(tweet_train_df)\n"
    },
    {
      "raw": "tweet_test_df = data_imputation(tweet_test_df)",
      "rewrite-ns": 302565,
      "overhead-ns": 302565,
      "exec-ns": 807332,
      "total-ns": 1109897,
      "patts-hit": {},
      "rewritten": "tweet_test_df = data_imputation(tweet_test_df)\n"
    },
    {
      "raw": "tweet_train_df.isna().sum()",
      "rewrite-ns": 357980,
      "overhead-ns": 357980,
      "exec-ns": 2856907,
      "total-ns": 3214887,
      "patts-hit": {},
      "rewritten": "tweet_train_df.isna().sum()\n"
    },
    {
      "raw": "tweet_train_df['text'] = tweet_train_df['text'] +' '+ tweet_train_df['location'] +' '+ tweet_train_df['keyword']\ntweet_test_df['text'] = tweet_test_df['text'] +' '+ tweet_test_df['location'] +' '+ tweet_test_df['keyword']",
      "rewrite-ns": 1864068,
      "overhead-ns": 1864068,
      "exec-ns": 5046093,
      "total-ns": 6910161,
      "patts-hit": {},
      "rewritten": "tweet_train_df['text'] = tweet_train_df['text'] + ' ' + tweet_train_df[\n    'location'] + ' ' + tweet_train_df['keyword']\ntweet_test_df['text'] = tweet_test_df['text'] + ' ' + tweet_test_df['location'\n    ] + ' ' + tweet_test_df['keyword']\n"
    },
    {
      "raw": "target = tweet_train_df['target']",
      "rewrite-ns": 301902,
      "overhead-ns": 301902,
      "exec-ns": 237439,
      "total-ns": 539341,
      "patts-hit": {},
      "rewritten": "target = tweet_train_df['target']\n"
    },
    {
      "raw": "tweet_train_df.drop(['target', 'location', 'keyword', 'id'], axis=1, inplace=True)\ntweet_test_df.drop(['location', 'keyword', 'id'], axis=1, inplace=True)",
      "rewrite-ns": 1119754,
      "overhead-ns": 1119754,
      "exec-ns": 1220093,
      "total-ns": 2339847,
      "patts-hit": {},
      "rewritten": "tweet_train_df.drop(['target', 'location', 'keyword', 'id'], axis=1,\n    inplace=True)\ntweet_test_df.drop(['location', 'keyword', 'id'], axis=1, inplace=True)\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# lemmetizer = WordNetLemmatizer()",
      "rewrite-ns": 12505,
      "overhead-ns": 12505,
      "exec-ns": 66309,
      "total-ns": 78814,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# all_names = set(names.words())",
      "rewrite-ns": 11471,
      "overhead-ns": 11471,
      "exec-ns": 61676,
      "total-ns": 73147,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# stop_words = set(stopwords.words('english'))",
      "rewrite-ns": 10851,
      "overhead-ns": 10851,
      "exec-ns": 57315,
      "total-ns": 68166,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# tf_idf = TfidfVectorizer(min_df=0.1, max_df=0.7)",
      "rewrite-ns": 10079,
      "overhead-ns": 10079,
      "exec-ns": 54724,
      "total-ns": 64803,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "def cleaned_string(string):\n    # Removing all the digits\n    string = re.sub(r'\\d', '', string)\n    \n    # Removing accented data\n    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    \n    # Removing Mentions\n    string = re.sub(r'@\\w+', ' ', string)\n    \n    # Removing links \n    string = re.sub(r'(https?:\\/\\/)?([\\da-zA-Z\\.-\\/\\#\\:]+)\\.([\\da-zA-Z\\.\\/\\:\\#]{0,9})([\\/\\w \\.-\\/\\:\\#]*)', ' ', string)\n    \n    # Removing all the digits special caharacters\n    string = re.sub(r'\\W', ' ', string)\n        \n    \n    # Removing double whitespaces\n    string = re.sub(r'\\s+', ' ', string, flags=re.I)\n    \n\n    \n    string = string.strip()\n    \n    #Removing all Single characters\n    string = re.sub(r'\\^[a-zA-Z]\\s+','' , string)\n    \n    \n    # Lemmetizing the string and removing stop words\n    string = string.split()\n# FIRST-AUTHOR: remove ML code\n#     string = [lemmetizer.lemmatize(word) for word in string if word not in stop_words and word not in all_names]\n    string = ' '.join(string)\n    \n    # Lowercasing all data\n    string = string.lower()\n        \n    return string",
      "rewrite-ns": 4039687,
      "overhead-ns": 4039687,
      "exec-ns": 790838,
      "total-ns": 4830525,
      "patts-hit": {},
      "rewritten": "def cleaned_string(string):\n    string = re.sub('\\\\d', '', string)\n    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore'\n        ).decode('utf-8', 'ignore')\n    string = re.sub('@\\\\w+', ' ', string)\n    string = re.sub(\n        '(https?:\\\\/\\\\/)?([\\\\da-zA-Z\\\\.-\\\\/\\\\#\\\\:]+)\\\\.([\\\\da-zA-Z\\\\.\\\\/\\\\:\\\\#]{0,9})([\\\\/\\\\w \\\\.-\\\\/\\\\:\\\\#]*)'\n        , ' ', string)\n    string = re.sub('\\\\W', ' ', string)\n    string = re.sub('\\\\s+', ' ', string, flags=re.I)\n    string = string.strip()\n    string = re.sub('\\\\^[a-zA-Z]\\\\s+', '', string)\n    string = string.split()\n    string = ' '.join(string)\n    string = string.lower()\n    return string\n"
    },
    {
      "raw": "def clean_text(data):\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            data.iloc[i, j] = cleaned_string(data.iloc[i, j])\n    return data\n            \n            \n    ",
      "rewrite-ns": 1665717,
      "overhead-ns": 1665717,
      "exec-ns": 420660,
      "total-ns": 2086377,
      "patts-hit": {},
      "rewritten": "def clean_text(data):\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            data.iloc[i, j] = cleaned_string(data.iloc[i, j])\n    return data\n"
    },
    {
      "raw": "tweet_cleaned_test_df = clean_text(tweet_test_df)",
      "rewrite-ns": 284807,
      "overhead-ns": 284807,
      "exec-ns": 260114012,
      "total-ns": 260398819,
      "patts-hit": {},
      "rewritten": "tweet_cleaned_test_df = clean_text(tweet_test_df)\n"
    },
    {
      "raw": "tweet_cleaned_test_df.shape",
      "rewrite-ns": 51683,
      "overhead-ns": 51683,
      "exec-ns": 429598,
      "total-ns": 481281,
      "patts-hit": {},
      "rewritten": "tweet_cleaned_test_df.shape\n"
    },
    {
      "raw": "tweet_cleaned_test_df.head()",
      "rewrite-ns": 70127,
      "overhead-ns": 70127,
      "exec-ns": 1982911,
      "total-ns": 2053038,
      "patts-hit": {},
      "rewritten": "tweet_cleaned_test_df.head()\n"
    },
    {
      "raw": "tweet_cleaned_train_df = clean_text(tweet_train_df)",
      "rewrite-ns": 296244,
      "overhead-ns": 296244,
      "exec-ns": 603041914,
      "total-ns": 603338158,
      "patts-hit": {},
      "rewritten": "tweet_cleaned_train_df = clean_text(tweet_train_df)\n"
    },
    {
      "raw": "tweet_train_df.shape",
      "rewrite-ns": 51230,
      "overhead-ns": 51230,
      "exec-ns": 421538,
      "total-ns": 472768,
      "patts-hit": {},
      "rewritten": "tweet_train_df.shape\n"
    },
    {
      "raw": "tweet_cleaned_train_df.head()",
      "rewrite-ns": 70758,
      "overhead-ns": 70758,
      "exec-ns": 1954737,
      "total-ns": 2025495,
      "patts-hit": {},
      "rewritten": "tweet_cleaned_train_df.head()\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# X_train, X_valid, y_train, y_valid = train_test_split(tweet_cleaned_train_df['text'], target,random_state = 0)\n_ = tweet_cleaned_train_df['text']\n",
      "rewrite-ns": 298065,
      "overhead-ns": 298065,
      "exec-ns": 245136,
      "total-ns": 543201,
      "patts-hit": {},
      "rewritten": "_ = tweet_cleaned_train_df['text']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# catboost = LogisticRegression()",
      "rewrite-ns": 11944,
      "overhead-ns": 11944,
      "exec-ns": 63372,
      "total-ns": 75316,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# pipeline_sgd = Pipeline([\n#     ('tfidf',  TfidfVectorizer()),\n#     ('nb', catboost,)\n# ])",
      "rewrite-ns": 11035,
      "overhead-ns": 11035,
      "exec-ns": 58434,
      "total-ns": 69469,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# model = pipeline_sgd.fit(X_train, y_train)",
      "rewrite-ns": 10075,
      "overhead-ns": 10075,
      "exec-ns": 55511,
      "total-ns": 65586,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# y_predict = model.predict(X_valid)",
      "rewrite-ns": 10303,
      "overhead-ns": 10303,
      "exec-ns": 55313,
      "total-ns": 65616,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# print(classification_report(y_valid, y_predict))",
      "rewrite-ns": 9848,
      "overhead-ns": 9848,
      "exec-ns": 54204,
      "total-ns": 64052,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# y_pred_test = model.predict(tweet_cleaned_test_df['text'])\ny_pred_test = tweet_cleaned_test_df['text']",
      "rewrite-ns": 290033,
      "overhead-ns": 290033,
      "exec-ns": 231875,
      "total-ns": 521908,
      "patts-hit": {},
      "rewritten": "y_pred_test = tweet_cleaned_test_df['text']\n"
    },
    {
      "raw": "# Saving result on test set\n# FIRST-AUTHOR: remove ML code\noutput = pd.DataFrame({'Id': Id,\n                       'target': y_pred_test})\n\noutput.to_csv(r'submission.csv', index=False)",
      "rewrite-ns": 847149,
      "overhead-ns": 847149,
      "exec-ns": 7002609,
      "total-ns": 7849758,
      "patts-hit": {},
      "rewritten": "output = pd.DataFrame({'Id': Id, 'target': y_pred_test})\noutput.to_csv('submission.csv', index=False)\n"
    },
    {
      "raw": "",
      "rewrite-ns": 12348,
      "overhead-ns": 12348,
      "exec-ns": 68146,
      "total-ns": 80494,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "",
      "rewrite-ns": 11009,
      "overhead-ns": 11009,
      "exec-ns": 61611,
      "total-ns": 72620,
      "patts-hit": {},
      "rewritten": ""
    }
  ],
  "total-time-in-sec": 0.939352298,
  "max-disk-in-mb": 0
}