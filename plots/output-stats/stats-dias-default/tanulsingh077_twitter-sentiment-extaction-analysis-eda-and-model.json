{
  "max-mem-in-mb": 185,
  "max-mem-in-mb2": 192,
  "cells": [
    {
      "raw": "import re\nimport string\nimport numpy as np \nimport random\n# import pandas as pd \nexec(os.environ['IREWR_IMPORTS'])\n# ALEX: remove plotting\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# %matplotlib inline\n# from plotly import graph_objs as go\n# import plotly.express as px\n# import plotly.figure_factory as ff\nfrom collections import Counter\n\n# ALEX: remove plotting, ML code\n# from PIL import Image\n# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\n# import nltk\n# from nltk.corpus import stopwords\n\nfrom tqdm import tqdm\n# ALEX: remove ML code\n# import os\n# import nltk\n# import spacy\n# import random\n# from spacy.util import compounding\n# from spacy.util import minibatch\n\n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# ALEX: remove path\n# import os\n# for dirname, _, filenames in os.walk('./input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n# ALEX: make notebook work with runner\nfrom IPython.display import display",
      "rewrite-ns": 939671,
      "overhead-ns": 939671,
      "exec-ns": 2725979,
      "total-ns": 3665650,
      "patts-hit": {},
      "rewritten": "import re\nimport string\nimport numpy as np\nimport random\nexec(os.environ['IREWR_IMPORTS'])\nfrom collections import Counter\nfrom tqdm import tqdm\nfrom IPython.display import display\n"
    },
    {
      "raw": "def random_colours(number_of_colors):\n    '''\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    '''\n    colors = []\n    for i in range(number_of_colors):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors",
      "rewrite-ns": 1655875,
      "overhead-ns": 1655875,
      "exec-ns": 627439,
      "total-ns": 2283314,
      "patts-hit": {},
      "rewritten": "def random_colours(number_of_colors):\n    \"\"\"\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    \"\"\"\n    colors = []\n    for i in range(number_of_colors):\n        colors.append('#' + ''.join([random.choice('0123456789ABCDEF') for\n            j in range(6)]))\n    return colors\n"
    },
    {
      "raw": "train = pd.read_csv('./input/train.scaled.csv')\ntest = pd.read_csv('./input/test.scaled.csv')\nss = pd.read_csv('./input/sample_submission.scaled.csv')",
      "rewrite-ns": 944243,
      "overhead-ns": 944243,
      "exec-ns": 51394819,
      "total-ns": 52339062,
      "patts-hit": {},
      "rewritten": "train = pd.read_csv('./input/train.scaled.csv')\ntest = pd.read_csv('./input/test.scaled.csv')\nss = pd.read_csv('./input/sample_submission.scaled.csv')\n"
    },
    {
      "raw": "print(train.shape)\nprint(test.shape)",
      "rewrite-ns": 556848,
      "overhead-ns": 556848,
      "exec-ns": 244925,
      "total-ns": 801773,
      "patts-hit": {},
      "rewritten": "print(train.shape)\nprint(test.shape)\n"
    },
    {
      "raw": "train.info()",
      "rewrite-ns": 67961,
      "overhead-ns": 67961,
      "exec-ns": 12626797,
      "total-ns": 12694758,
      "patts-hit": {},
      "rewritten": "train.info()\n"
    },
    {
      "raw": "train.dropna(inplace=True)",
      "rewrite-ns": 357005,
      "overhead-ns": 357005,
      "exec-ns": 10800743,
      "total-ns": 11157748,
      "patts-hit": {},
      "rewritten": "train.dropna(inplace=True)\n"
    },
    {
      "raw": "test.info()",
      "rewrite-ns": 71681,
      "overhead-ns": 71681,
      "exec-ns": 3370964,
      "total-ns": 3442645,
      "patts-hit": {},
      "rewritten": "test.info()\n"
    },
    {
      "raw": "train.head()",
      "rewrite-ns": 76976,
      "overhead-ns": 76976,
      "exec-ns": 4869822,
      "total-ns": 4946798,
      "patts-hit": {},
      "rewritten": "train.head()\n"
    },
    {
      "raw": "train.describe()",
      "rewrite-ns": 77803,
      "overhead-ns": 77803,
      "exec-ns": 28286966,
      "total-ns": 28364769,
      "patts-hit": {},
      "rewritten": "train.describe()\n"
    },
    {
      "raw": "temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Purples')",
      "rewrite-ns": 954682,
      "overhead-ns": 954682,
      "exec-ns": 11541896,
      "total-ns": 12496578,
      "patts-hit": {},
      "rewritten": "temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by\n    ='text', ascending=False)\ntemp\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# sns.countplot(x='sentiment',data=train)",
      "rewrite-ns": 12722,
      "overhead-ns": 12722,
      "exec-ns": 68481,
      "total-ns": 81203,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# ALEX: remove plotting\n# fig = go.Figure(go.Funnelarea(\n#     text =temp.sentiment,\n#     values = temp.text,\n#     title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n#     ))\n# fig.show()\n_ = temp.sentiment\n_ = temp.text",
      "rewrite-ns": 462136,
      "overhead-ns": 462136,
      "exec-ns": 277231,
      "total-ns": 739367,
      "patts-hit": {},
      "rewritten": "_ = temp.sentiment\n_ = temp.text\n"
    },
    {
      "raw": "def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))",
      "rewrite-ns": 2182362,
      "overhead-ns": 2182362,
      "exec-ns": 472882,
      "total-ns": 2655244,
      "patts-hit": {},
      "rewritten": "def jaccard(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n"
    },
    {
      "raw": "results_jaccard=[]\n\nfor ind,row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])",
      "rewrite-ns": 1601549,
      "overhead-ns": 1601549,
      "exec-ns": 1126142597,
      "total-ns": 1127744146,
      "patts-hit": {},
      "rewritten": "results_jaccard = []\nfor ind, row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n    jaccard_score = jaccard(sentence1, sentence2)\n    results_jaccard.append([sentence1, sentence2, jaccard_score])\n"
    },
    {
      "raw": "jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ntrain = train.merge(jaccard,how='outer')",
      "rewrite-ns": 983154,
      "overhead-ns": 983154,
      "exec-ns": 16178947,
      "total-ns": 17162101,
      "patts-hit": {},
      "rewritten": "jaccard = pd.DataFrame(results_jaccard, columns=['text', 'selected_text',\n    'jaccard_score'])\ntrain = train.merge(jaccard, how='outer')\n"
    },
    {
      "raw": "train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text",
      "rewrite-ns": 2413040,
      "overhead-ns": 2413040,
      "exec-ns": 38046827,
      "total-ns": 40459867,
      "patts-hit": {},
      "rewritten": "train['Num_words_ST'] = train['selected_text'].apply(lambda x: len(str(x).\n    split()))\ntrain['Num_word_text'] = train['text'].apply(lambda x: len(str(x).split()))\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST']\n"
    },
    {
      "raw": "train.head()",
      "rewrite-ns": 75193,
      "overhead-ns": 75193,
      "exec-ns": 5806763,
      "total-ns": 5881956,
      "patts-hit": {},
      "rewritten": "train.head()\n"
    },
    {
      "raw": "hist_data = [train['Num_words_ST'],train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\n# ALEX: remove plotting\n# fig = ff.create_distplot(hist_data, group_labels,show_curve=False)\n# fig.update_layout(title_text='Distribution of Number Of words')\n# fig.update_layout(\n#     autosize=False,\n#     width=900,\n#     height=700,\n#     paper_bgcolor=\"LightSteelBlue\",\n# )\n# fig.show()",
      "rewrite-ns": 726055,
      "overhead-ns": 726055,
      "exec-ns": 273710,
      "total-ns": 999765,
      "patts-hit": {},
      "rewritten": "hist_data = [train['Num_words_ST'], train['Num_word_text']]\ngroup_labels = ['Selected_Text', 'Text']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# p1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\n# p1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")\n_ = train['Num_words_ST']\n_ = train['Num_word_text']",
      "rewrite-ns": 505400,
      "overhead-ns": 505400,
      "exec-ns": 221627,
      "total-ns": 727027,
      "patts-hit": {},
      "rewritten": "_ = train['Num_words_ST']\n_ = train['Num_word_text']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# p1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\n# p2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")\n_ = train[train['sentiment']=='positive']['difference_in_words']\n_ = train[train['sentiment']=='negative']['difference_in_words']",
      "rewrite-ns": 1078326,
      "overhead-ns": 1078326,
      "exec-ns": 4531854,
      "total-ns": 5610180,
      "patts-hit": {},
      "rewritten": "_ = train[train['sentiment'] == 'positive']['difference_in_words']\n_ = train[train['sentiment'] == 'negative']['difference_in_words']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# sns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)\n_ = train[train['sentiment']=='neutral']['difference_in_words']",
      "rewrite-ns": 587461,
      "overhead-ns": 587461,
      "exec-ns": 2151338,
      "total-ns": 2738799,
      "patts-hit": {},
      "rewritten": "_ = train[train['sentiment'] == 'neutral']['difference_in_words']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# p1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\n# p2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\n# plt.legend(labels=['positive','negative'])\n_ = train[train['sentiment']=='positive']['jaccard_score']\n_ = train[train['sentiment']=='negative']['jaccard_score']",
      "rewrite-ns": 1079575,
      "overhead-ns": 1079575,
      "exec-ns": 4083217,
      "total-ns": 5162792,
      "patts-hit": {},
      "rewritten": "_ = train[train['sentiment'] == 'positive']['jaccard_score']\n_ = train[train['sentiment'] == 'negative']['jaccard_score']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# sns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)\n_ = train[train['sentiment']=='neutral']['jaccard_score']",
      "rewrite-ns": 569994,
      "overhead-ns": 569994,
      "exec-ns": 2117756,
      "total-ns": 2687750,
      "patts-hit": {},
      "rewritten": "_ = train[train['sentiment'] == 'neutral']['jaccard_score']\n"
    },
    {
      "raw": "k = train[train['Num_word_text']<=2]",
      "rewrite-ns": 485100,
      "overhead-ns": 485100,
      "exec-ns": 566244,
      "total-ns": 1051344,
      "patts-hit": {},
      "rewritten": "k = train[train['Num_word_text'] <= 2]\n"
    },
    {
      "raw": "# ALEX: make notebook run\n# k.groupby('sentiment').mean()['jaccard_score']\nk.groupby('sentiment').mean(numeric_only=True)['jaccard_score']",
      "rewrite-ns": 558045,
      "overhead-ns": 558045,
      "exec-ns": 1661346,
      "total-ns": 2219391,
      "patts-hit": {},
      "rewritten": "k.groupby('sentiment').mean(numeric_only=True)['jaccard_score']\n"
    },
    {
      "raw": "k[k['sentiment']=='positive']",
      "rewrite-ns": 445732,
      "overhead-ns": 445732,
      "exec-ns": 6915910,
      "total-ns": 7361642,
      "patts-hit": {},
      "rewritten": "k[k['sentiment'] == 'positive']\n"
    },
    {
      "raw": "def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text",
      "rewrite-ns": 3028365,
      "overhead-ns": 3028365,
      "exec-ns": 633997,
      "total-ns": 3662362,
      "patts-hit": {},
      "rewritten": "def clean_text(text):\n    \"\"\"Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.\"\"\"\n    text = str(text).lower()\n    text = re.sub('\\\\[.*?\\\\]', '', text)\n    text = re.sub('https?://\\\\S+|www\\\\.\\\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\\\w*\\\\d\\\\w*', '', text)\n    return text\n"
    },
    {
      "raw": "train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))",
      "rewrite-ns": 1422220,
      "overhead-ns": 1422220,
      "exec-ns": 555919918,
      "total-ns": 557342138,
      "patts-hit": {},
      "rewritten": "train['text'] = train['text'].apply(lambda x: clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x: clean_text(x))\n"
    },
    {
      "raw": "train.head()",
      "rewrite-ns": 136664,
      "overhead-ns": 136664,
      "exec-ns": 6502902,
      "total-ns": 6639566,
      "patts-hit": {},
      "rewritten": "train.head()\n"
    },
    {
      "raw": "train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Blues')",
      "rewrite-ns": 2210845,
      "overhead-ns": 2210845,
      "exec-ns": 43723863,
      "total-ns": 45934708,
      "patts-hit": {},
      "rewritten": "train['temp_list'] = train['selected_text'].apply(lambda x: str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words', 'count']\ntemp\n"
    },
    {
      "raw": "# fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "rewrite-ns": 15329,
      "overhead-ns": 15329,
      "exec-ns": 76992,
      "total-ns": 92321,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "def remove_stopword(x):\n# ALEX: make notebook run\n#     return [y for y in x if y not in stopwords.words('english')]\n    return [y for y in x if y not in ['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n                                      'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n                                      \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n                                      'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n                                      'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they',\n                                      'them', 'their', 'theirs', 'themselves', 'what', 'which',\n                                      'who', 'whom', 'this', 'that', \"that'll\", 'these',\n                                      'those', 'am', 'is', 'are', 'was', 'were', 'be',\n                                      'been', 'being', 'have', 'has', 'had', 'having', 'do',\n                                      'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',\n                                      'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n                                      'by', 'for', 'with', 'about', 'against', 'between', 'into',\n                                      'through', 'during', 'before', 'after', 'above',\n                                      'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n                                      'off', 'over', 'under', 'again', 'further', 'then', 'once',\n                                      'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any',\n                                      'both', 'each', 'few', 'more', 'most', 'other', 'some',\n                                      'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n                                      'than', 'too', 'very', 's', 't', 'can', 'will', 'just',\n                                      'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n                                      'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n                                      \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\n                                      \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn',\n                                      \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n                                      'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n                                      'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))",
      "rewrite-ns": 7856257,
      "overhead-ns": 7856257,
      "exec-ns": 232186972,
      "total-ns": 240043229,
      "patts-hit": {},
      "rewritten": "def remove_stopword(x):\n    return [y for y in x if y not in ['i', 'me', 'my', 'myself', 'we',\n        'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n        \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him',\n        'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it',\n        \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs',\n        'themselves', 'what', 'which', 'who', 'whom', 'this', 'that',\n        \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be',\n        'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n        'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n        'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with',\n        'about', 'against', 'between', 'into', 'through', 'during',\n        'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n        'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\n        'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how',\n        'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other',\n        'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n        'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don',\n        \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're',\n        've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn',\n        \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\",\n        'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\",\n        'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn',\n        \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\",\n        'wouldn', \"wouldn't\"]]\ntrain['temp_list'] = train['temp_list'].apply(lambda x: remove_stopword(x))\n"
    },
    {
      "raw": "top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Purples')",
      "rewrite-ns": 1855984,
      "overhead-ns": 1855984,
      "exec-ns": 14631107,
      "total-ns": 16487091,
      "patts-hit": {},
      "rewritten": "top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:, :]\ntemp.columns = ['Common_words', 'count']\ntemp\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n# fig.show()",
      "rewrite-ns": 15572,
      "overhead-ns": 15572,
      "exec-ns": 79095,
      "total-ns": 94667,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords",
      "rewrite-ns": 1529968,
      "overhead-ns": 1529968,
      "exec-ns": 374640340,
      "total-ns": 376170308,
      "patts-hit": {},
      "rewritten": "train['temp_list1'] = train['text'].apply(lambda x: str(x).split())\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x: remove_stopword(x))\n"
    },
    {
      "raw": "top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Blues')",
      "rewrite-ns": 1868402,
      "overhead-ns": 1868402,
      "exec-ns": 28985038,
      "total-ns": 30853440,
      "patts-hit": {},
      "rewritten": "top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:, :]\ntemp.columns = ['Common_words', 'count']\ntemp\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "rewrite-ns": 19073,
      "overhead-ns": 19073,
      "exec-ns": 91370,
      "total-ns": 110443,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "Positive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']",
      "rewrite-ns": 1355860,
      "overhead-ns": 1355860,
      "exec-ns": 9794840,
      "total-ns": 11150700,
      "patts-hit": {},
      "rewritten": "Positive_sent = train[train['sentiment'] == 'positive']\nNegative_sent = train[train['sentiment'] == 'negative']\nNeutral_sent = train[train['sentiment'] == 'neutral']\n"
    },
    {
      "raw": "#MosT common positive words\ntop = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp_positive # .style.background_gradient(cmap='Greens')",
      "rewrite-ns": 1487699,
      "overhead-ns": 1487699,
      "exec-ns": 6579969,
      "total-ns": 8067668,
      "patts-hit": {},
      "rewritten": "top = Counter([item for sublist in Positive_sent['temp_list'] for item in\n    sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words', 'count']\ntemp_positive\n"
    },
    {
      "raw": "# fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "rewrite-ns": 14239,
      "overhead-ns": 14239,
      "exec-ns": 75706,
      "total-ns": 89945,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "#MosT common negative words\ntop = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp_negative # .style.background_gradient(cmap='Reds')",
      "rewrite-ns": 1846229,
      "overhead-ns": 1846229,
      "exec-ns": 6235572,
      "total-ns": 8081801,
      "patts-hit": {},
      "rewritten": "top = Counter([item for sublist in Negative_sent['temp_list'] for item in\n    sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:, :]\ntemp_negative.columns = ['Common_words', 'count']\ntemp_negative\n"
    },
    {
      "raw": "# fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\n# fig.show()",
      "rewrite-ns": 13026,
      "overhead-ns": 13026,
      "exec-ns": 70863,
      "total-ns": 83889,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "#MosT common Neutral words\ntop = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp_neutral # .style.background_gradient(cmap='Reds')",
      "rewrite-ns": 1845652,
      "overhead-ns": 1845652,
      "exec-ns": 11143557,
      "total-ns": 12989209,
      "patts-hit": {},
      "rewritten": "top = Counter([item for sublist in Neutral_sent['temp_list'] for item in\n    sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:, :]\ntemp_neutral.columns = ['Common_words', 'count']\ntemp_neutral\n"
    },
    {
      "raw": "# fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "rewrite-ns": 12993,
      "overhead-ns": 12993,
      "exec-ns": 69749,
      "total-ns": 82742,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\n# fig.show()",
      "rewrite-ns": 11185,
      "overhead-ns": 11185,
      "exec-ns": 58518,
      "total-ns": 69703,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "raw_text = [word for word_list in train['temp_list1'] for word in word_list]",
      "rewrite-ns": 598697,
      "overhead-ns": 598697,
      "exec-ns": 6230273,
      "total-ns": 6828970,
      "patts-hit": {},
      "rewritten": "raw_text = [word for word_list in train['temp_list1'] for word in word_list]\n"
    },
    {
      "raw": "def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words",
      "rewrite-ns": 4556469,
      "overhead-ns": 4556469,
      "exec-ns": 1027224,
      "total-ns": 5583693,
      "patts-hit": {},
      "rewritten": "def words_unique(sentiment, numwords, raw_words):\n    \"\"\"\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    \"\"\"\n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother.append(word)\n    allother = list(set(allother))\n    specificnonly = [x for x in raw_text if x not in allother]\n    mycounter = Counter()\n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns=[\n        'words', 'count'])\n    return Unique_words\n"
    },
    {
      "raw": "Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\n# ALEX: remove table styling\nUnique_Positive # .style.background_gradient(cmap='Greens')",
      "rewrite-ns": 440349,
      "overhead-ns": 440349,
      "exec-ns": 29738120944,
      "total-ns": 29738561293,
      "patts-hit": {},
      "rewritten": "Unique_Positive = words_unique('positive', 20, raw_text)\nprint('The top 20 unique words in Positive Tweets are:')\nUnique_Positive\n"
    },
    {
      "raw": "# fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\n# fig.show()",
      "rewrite-ns": 33079,
      "overhead-ns": 33079,
      "exec-ns": 152544,
      "total-ns": 185623,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# from palettable.colorbrewer.qualitative import Pastel1_7\n# ALEX: remove plotting\n# plt.figure(figsize=(16,10))\n# my_circle=plt.Circle((0,0), 0.7, color='white')\n# plt.pie(Unique_Positive['count'], labels=Unique_Positive.words) # , colors=Pastel1_7.hex_colors)\n# p=plt.gcf()\n# p.gca().add_artist(my_circle)\n# plt.title('DoNut Plot Of Unique Positive Words')\n# plt.show()\n_ = Unique_Positive['count']",
      "rewrite-ns": 401260,
      "overhead-ns": 401260,
      "exec-ns": 365431,
      "total-ns": 766691,
      "patts-hit": {},
      "rewritten": "_ = Unique_Positive['count']\n"
    },
    {
      "raw": "Unique_Negative= words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\n# ALEX: remove table styling\nUnique_Negative # .style.background_gradient(cmap='Reds')",
      "rewrite-ns": 473116,
      "overhead-ns": 473116,
      "exec-ns": 30000514696,
      "total-ns": 30000987812,
      "patts-hit": {},
      "rewritten": "Unique_Negative = words_unique('negative', 10, raw_text)\nprint('The top 10 unique words in Negative Tweets are:')\nUnique_Negative\n"
    },
    {
      "raw": "# from palettable.colorbrewer.qualitative import Pastel1_7\n# ALEX: remove plotting\n# plt.figure(figsize=(16,10))\n# my_circle=plt.Circle((0,0), 0.7, color='white')\n# plt.rcParams['text.color'] = 'black'\n# plt.pie(Unique_Negative['count'], labels=Unique_Negative.words) # , colors=Pastel1_7.hex_colors)\n# p=plt.gcf()\n# p.gca().add_artist(my_circle)\n# plt.title('DoNut Plot Of Unique Negative Words')\n# plt.show()\n_ = Unique_Negative['count']",
      "rewrite-ns": 444449,
      "overhead-ns": 444449,
      "exec-ns": 432733,
      "total-ns": 877182,
      "patts-hit": {},
      "rewritten": "_ = Unique_Negative['count']\n"
    },
    {
      "raw": "Unique_Neutral= words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\n# ALEX: remove plotting\nUnique_Neutral # .style.background_gradient(cmap='Oranges')",
      "rewrite-ns": 469994,
      "overhead-ns": 469994,
      "exec-ns": 28432732438,
      "total-ns": 28433202432,
      "patts-hit": {},
      "rewritten": "Unique_Neutral = words_unique('neutral', 10, raw_text)\nprint('The top 10 unique words in Neutral Tweets are:')\nUnique_Neutral\n"
    },
    {
      "raw": "# from palettable.colorbrewer.qualitative import Pastel1_7\n# ALEX: remove plotting\n# plt.figure(figsize=(16,10))\n# my_circle=plt.Circle((0,0), 0.7, color='white')\n# plt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words) # , colors=Pastel1_7.hex_colors)\n# p=plt.gcf()\n# p.gca().add_artist(my_circle)\n# plt.title('DoNut Plot Of Unique Neutral Words')\n# plt.show()\nUnique_Neutral['count']",
      "rewrite-ns": 380418,
      "overhead-ns": 380418,
      "exec-ns": 915433,
      "total-ns": 1295851,
      "patts-hit": {},
      "rewritten": "Unique_Neutral['count']\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n#                    title = None, title_size=40, image_color=False):\n#     stopwords = set(STOPWORDS)\n#     more_stopwords = {'u', \"im\"}\n#     stopwords = stopwords.union(more_stopwords)\n\n#     wordcloud = WordCloud(background_color=color,\n#                     stopwords = stopwords,\n#                     max_words = max_words,\n#                     max_font_size = max_font_size, \n#                     random_state = 42,\n#                     width=400, \n#                     height=200,\n#                     mask = mask)\n#     wordcloud.generate(str(text))\n    \n#     plt.figure(figsize=figure_size)\n#     if image_color:\n#         image_colors = ImageColorGenerator(mask);\n#         plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n#         plt.title(title, fontdict={'size': title_size,  \n#                                   'verticalalignment': 'bottom'})\n#     else:\n#         plt.imshow(wordcloud);\n#         plt.title(title, fontdict={'size': title_size, 'color': 'black', \n#                                   'verticalalignment': 'bottom'})\n#     plt.axis('off');\n#     plt.tight_layout()  \n# d = '/kaggle/input/masks-for-wordclouds/'",
      "rewrite-ns": 18671,
      "overhead-ns": 18671,
      "exec-ns": 71831,
      "total-ns": 90502,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# ALEX: remove plotting\n# pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\n# plot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")\n_ = Neutral_sent.text",
      "rewrite-ns": 269690,
      "overhead-ns": 269690,
      "exec-ns": 243660,
      "total-ns": 513350,
      "patts-hit": {},
      "rewritten": "_ = Neutral_sent.text\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plot_wordcloud(Positive_sent.text,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)\n_ = Positive_sent.text",
      "rewrite-ns": 246543,
      "overhead-ns": 246543,
      "exec-ns": 224280,
      "total-ns": 470823,
      "patts-hit": {},
      "rewritten": "_ = Positive_sent.text\n"
    },
    {
      "raw": "# ALEX: remove plotting\n# plot_wordcloud(Negative_sent.text,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)\n_ = Negative_sent.text",
      "rewrite-ns": 242308,
      "overhead-ns": 242308,
      "exec-ns": 225211,
      "total-ns": 467519,
      "patts-hit": {},
      "rewritten": "_ = Negative_sent.text\n"
    },
    {
      "raw": "df_train = pd.read_csv('./input/train.scaled.csv')\ndf_test = pd.read_csv('./input/test.scaled.csv')\ndf_submission = pd.read_csv('./input/sample_submission.scaled.csv')",
      "rewrite-ns": 955569,
      "overhead-ns": 955569,
      "exec-ns": 52459333,
      "total-ns": 53414902,
      "patts-hit": {},
      "rewritten": "df_train = pd.read_csv('./input/train.scaled.csv')\ndf_test = pd.read_csv('./input/test.scaled.csv')\ndf_submission = pd.read_csv('./input/sample_submission.scaled.csv')\n"
    },
    {
      "raw": "df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set",
      "rewrite-ns": 1126564,
      "overhead-ns": 1126564,
      "exec-ns": 21844072,
      "total-ns": 22970636,
      "patts-hit": {},
      "rewritten": "df_train['Num_words_text'] = df_train['text'].apply(lambda x: len(str(x).\n    split()))\n"
    },
    {
      "raw": "df_train = df_train[df_train['Num_words_text']>=3]",
      "rewrite-ns": 526167,
      "overhead-ns": 526167,
      "exec-ns": 1681747,
      "total-ns": 2207914,
      "patts-hit": {},
      "rewritten": "df_train = df_train[df_train['Num_words_text'] >= 3]\n"
    },
    {
      "raw": "def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'./working/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)",
      "rewrite-ns": 2042175,
      "overhead-ns": 2042175,
      "exec-ns": 530549,
      "total-ns": 2572724,
      "patts-hit": {},
      "rewritten": "def save_model(output_dir, nlp, new_model_name):\n    \"\"\" This Function Saves model to \n    given output directory\"\"\"\n    output_dir = f'./working/{output_dir}'\n    if output_dir is not None:\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta['name'] = new_model_name\n        nlp.to_disk(output_dir)\n        print('Saved model to', output_dir)\n"
    },
    {
      "raw": "# pass model = nlp if you want to train on top of existing model \n\n# ALEX: remove ML code\n# def train(train_data, output_dir, n_iter=20, model=None):\n#     \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n#     \"\"\n#     if model is not None:\n#         nlp = spacy.load(output_dir)  # load existing spaCy model\n#         print(\"Loaded model '%s'\" % model)\n#     else:\n#         nlp = spacy.blank(\"en\")  # create blank Language class\n#         print(\"Created blank 'en' model\")\n    \n#     # create the built-in pipeline components and add them to the pipeline\n#     # nlp.create_pipe works for built-ins that are registered with spaCy\n#     if \"ner\" not in nlp.pipe_names:\n#         ner = nlp.create_pipe(\"ner\")\n#         nlp.add_pipe(ner, last=True)\n#     # otherwise, get it so we can add labels\n#     else:\n#         ner = nlp.get_pipe(\"ner\")\n    \n#     # add labels\n#     for _, annotations in train_data:\n#         for ent in annotations.get(\"entities\"):\n#             ner.add_label(ent[2])\n\n#     # get names of other pipes to disable them during training\n#     other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n#     with nlp.disable_pipes(*other_pipes):  # only train NER\n#         # sizes = compounding(1.0, 4.0, 1.001)\n#         # batch up the examples using spaCy's minibatch\n#         if model is None:\n#             nlp.begin_training()\n#         else:\n#             nlp.resume_training()\n\n\n#         for itn in tqdm(range(n_iter)):\n#             random.shuffle(train_data)\n#             batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n#             losses = {}\n#             for batch in batches:\n#                 texts, annotations = zip(*batch)\n#                 nlp.update(texts,  # batch of texts\n#                             annotations,  # batch of annotations\n#                             drop=0.5,   # dropout - make it harder to memorise data\n#                             losses=losses, \n#                             )\n#             print(\"Losses\", losses)\n#     save_model(output_dir, nlp, 'st_ner')",
      "rewrite-ns": 21464,
      "overhead-ns": 21464,
      "exec-ns": 68089,
      "total-ns": 89553,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# ALEX: remove ML code\n# def get_model_out_path(sentiment):\n#     '''\n#     Returns Model output path\n#     '''\n#     model_out_path = None\n#     if sentiment == 'positive':\n#         model_out_path = 'models/model_pos'\n#     elif sentiment == 'negative':\n#         model_out_path = 'models/model_neg'\n#     return model_out_path",
      "rewrite-ns": 11951,
      "overhead-ns": 11951,
      "exec-ns": 59836,
      "total-ns": 71787,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data",
      "rewrite-ns": 2677230,
      "overhead-ns": 2677230,
      "exec-ns": 629183,
      "total-ns": 3306413,
      "patts-hit": {},
      "rewritten": "def get_training_data(sentiment):\n    \"\"\"\n    Returns Trainong data in the format needed to train spacy NER\n    \"\"\"\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {'entities': [[start, end,\n                'selected_text']]}))\n    return train_data\n"
    },
    {
      "raw": "sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\n# ALEX: remove ML code\n# model_path = get_model_out_path(sentiment)\n# # For DEmo Purposes I have taken 3 iterations you can train the model as you want\n# train(train_data, model_path, n_iter=3, model=None)",
      "rewrite-ns": 428755,
      "overhead-ns": 428755,
      "exec-ns": 928156421,
      "total-ns": 928585176,
      "patts-hit": {},
      "rewritten": "sentiment = 'positive'\ntrain_data = get_training_data(sentiment)\n"
    },
    {
      "raw": "sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\n# ALEX: remove ML\n# model_path = get_model_out_path(sentiment)\n\n# train(train_data, model_path, n_iter=3, model=None)",
      "rewrite-ns": 515405,
      "overhead-ns": 515405,
      "exec-ns": 964126504,
      "total-ns": 964641909,
      "patts-hit": {},
      "rewritten": "sentiment = 'negative'\ntrain_data = get_training_data(sentiment)\n"
    },
    {
      "raw": "# ALEX: remove ML code\n# def predict_entities(text, model):\n#     doc = model(text)\n#     ent_array = []\n#     for ent in doc.ents:\n#         start = text.find(ent.text)\n#         end = start + len(ent.text)\n#         new_int = [start, end, ent.label_]\n#         if new_int not in ent_array:\n#             ent_array.append([start, end, ent.label_])\n#     selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n#     return selected_text",
      "rewrite-ns": 27010,
      "overhead-ns": 27010,
      "exec-ns": 100831,
      "total-ns": 127841,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# ALEX: remove ML\n# selected_texts = []\n# MODELS_BASE_PATH = './input/tse-spacy-model/models/'\n\n# if MODELS_BASE_PATH is not None:\n#     print(\"Loading Models  from \", MODELS_BASE_PATH)\n#     model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n#     model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n#     for index, row in df_test.iterrows():\n#         text = row.text\n#         output_str = \"\"\n#         if row.sentiment == 'neutral' or len(text.split()) <= 2:\n#             selected_texts.append(text)\n#         elif row.sentiment == 'positive':\n#             selected_texts.append(predict_entities(text, model_pos))\n#         else:\n#             selected_texts.append(predict_entities(text, model_neg))\n\nselected_texts = [': you get to go home and i have to go to work' for _ in range(len(df_test))]\n\ndf_test['selected_text'] = selected_texts",
      "rewrite-ns": 858355,
      "overhead-ns": 858355,
      "exec-ns": 808418,
      "total-ns": 1666773,
      "patts-hit": {},
      "rewritten": "selected_texts = [': you get to go home and i have to go to work' for _ in\n    range(len(df_test))]\ndf_test['selected_text'] = selected_texts\n"
    },
    {
      "raw": "df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))",
      "rewrite-ns": 1066500,
      "overhead-ns": 1066500,
      "exec-ns": 9409119,
      "total-ns": 10475619,
      "patts-hit": {},
      "rewritten": "df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv('submission.csv', index=False)\ndisplay(df_submission.head(10))\n"
    },
    {
      "raw": "",
      "rewrite-ns": 12108,
      "overhead-ns": 12108,
      "exec-ns": 71296,
      "total-ns": 83404,
      "patts-hit": {},
      "rewritten": ""
    }
  ],
  "total-time-in-sec": 92.853567991,
  "max-disk-in-mb": 0
}