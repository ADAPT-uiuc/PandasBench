{
  "max-mem-in-mb": 976,
  "max-mem-in-mb2": 249,
  "cells": [
    {
      "raw": "import re\nimport string\nimport numpy as np \nimport random\n# import pandas as pd \nexec(os.environ['IREWR_IMPORTS'])\n# ALEX: remove plotting\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# %matplotlib inline\n# from plotly import graph_objs as go\n# import plotly.express as px\n# import plotly.figure_factory as ff\nfrom collections import Counter\n\n# ALEX: remove plotting, ML code\n# from PIL import Image\n# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\n# import nltk\n# from nltk.corpus import stopwords\n\nfrom tqdm import tqdm\n# ALEX: remove ML code\n# import os\n# import nltk\n# import spacy\n# import random\n# from spacy.util import compounding\n# from spacy.util import minibatch\n\n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# ALEX: remove path\n# import os\n# for dirname, _, filenames in os.walk('./input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n# ALEX: make notebook work with runner\nfrom IPython.display import display",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 3370825211
    },
    {
      "raw": "def random_colours(number_of_colors):\n    '''\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    '''\n    colors = []\n    for i in range(number_of_colors):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1224752
    },
    {
      "raw": "train = pd.read_csv('./input/train.scaled.csv')\ntest = pd.read_csv('./input/test.scaled.csv')\nss = pd.read_csv('./input/sample_submission.scaled.csv')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 2597452911
    },
    {
      "raw": "print(train.shape)\nprint(test.shape)",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 459993
    },
    {
      "raw": "train.info()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 92534131
    },
    {
      "raw": "train.dropna(inplace=True)",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 5544390
    },
    {
      "raw": "test.info()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 52684319
    },
    {
      "raw": "train.head()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 17863479
    },
    {
      "raw": "train.describe()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 9885207
    },
    {
      "raw": "temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Purples')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 115064965
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# sns.countplot(x='sentiment',data=train)",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 254666
    },
    {
      "raw": "# ALEX: remove plotting\n# fig = go.Figure(go.Funnelarea(\n#     text =temp.sentiment,\n#     values = temp.text,\n#     title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n#     ))\n# fig.show()\n_ = temp.sentiment\n_ = temp.text",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 2183900
    },
    {
      "raw": "def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 797143
    },
    {
      "raw": "results_jaccard=[]\n\nfor ind,row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 751345821371
    },
    {
      "raw": "jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ntrain = train.merge(jaccard,how='outer')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 127063398
    },
    {
      "raw": "train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 67410766
    },
    {
      "raw": "train.head()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1313760
    },
    {
      "raw": "hist_data = [train['Num_words_ST'],train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\n# ALEX: remove plotting\n# fig = ff.create_distplot(hist_data, group_labels,show_curve=False)\n# fig.update_layout(title_text='Distribution of Number Of words')\n# fig.update_layout(\n#     autosize=False,\n#     width=900,\n#     height=700,\n#     paper_bgcolor=\"LightSteelBlue\",\n# )\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 2591344
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# p1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\n# p1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")\n_ = train['Num_words_ST']\n_ = train['Num_word_text']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 2254286
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# p1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\n# p2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")\n_ = train[train['sentiment']=='positive']['difference_in_words']\n_ = train[train['sentiment']=='negative']['difference_in_words']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 131896643
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# sns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)\n_ = train[train['sentiment']=='neutral']['difference_in_words']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 56837092
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# p1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\n# p2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\n# plt.legend(labels=['positive','negative'])\n_ = train[train['sentiment']=='positive']['jaccard_score']\n_ = train[train['sentiment']=='negative']['jaccard_score']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 148736087
    },
    {
      "raw": "# ALEX: remove plotting\n# plt.figure(figsize=(12,6))\n# sns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)\n_ = train[train['sentiment']=='neutral']['jaccard_score']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 72035120
    },
    {
      "raw": "k = train[train['Num_word_text']<=2]",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 15518775
    },
    {
      "raw": "# ALEX: make notebook run\n# k.groupby('sentiment').mean()['jaccard_score']\nk.groupby('sentiment').mean(numeric_only=True)['jaccard_score']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 139122145
    },
    {
      "raw": "k[k['sentiment']=='positive']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 9599540
    },
    {
      "raw": "def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1271688
    },
    {
      "raw": "train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 170952346
    },
    {
      "raw": "train.head()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1209072
    },
    {
      "raw": "train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Blues')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 242757011
    },
    {
      "raw": "# fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 301797
    },
    {
      "raw": "def remove_stopword(x):\n# ALEX: make notebook run\n#     return [y for y in x if y not in stopwords.words('english')]\n    return [y for y in x if y not in ['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n                                      'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n                                      \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n                                      'he', 'him', 'his', 'himself', 'she', \"she's\", 'her',\n                                      'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they',\n                                      'them', 'their', 'theirs', 'themselves', 'what', 'which',\n                                      'who', 'whom', 'this', 'that', \"that'll\", 'these',\n                                      'those', 'am', 'is', 'are', 'was', 'were', 'be',\n                                      'been', 'being', 'have', 'has', 'had', 'having', 'do',\n                                      'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but',\n                                      'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at',\n                                      'by', 'for', 'with', 'about', 'against', 'between', 'into',\n                                      'through', 'during', 'before', 'after', 'above',\n                                      'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n                                      'off', 'over', 'under', 'again', 'further', 'then', 'once',\n                                      'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any',\n                                      'both', 'each', 'few', 'more', 'most', 'other', 'some',\n                                      'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n                                      'than', 'too', 'very', 's', 't', 'can', 'will', 'just',\n                                      'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n                                      'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn',\n                                      \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\n                                      \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn',\n                                      \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n                                      'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n                                      'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 33533523
    },
    {
      "raw": "top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Purples')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 200373240
    },
    {
      "raw": "# ALEX: remove plotting\n# fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 296366
    },
    {
      "raw": "train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 174236537
    },
    {
      "raw": "top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp # .style.background_gradient(cmap='Blues')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 352628342
    },
    {
      "raw": "# ALEX: remove plotting\n# fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 313771
    },
    {
      "raw": "Positive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 57889570
    },
    {
      "raw": "#MosT common positive words\ntop = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp_positive # .style.background_gradient(cmap='Greens')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 333627582
    },
    {
      "raw": "# fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 288113
    },
    {
      "raw": "#MosT common negative words\ntop = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp_negative # .style.background_gradient(cmap='Reds')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 76413075
    },
    {
      "raw": "# fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 278283
    },
    {
      "raw": "#MosT common Neutral words\ntop = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\n# ALEX: remove table styling\ntemp_neutral # .style.background_gradient(cmap='Reds')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 107310850
    },
    {
      "raw": "# fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n#              width=700, height=700,color='Common_words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 282000
    },
    {
      "raw": "# fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 255641
    },
    {
      "raw": "raw_text = [word for word_list in train['temp_list1'] for word in word_list]",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 152311747
    },
    {
      "raw": "def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1747438
    },
    {
      "raw": "Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\n# ALEX: remove table styling\nUnique_Positive # .style.background_gradient(cmap='Greens')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 33075038372
    },
    {
      "raw": "# fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\n# fig.show()",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 284544
    },
    {
      "raw": "# from palettable.colorbrewer.qualitative import Pastel1_7\n# ALEX: remove plotting\n# plt.figure(figsize=(16,10))\n# my_circle=plt.Circle((0,0), 0.7, color='white')\n# plt.pie(Unique_Positive['count'], labels=Unique_Positive.words) # , colors=Pastel1_7.hex_colors)\n# p=plt.gcf()\n# p.gca().add_artist(my_circle)\n# plt.title('DoNut Plot Of Unique Positive Words')\n# plt.show()\n_ = Unique_Positive['count']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1760503
    },
    {
      "raw": "Unique_Negative= words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\n# ALEX: remove table styling\nUnique_Negative # .style.background_gradient(cmap='Reds')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 31559423723
    },
    {
      "raw": "# from palettable.colorbrewer.qualitative import Pastel1_7\n# ALEX: remove plotting\n# plt.figure(figsize=(16,10))\n# my_circle=plt.Circle((0,0), 0.7, color='white')\n# plt.rcParams['text.color'] = 'black'\n# plt.pie(Unique_Negative['count'], labels=Unique_Negative.words) # , colors=Pastel1_7.hex_colors)\n# p=plt.gcf()\n# p.gca().add_artist(my_circle)\n# plt.title('DoNut Plot Of Unique Negative Words')\n# plt.show()\n_ = Unique_Negative['count']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1110284
    },
    {
      "raw": "Unique_Neutral= words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\n# ALEX: remove plotting\nUnique_Neutral # .style.background_gradient(cmap='Oranges')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 28859221585
    },
    {
      "raw": "# from palettable.colorbrewer.qualitative import Pastel1_7\n# ALEX: remove plotting\n# plt.figure(figsize=(16,10))\n# my_circle=plt.Circle((0,0), 0.7, color='white')\n# plt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words) # , colors=Pastel1_7.hex_colors)\n# p=plt.gcf()\n# p.gca().add_artist(my_circle)\n# plt.title('DoNut Plot Of Unique Neutral Words')\n# plt.show()\nUnique_Neutral['count']",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1120245
    },
    {
      "raw": "# ALEX: remove plotting\n# def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n#                    title = None, title_size=40, image_color=False):\n#     stopwords = set(STOPWORDS)\n#     more_stopwords = {'u', \"im\"}\n#     stopwords = stopwords.union(more_stopwords)\n\n#     wordcloud = WordCloud(background_color=color,\n#                     stopwords = stopwords,\n#                     max_words = max_words,\n#                     max_font_size = max_font_size, \n#                     random_state = 42,\n#                     width=400, \n#                     height=200,\n#                     mask = mask)\n#     wordcloud.generate(str(text))\n    \n#     plt.figure(figsize=figure_size)\n#     if image_color:\n#         image_colors = ImageColorGenerator(mask);\n#         plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n#         plt.title(title, fontdict={'size': title_size,  \n#                                   'verticalalignment': 'bottom'})\n#     else:\n#         plt.imshow(wordcloud);\n#         plt.title(title, fontdict={'size': title_size, 'color': 'black', \n#                                   'verticalalignment': 'bottom'})\n#     plt.axis('off');\n#     plt.tight_layout()  \n# d = '/kaggle/input/masks-for-wordclouds/'",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 353920
    },
    {
      "raw": "# ALEX: remove plotting\n# pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\n# plot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")\n_ = Neutral_sent.text",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 12202399
    },
    {
      "raw": "# ALEX: remove plotting\n# plot_wordcloud(Positive_sent.text,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)\n_ = Positive_sent.text",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 10527362
    },
    {
      "raw": "# ALEX: remove plotting\n# plot_wordcloud(Negative_sent.text,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)\n_ = Negative_sent.text",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 11468168
    },
    {
      "raw": "df_train = pd.read_csv('./input/train.scaled.csv')\ndf_test = pd.read_csv('./input/test.scaled.csv')\ndf_submission = pd.read_csv('./input/sample_submission.scaled.csv')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 130102938
    },
    {
      "raw": "df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 20126040
    },
    {
      "raw": "df_train = df_train[df_train['Num_words_text']>=3]",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 6564740
    },
    {
      "raw": "def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'./working/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 716384
    },
    {
      "raw": "# pass model = nlp if you want to train on top of existing model \n\n# ALEX: remove ML code\n# def train(train_data, output_dir, n_iter=20, model=None):\n#     \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n#     \"\"\n#     if model is not None:\n#         nlp = spacy.load(output_dir)  # load existing spaCy model\n#         print(\"Loaded model '%s'\" % model)\n#     else:\n#         nlp = spacy.blank(\"en\")  # create blank Language class\n#         print(\"Created blank 'en' model\")\n    \n#     # create the built-in pipeline components and add them to the pipeline\n#     # nlp.create_pipe works for built-ins that are registered with spaCy\n#     if \"ner\" not in nlp.pipe_names:\n#         ner = nlp.create_pipe(\"ner\")\n#         nlp.add_pipe(ner, last=True)\n#     # otherwise, get it so we can add labels\n#     else:\n#         ner = nlp.get_pipe(\"ner\")\n    \n#     # add labels\n#     for _, annotations in train_data:\n#         for ent in annotations.get(\"entities\"):\n#             ner.add_label(ent[2])\n\n#     # get names of other pipes to disable them during training\n#     other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n#     with nlp.disable_pipes(*other_pipes):  # only train NER\n#         # sizes = compounding(1.0, 4.0, 1.001)\n#         # batch up the examples using spaCy's minibatch\n#         if model is None:\n#             nlp.begin_training()\n#         else:\n#             nlp.resume_training()\n\n\n#         for itn in tqdm(range(n_iter)):\n#             random.shuffle(train_data)\n#             batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n#             losses = {}\n#             for batch in batches:\n#                 texts, annotations = zip(*batch)\n#                 nlp.update(texts,  # batch of texts\n#                             annotations,  # batch of annotations\n#                             drop=0.5,   # dropout - make it harder to memorise data\n#                             losses=losses, \n#                             )\n#             print(\"Losses\", losses)\n#     save_model(output_dir, nlp, 'st_ner')",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 744246
    },
    {
      "raw": "# ALEX: remove ML code\n# def get_model_out_path(sentiment):\n#     '''\n#     Returns Model output path\n#     '''\n#     model_out_path = None\n#     if sentiment == 'positive':\n#         model_out_path = 'models/model_pos'\n#     elif sentiment == 'negative':\n#         model_out_path = 'models/model_neg'\n#     return model_out_path",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 260499
    },
    {
      "raw": "def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1005909
    },
    {
      "raw": "sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\n# ALEX: remove ML code\n# model_path = get_model_out_path(sentiment)\n# # For DEmo Purposes I have taken 3 iterations you can train the model as you want\n# train(train_data, model_path, n_iter=3, model=None)",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 659542914641
    },
    {
      "raw": "sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\n# ALEX: remove ML\n# model_path = get_model_out_path(sentiment)\n\n# train(train_data, model_path, n_iter=3, model=None)",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 569481371017
    },
    {
      "raw": "# ALEX: remove ML code\n# def predict_entities(text, model):\n#     doc = model(text)\n#     ent_array = []\n#     for ent in doc.ents:\n#         start = text.find(ent.text)\n#         end = start + len(ent.text)\n#         new_int = [start, end, ent.label_]\n#         if new_int not in ent_array:\n#             ent_array.append([start, end, ent.label_])\n#     selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n#     return selected_text",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 564692
    },
    {
      "raw": "# ALEX: remove ML\n# selected_texts = []\n# MODELS_BASE_PATH = './input/tse-spacy-model/models/'\n\n# if MODELS_BASE_PATH is not None:\n#     print(\"Loading Models  from \", MODELS_BASE_PATH)\n#     model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n#     model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n#     for index, row in df_test.iterrows():\n#         text = row.text\n#         output_str = \"\"\n#         if row.sentiment == 'neutral' or len(text.split()) <= 2:\n#             selected_texts.append(text)\n#         elif row.sentiment == 'positive':\n#             selected_texts.append(predict_entities(text, model_pos))\n#         else:\n#             selected_texts.append(predict_entities(text, model_neg))\n\nselected_texts = [': you get to go home and i have to go to work' for _ in range(len(df_test))]\n\ndf_test['selected_text'] = selected_texts",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 5298096
    },
    {
      "raw": "df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 1517449946
    },
    {
      "raw": "",
      "external_calls": {},
      "all_calls": {},
      "total-ns": 267662
    }
  ],
  "total-time-in-sec": 2084.535151301,
  "max-disk-in-mb": 0
}