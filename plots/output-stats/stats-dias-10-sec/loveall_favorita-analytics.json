{
  "max-mem-in-mb": 4243,
  "max-mem-in-mb2": 5065,
  "cells": [
    {
      "raw": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n\n# FIRST-AUTHOR: remove ML code\n# import xgboost as xgb\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# FIRST-AUTHOR: remove path printing\n# from subprocess import check_output\n# print(check_output([\"ls\", \"./input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "rewrite-ns": 820223,
      "overhead-ns": 820223,
      "exec-ns": 553338083,
      "total-ns": 554158306,
      "patts-hit": {},
      "rewritten": "import numpy as np\nexec(os.environ['IREWR_IMPORTS'])\nimport matplotlib.pyplot as plt\n"
    },
    {
      "raw": "#Since training data is huge, so I am planning to read few millions of rows from the csv file.\ntrain = pd.read_csv(\"./input/train.csv\", nrows=nrows, parse_dates=['date'],index_col='id')\n\n#print the last 10 rows of the data, this will help us to think what we can dow with the data.\ntrain.tail(5)",
      "rewrite-ns": 1084038,
      "overhead-ns": 1084038,
      "exec-ns": 4506037320,
      "total-ns": 4507121358,
      "patts-hit": {},
      "rewritten": "train = pd.read_csv('./input/train.csv', nrows=nrows, parse_dates=['date'],\n    index_col='id')\ntrain.tail(5)\n"
    },
    {
      "raw": "items = pd.read_csv(\"./input/items.scaled.csv\")",
      "rewrite-ns": 499251,
      "overhead-ns": 499251,
      "exec-ns": 2118848,
      "total-ns": 2618099,
      "patts-hit": {},
      "rewritten": "items = pd.read_csv('./input/items.scaled.csv')\n"
    },
    {
      "raw": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)",
      "rewrite-ns": 603273,
      "overhead-ns": 603273,
      "exec-ns": 1644758892,
      "total-ns": 1645362165,
      "patts-hit": {},
      "rewritten": "train_items = pd.merge(train, items, how='inner')\ntrain_items.tail(5)\n"
    },
    {
      "raw": "#Lets find out most popular item ordered by people across the 6 millions rows we have read.\n#We will group by item_nbr and add the unit sales.\ndf = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\n#In order to find top 10 popular items we will sort the numpy array and pick the top 10 from\n#the list.\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n\n#Plot the highest list of items.\n# FIRST-AUTHOR: remove plotting\n# df_highest.plot(kind='bar',figsize = (10,10),  title = \"Top 10 items sold across all stores\")\n# plt.show()",
      "rewrite-ns": 1328483,
      "overhead-ns": 1328483,
      "exec-ns": 234067464,
      "total-ns": 235395947,
      "patts-hit": {},
      "rewritten": "df = train_items['unit_sales'].groupby(train_items['item_nbr']).sum()\ndf = df.sort_values()\ndf_highest = df.nlargest(n=10)\n"
    },
    {
      "raw": "#Next we find lowest/less demand product. We use nsmallest to find the bottom 10 items,\n#probably it doesn;t matter even if we stock them.\ndf_lowest = df.nsmallest(n=10)\n# FIRST-AUTHOR: remove plotting\n# df_lowest.plot(kind='bar',figsize = (10,10),  title = \"Bottom 10 items sold\")\n# plt.show()",
      "rewrite-ns": 475249,
      "overhead-ns": 475249,
      "exec-ns": 2079303,
      "total-ns": 2554552,
      "patts-hit": {},
      "rewritten": "df_lowest = df.nsmallest(n=10)\n"
    },
    {
      "raw": "#Next we could find out popular items in a given year. This will be useful to find out \n#if there were any new items introduced in the recent times.\n#In order to do that we need to covert the date field into python date format and then\n# extract various fields from it.\n\ntrain_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] =train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year",
      "rewrite-ns": 2310733,
      "overhead-ns": 2310733,
      "exec-ns": 1845046694,
      "total-ns": 1847357427,
      "patts-hit": {},
      "rewritten": "train_items['date'] = pd.to_datetime(train_items['date'], format='%Y-%m-%d')\ntrain_items['day_item_purchased'] = train_items['date'].dt.day\ntrain_items['month_item_purchased'] = train_items['date'].dt.month\ntrain_items['quarter_item_purchased'] = train_items['date'].dt.quarter\ntrain_items['year_item_purchased'] = train_items['date'].dt.year\n"
    },
    {
      "raw": "train_items.drop('date', axis=1, inplace=True)",
      "rewrite-ns": 545807,
      "overhead-ns": 545807,
      "exec-ns": 469515981,
      "total-ns": 470061788,
      "patts-hit": {},
      "rewritten": "train_items.drop('date', axis=1, inplace=True)\n"
    },
    {
      "raw": "#Lets print out new training dataset\nprint (train_items.tail(2))",
      "rewrite-ns": 491076,
      "overhead-ns": 491076,
      "exec-ns": 7079613,
      "total-ns": 7570689,
      "patts-hit": {},
      "rewritten": "print(train_items.tail(2))\n"
    },
    {
      "raw": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])['unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n#Plot the highest list of items.\n# FIRST-AUTHOR: remove plotting\n# df_year_highest.plot(kind='bar',figsize = (10,10),  title = \"Top items sold Quarterly\")\n# plt.show()",
      "rewrite-ns": 1298256,
      "overhead-ns": 1298256,
      "exec-ns": 660642955,
      "total-ns": 661941211,
      "patts-hit": {},
      "rewritten": "df_year = train_items.groupby(['quarter_item_purchased', 'item_nbr'])[\n    'unit_sales'].sum()\ndf_year = df_year.sort_values()\ndf_year_highest = df_year.nlargest(n=10)\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n# FIRST-AUTHOR: remove plotting\n# plt.pie(df_items_highest, labels=df_items_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_highest.index\n",
      "rewrite-ns": 1443538,
      "overhead-ns": 1443538,
      "exec-ns": 630290097,
      "total-ns": 631733635,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_highest = df_items.nlargest(n=10)\n_ = df_items_highest.index\n"
    },
    {
      "raw": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']",
      "rewrite-ns": 635031,
      "overhead-ns": 635031,
      "exec-ns": 1352345152,
      "total-ns": 1352980183,
      "patts-hit": {},
      "rewritten": "grocery_info = train_items.loc[train_items['family'] == 'GROCERY I']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(12,12))\n# #print (grocery_info.tail(2))\n# plt.plot(grocery_info['day_item_purchased'],grocery_info['unit_sales'])\n# plt.show()\n_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']",
      "rewrite-ns": 659323,
      "overhead-ns": 659323,
      "exec-ns": 529470,
      "total-ns": 1188793,
      "patts-hit": {},
      "rewritten": "_ = grocery_info['day_item_purchased']\n_ = grocery_info['unit_sales']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(9,10))\ndf_items = train_items.groupby(['family','perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n# FIRST-AUTHOR: remove plotting\n# plt.pie(df_items_perish_highest, labels=df_items_perish_highest.index,shadow=False,autopct='%1.1f%%')\n# plt.tight_layout()\n# plt.show()\n_ = df_items_perish_highest.index",
      "rewrite-ns": 1473248,
      "overhead-ns": 1473248,
      "exec-ns": 1003644768,
      "total-ns": 1005118016,
      "patts-hit": {},
      "rewritten": "df_items = train_items.groupby(['family', 'perishable'])['unit_sales'].sum()\ndf_items = df_items.sort_values()\ndf_items_perish_highest = df_items.nlargest(n=10)\n_ = df_items_perish_highest.index\n"
    },
    {
      "raw": "transaction = pd.read_csv(\"./input/transactions.scaled.csv\")",
      "rewrite-ns": 449557,
      "overhead-ns": 449557,
      "exec-ns": 8817628,
      "total-ns": 9267185,
      "patts-hit": {},
      "rewritten": "transaction = pd.read_csv('./input/transactions.scaled.csv')\n"
    },
    {
      "raw": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] =transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint (transaction.tail(2))",
      "rewrite-ns": 2690573,
      "overhead-ns": 2690573,
      "exec-ns": 15403059,
      "total-ns": 18093632,
      "patts-hit": {},
      "rewritten": "transaction['date'] = pd.to_datetime(transaction['date'], format='%Y-%m-%d')\ntransaction['day_item_purchased'] = transaction['date'].dt.day\ntransaction['month_item_purchased'] = transaction['date'].dt.month\ntransaction['quarter_item_purchased'] = transaction['date'].dt.quarter\ntransaction['year_item_purchased'] = transaction['date'].dt.year\nprint(transaction.tail(2))\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(25,25))\n# plt.plot(transaction['date'],transaction['transactions'])\n# plt.show()\n_ = transaction['date']\n_ = transaction['transactions']\n",
      "rewrite-ns": 544209,
      "overhead-ns": 544209,
      "exec-ns": 290390,
      "total-ns": 834599,
      "patts-hit": {},
      "rewritten": "_ = transaction['date']\n_ = transaction['transactions']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(8,12))\ntrans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# FIRST-AUTHOR: remove plotting\n# trans_day.plot(kind='bar')\n# plt.show()",
      "rewrite-ns": 657236,
      "overhead-ns": 657236,
      "exec-ns": 1103946,
      "total-ns": 1761182,
      "patts-hit": {},
      "rewritten": "trans_day = transaction['transactions'].groupby(transaction[\n    'year_item_purchased']).sum()\n"
    },
    {
      "raw": "stores = pd.read_csv(\"./input/stores.scaled.csv\")\nprint (stores.head())",
      "rewrite-ns": 652630,
      "overhead-ns": 652630,
      "exec-ns": 4337283,
      "total-ns": 4989913,
      "patts-hit": {},
      "rewritten": "stores = pd.read_csv('./input/stores.scaled.csv')\nprint(stores.head())\n"
    },
    {
      "raw": "#Lets find out number of cities in each state, which in nothing but finding out number of stores in each\n#in each state.\ndf = stores['city'].groupby(stores['state']).count()\n# FIRST-AUTHOR: remove plotting\n# df.plot(kind='bar', figsize = (12,8), yticks=np.arange(min(df), max(df)+1, 1.0), title = \"Number of cities in each state\")\n# plt.show()\n_ = min(df)\n_ = max(df)",
      "rewrite-ns": 1111877,
      "overhead-ns": 1111877,
      "exec-ns": 733247,
      "total-ns": 1845124,
      "patts-hit": {},
      "rewritten": "df = stores['city'].groupby(stores['state']).count()\n_ = min(df)\n_ = max(df)\n"
    },
    {
      "raw": "#Looks like onpromotion field is always NaN, if so we will get rid of that columns \n#from the training data\nprint(train['onpromotion'].notnull().any())\ntrain_new=train.drop('onpromotion',axis=1)\nprint(train_new.tail(5))",
      "rewrite-ns": 1211843,
      "overhead-ns": 1211843,
      "exec-ns": 171904859,
      "total-ns": 173116702,
      "patts-hit": {},
      "rewritten": "print(train['onpromotion'].notnull().any())\ntrain_new = train.drop('onpromotion', axis=1)\nprint(train_new.tail(5))\n"
    },
    {
      "raw": "oils = pd.read_csv(\"./input/oil.scaled.csv\")\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] =oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year",
      "rewrite-ns": 2658225,
      "overhead-ns": 2658225,
      "exec-ns": 3944265,
      "total-ns": 6602490,
      "patts-hit": {},
      "rewritten": "oils = pd.read_csv('./input/oil.scaled.csv')\noils['date'] = pd.to_datetime(oils['date'], format='%Y-%m-%d')\noils['day_item_purchased'] = oils['date'].dt.day\noils['month_item_purchased'] = oils['date'].dt.month\noils['quarter_item_purchased'] = oils['date'].dt.quarter\noils['year_item_purchased'] = oils['date'].dt.year\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# plt.figure(figsize=(25,25))\n# #trans_day = transaction['transactions'].groupby(transaction['year_item_purchased']).sum()\n# plt.plot(oils['date'],oils['dcoilwtico'])\n# #trans_day.plot(kind='bar')\n# plt.show()\n_ = oils['date']\n_ = oils['dcoilwtico']",
      "rewrite-ns": 552945,
      "overhead-ns": 552945,
      "exec-ns": 314137,
      "total-ns": 867082,
      "patts-hit": {},
      "rewritten": "_ = oils['date']\n_ = oils['dcoilwtico']\n"
    }
  ],
  "total-time-in-sec": 13.142540078,
  "max-disk-in-mb": 0
}