{
  "max-mem-in-mb": 876,
  "max-mem-in-mb2": 1121,
  "cells": [
    {
      "raw": "# Basic\nimport numpy as np \n# import pandas as pd \nexec(os.environ['IREWR_IMPORTS'])\n# FIRST-AUTHOR: remove plotting\n# import seaborn as sns\n# import matplotlib.pyplot as plt \n\n# # System\n# import warnings\n# import os\n# warnings.filterwarnings(\"ignore\")\n# %matplotlib inline\n\n# FIRST-AUTHOR: remove path printing\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))",
      "rewrite-ns": 705393,
      "overhead-ns": 705393,
      "exec-ns": 404268,
      "total-ns": 1109661,
      "patts-hit": {},
      "rewritten": "import numpy as np\nexec(os.environ['IREWR_IMPORTS'])\n"
    },
    {
      "raw": "users = pd.read_csv('./input/BX-Users.scaled.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1') #encoding = \"latin-1\"",
      "rewrite-ns": 834576,
      "overhead-ns": 834576,
      "exec-ns": 103390164,
      "total-ns": 104224740,
      "patts-hit": {},
      "rewritten": "users = pd.read_csv('./input/BX-Users.scaled.csv', error_bad_lines=False,\n    delimiter=';', encoding='ISO-8859-1')\n"
    },
    {
      "raw": "books = pd.read_csv('./input/BX-Books.scaled.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1') #encoding = \"latin-1",
      "rewrite-ns": 954320,
      "overhead-ns": 954320,
      "exec-ns": 727440646,
      "total-ns": 728394966,
      "patts-hit": {},
      "rewritten": "books = pd.read_csv('./input/BX-Books.scaled.csv', error_bad_lines=False,\n    delimiter=';', encoding='ISO-8859-1')\n"
    },
    {
      "raw": "ratings = pd.read_csv('./input/BX-Book-Ratings.scaled.csv', error_bad_lines=False, delimiter=';', encoding = 'ISO-8859-1')",
      "rewrite-ns": 675679,
      "overhead-ns": 675679,
      "exec-ns": 219732563,
      "total-ns": 220408242,
      "patts-hit": {},
      "rewritten": "ratings = pd.read_csv('./input/BX-Book-Ratings.scaled.csv', error_bad_lines\n    =False, delimiter=';', encoding='ISO-8859-1')\n"
    },
    {
      "raw": "users.shape",
      "rewrite-ns": 88165,
      "overhead-ns": 88165,
      "exec-ns": 1053847,
      "total-ns": 1142012,
      "patts-hit": {},
      "rewritten": "users.shape\n"
    },
    {
      "raw": "books.shape",
      "rewrite-ns": 61020,
      "overhead-ns": 61020,
      "exec-ns": 491870,
      "total-ns": 552890,
      "patts-hit": {},
      "rewritten": "books.shape\n"
    },
    {
      "raw": "ratings.shape",
      "rewrite-ns": 53806,
      "overhead-ns": 53806,
      "exec-ns": 440401,
      "total-ns": 494207,
      "patts-hit": {},
      "rewritten": "ratings.shape\n"
    },
    {
      "raw": "users.columns",
      "rewrite-ns": 46924,
      "overhead-ns": 46924,
      "exec-ns": 542014,
      "total-ns": 588938,
      "patts-hit": {},
      "rewritten": "users.columns\n"
    },
    {
      "raw": "ratings.columns",
      "rewrite-ns": 45411,
      "overhead-ns": 45411,
      "exec-ns": 486334,
      "total-ns": 531745,
      "patts-hit": {},
      "rewritten": "ratings.columns\n"
    },
    {
      "raw": "books.columns",
      "rewrite-ns": 44789,
      "overhead-ns": 44789,
      "exec-ns": 486522,
      "total-ns": 531311,
      "patts-hit": {},
      "rewritten": "books.columns\n"
    },
    {
      "raw": "data = pd.merge(ratings, users, on='User-ID', how='inner')",
      "rewrite-ns": 605195,
      "overhead-ns": 605195,
      "exec-ns": 93606998,
      "total-ns": 94212193,
      "patts-hit": {},
      "rewritten": "data = pd.merge(ratings, users, on='User-ID', how='inner')\n"
    },
    {
      "raw": "data = pd.merge(data, books, on='ISBN', how='inner')",
      "rewrite-ns": 647480,
      "overhead-ns": 647480,
      "exec-ns": 364526001,
      "total-ns": 365173481,
      "patts-hit": {},
      "rewritten": "data = pd.merge(data, books, on='ISBN', how='inner')\n"
    },
    {
      "raw": "# Check\ndata.columns",
      "rewrite-ns": 101142,
      "overhead-ns": 101142,
      "exec-ns": 879993,
      "total-ns": 981135,
      "patts-hit": {},
      "rewritten": "data.columns\n"
    },
    {
      "raw": "#data.rename(columns={'Book-Rating':'BookRating', 'User-ID':'UserID'},inplace=True)",
      "rewrite-ns": 14778,
      "overhead-ns": 14778,
      "exec-ns": 81223,
      "total-ns": 96001,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# Drop (TODO: image analysis?)\n'''to_drop = ['Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n\ndata = data.drop(to_drop, axis=1, inplace=False)'''",
      "rewrite-ns": 194423,
      "overhead-ns": 194423,
      "exec-ns": 583129,
      "total-ns": 777552,
      "patts-hit": {},
      "rewritten": "\"\"\"to_drop = ['Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n\ndata = data.drop(to_drop, axis=1, inplace=False)\"\"\"\n"
    },
    {
      "raw": "data.shape",
      "rewrite-ns": 52891,
      "overhead-ns": 52891,
      "exec-ns": 453306,
      "total-ns": 506197,
      "patts-hit": {},
      "rewritten": "data.shape\n"
    },
    {
      "raw": "print('Size of the dataset is: ', data.memory_usage().sum() / 1024**2, ' MB')",
      "rewrite-ns": 773432,
      "overhead-ns": 773432,
      "exec-ns": 1352223,
      "total-ns": 2125655,
      "patts-hit": {},
      "rewritten": "print('Size of the dataset is: ', data.memory_usage().sum() / 1024 ** 2, ' MB')\n"
    },
    {
      "raw": "# TODO: EDA in Power BI",
      "rewrite-ns": 12617,
      "overhead-ns": 12617,
      "exec-ns": 69409,
      "total-ns": 82026,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "data.shape",
      "rewrite-ns": 53549,
      "overhead-ns": 53549,
      "exec-ns": 436758,
      "total-ns": 490307,
      "patts-hit": {},
      "rewritten": "data.shape\n"
    },
    {
      "raw": "data.head(5)",
      "rewrite-ns": 92247,
      "overhead-ns": 92247,
      "exec-ns": 9380089,
      "total-ns": 9472336,
      "patts-hit": {},
      "rewritten": "data.head(5)\n"
    },
    {
      "raw": "data.info()",
      "rewrite-ns": 76565,
      "overhead-ns": 76565,
      "exec-ns": 479241390,
      "total-ns": 479317955,
      "patts-hit": {},
      "rewritten": "data.info()\n"
    },
    {
      "raw": "print('Number of books: ', data['ISBN'].nunique())",
      "rewrite-ns": 568342,
      "overhead-ns": 568342,
      "exec-ns": 46717833,
      "total-ns": 47286175,
      "patts-hit": {},
      "rewritten": "print('Number of books: ', data['ISBN'].nunique())\n"
    },
    {
      "raw": "print('Number of users: ',data['User-ID'].nunique())",
      "rewrite-ns": 556017,
      "overhead-ns": 556017,
      "exec-ns": 4902174,
      "total-ns": 5458191,
      "patts-hit": {},
      "rewritten": "print('Number of users: ', data['User-ID'].nunique())\n"
    },
    {
      "raw": "print('Missing data [%]')\nround(data.isnull().sum() / len(data) * 100, 4)",
      "rewrite-ns": 929546,
      "overhead-ns": 929546,
      "exec-ns": 485782240,
      "total-ns": 486711786,
      "patts-hit": {},
      "rewritten": "print('Missing data [%]')\nround(data.isnull().sum() / len(data) * 100, 4)\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# sns.distplot(data['Age'].dropna(), kde=False)\n_ = data['Age'].dropna()",
      "rewrite-ns": 568253,
      "overhead-ns": 568253,
      "exec-ns": 6318634,
      "total-ns": 6886887,
      "patts-hit": {},
      "rewritten": "_ = data['Age'].dropna()\n"
    },
    {
      "raw": "print('Number of outliers: ', sum(data['Age'] > 100))",
      "rewrite-ns": 643381,
      "overhead-ns": 643381,
      "exec-ns": 30377806,
      "total-ns": 31021187,
      "patts-hit": {},
      "rewritten": "print('Number of outliers: ', sum(data['Age'] > 100))\n"
    },
    {
      "raw": "# data['Book-Rating'] = data['Book-Rating'].replace(0, None)\ndata['Book-Rating'] = data['Book-Rating'].replace([0], None)",
      "rewrite-ns": 226516,
      "overhead-ns": 226516,
      "exec-ns": 11241538,
      "total-ns": 11468054,
      "patts-hit": {},
      "rewritten": "data['Book-Rating'] = data['Book-Rating'].replace([0], None)\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# sns.countplot(x='Book-Rating', data=data)",
      "rewrite-ns": 14277,
      "overhead-ns": 14277,
      "exec-ns": 80847,
      "total-ns": 95124,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "print('Average book rating: ', round(data['Book-Rating'].mean(), 2))",
      "rewrite-ns": 644857,
      "overhead-ns": 644857,
      "exec-ns": 33243628,
      "total-ns": 33888485,
      "patts-hit": {},
      "rewritten": "print('Average book rating: ', round(data['Book-Rating'].mean(), 2))\n"
    },
    {
      "raw": "# Publication by Year\nyear = pd.to_numeric(data['Year-Of-Publication'], 'coerce').fillna(2099, downcast = 'infer')\n# FIRST-AUTHOR: remove plotting\n# sns.distplot(year, kde=False, hist_kws={\"range\": [1945,2020]})",
      "rewrite-ns": 763398,
      "overhead-ns": 763398,
      "exec-ns": 1015485,
      "total-ns": 1778883,
      "patts-hit": {},
      "rewritten": "year = pd.to_numeric(data['Year-Of-Publication'], 'coerce').fillna(2099,\n    downcast='infer')\n"
    },
    {
      "raw": "country = data['Location'].apply(lambda row: str(row).split(',')[-1])\ndata.groupby(country)['Book-Rating'].count().sort_values(ascending=False).head(10)",
      "rewrite-ns": 1289380,
      "overhead-ns": 1289380,
      "exec-ns": 238564319,
      "total-ns": 239853699,
      "patts-hit": {
        "SortHead": 1
      },
      "rewritten": "country = data['Location'].apply(lambda row: str(row).split(',')[-1])\ndias.rewriter.sort_head(called_on=data.groupby(country)['Book-Rating'].\n    count(), by=None, n=10, asc=False, orig=lambda _DIAS_x: _DIAS_x.\n    sort_values(ascending=False).head(10))\n"
    },
    {
      "raw": "# Cast to numeric\ndata['Year-Of-Publication'] = pd.to_numeric(data['Year-Of-Publication'], 'coerce').fillna(2099, downcast = 'infer')",
      "rewrite-ns": 907675,
      "overhead-ns": 907675,
      "exec-ns": 1568964,
      "total-ns": 2476639,
      "patts-hit": {},
      "rewritten": "data['Year-Of-Publication'] = pd.to_numeric(data['Year-Of-Publication'],\n    'coerce').fillna(2099, downcast='infer')\n"
    },
    {
      "raw": "data['Book-Rating'] = data['Book-Rating'].replace(0, None)",
      "rewrite-ns": 232602,
      "overhead-ns": 232602,
      "exec-ns": 13381270,
      "total-ns": 13613872,
      "patts-hit": {},
      "rewritten": "data['Book-Rating'] = data['Book-Rating'].replace(0, None)\n"
    },
    {
      "raw": "data['Age'] = np.where(data['Age']>90, None, data['Age'])",
      "rewrite-ns": 870205,
      "overhead-ns": 870205,
      "exec-ns": 16881535,
      "total-ns": 17751740,
      "patts-hit": {},
      "rewritten": "data['Age'] = np.where(data['Age'] > 90, None, data['Age'])\n"
    },
    {
      "raw": "# Categorical feautes\ndata[['Book-Author', 'Publisher']] = data[['Book-Author', 'Publisher']].fillna('Unknown')",
      "rewrite-ns": 800195,
      "overhead-ns": 800195,
      "exec-ns": 366989138,
      "total-ns": 367789333,
      "patts-hit": {},
      "rewritten": "data[['Book-Author', 'Publisher']] = data[['Book-Author', 'Publisher']].fillna(\n    'Unknown')\n"
    },
    {
      "raw": "# Check cat features\ndata[['Book-Author', 'Publisher']].isnull().sum()",
      "rewrite-ns": 641180,
      "overhead-ns": 641180,
      "exec-ns": 249559878,
      "total-ns": 250201058,
      "patts-hit": {},
      "rewritten": "data[['Book-Author', 'Publisher']].isnull().sum()\n"
    },
    {
      "raw": "# Age\nmedian = data[\"Age\"].median()\nstd = data[\"Age\"].std()\nis_null = data[\"Age\"].isnull().sum()\nrand_age = np.random.randint(median - std, median + std, size = is_null)\nage_slice = data[\"Age\"].copy()\nage_slice[pd.isnull(age_slice)] = rand_age\ndata[\"Age\"] = age_slice\ndata[\"Age\"] = data[\"Age\"].astype(int)",
      "rewrite-ns": 3524540,
      "overhead-ns": 3524540,
      "exec-ns": 275281109,
      "total-ns": 278805649,
      "patts-hit": {},
      "rewritten": "median = data['Age'].median()\nstd = data['Age'].std()\nis_null = data['Age'].isnull().sum()\nrand_age = np.random.randint(median - std, median + std, size=is_null)\nage_slice = data['Age'].copy()\nage_slice[pd.isnull(age_slice)] = rand_age\ndata['Age'] = age_slice\ndata['Age'] = data['Age'].astype(int)\n"
    },
    {
      "raw": "# Check Age\ndata['Age'].isnull().sum()",
      "rewrite-ns": 535136,
      "overhead-ns": 535136,
      "exec-ns": 1294116,
      "total-ns": 1829252,
      "patts-hit": {},
      "rewritten": "data['Age'].isnull().sum()\n"
    },
    {
      "raw": "data['Country'] = data['Location'].apply(lambda row: str(row).split(',')[-1])",
      "rewrite-ns": 1077529,
      "overhead-ns": 1077529,
      "exec-ns": 203312554,
      "total-ns": 204390083,
      "patts-hit": {},
      "rewritten": "data['Country'] = data['Location'].apply(lambda row: str(row).split(',')[-1])\n"
    },
    {
      "raw": "# Drop irelevant\ndata = data.drop('Location', axis=1)",
      "rewrite-ns": 507820,
      "overhead-ns": 507820,
      "exec-ns": 75970019,
      "total-ns": 76477839,
      "patts-hit": {},
      "rewritten": "data = data.drop('Location', axis=1)\n"
    },
    {
      "raw": "data['Country'].head()",
      "rewrite-ns": 440623,
      "overhead-ns": 440623,
      "exec-ns": 1215945,
      "total-ns": 1656568,
      "patts-hit": {},
      "rewritten": "data['Country'].head()\n"
    },
    {
      "raw": "#TODO: country/language analysis (Babel lib?)",
      "rewrite-ns": 15341,
      "overhead-ns": 15341,
      "exec-ns": 84015,
      "total-ns": 99356,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "#en_list = ['usa', 'canada', 'united kingdom', 'australia']",
      "rewrite-ns": 11976,
      "overhead-ns": 11976,
      "exec-ns": 71890,
      "total-ns": 83866,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "#data[data['Country'].isin(en_list)]",
      "rewrite-ns": 10863,
      "overhead-ns": 10863,
      "exec-ns": 62610,
      "total-ns": 73473,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "df = data",
      "rewrite-ns": 225738,
      "overhead-ns": 225738,
      "exec-ns": 196446,
      "total-ns": 422184,
      "patts-hit": {},
      "rewritten": "df = data\n"
    },
    {
      "raw": "# Relevant score\ndf = df[df['Book-Rating'] >= 6]",
      "rewrite-ns": 512433,
      "overhead-ns": 512433,
      "exec-ns": 164176865,
      "total-ns": 164689298,
      "patts-hit": {},
      "rewritten": "df = df[df['Book-Rating'] >= 6]\n"
    },
    {
      "raw": "# Check\ndf.groupby('ISBN')['User-ID'].count().describe()",
      "rewrite-ns": 685876,
      "overhead-ns": 685876,
      "exec-ns": 75658377,
      "total-ns": 76344253,
      "patts-hit": {},
      "rewritten": "df.groupby('ISBN')['User-ID'].count().describe()\n"
    },
    {
      "raw": "df = df.groupby('ISBN').filter(lambda x: len(x) >= 5)",
      "rewrite-ns": 879178,
      "overhead-ns": 879178,
      "exec-ns": 1065584355,
      "total-ns": 1066463533,
      "patts-hit": {},
      "rewritten": "df = df.groupby('ISBN').filter(lambda x: len(x) >= 5)\n"
    },
    {
      "raw": "df.groupby('User-ID')['ISBN'].count().describe()",
      "rewrite-ns": 670966,
      "overhead-ns": 670966,
      "exec-ns": 11848949,
      "total-ns": 12519915,
      "patts-hit": {},
      "rewritten": "df.groupby('User-ID')['ISBN'].count().describe()\n"
    },
    {
      "raw": "df = df.groupby('User-ID').filter(lambda x: len(x) >= 5)",
      "rewrite-ns": 859907,
      "overhead-ns": 859907,
      "exec-ns": 326844501,
      "total-ns": 327704408,
      "patts-hit": {},
      "rewritten": "df = df.groupby('User-ID').filter(lambda x: len(x) >= 5)\n"
    },
    {
      "raw": "df.shape",
      "rewrite-ns": 81574,
      "overhead-ns": 81574,
      "exec-ns": 3709986,
      "total-ns": 3791560,
      "patts-hit": {},
      "rewritten": "df.shape\n"
    },
    {
      "raw": "df_p = df.pivot_table(index='ISBN', columns='User-ID', values='Book-Rating')",
      "rewrite-ns": 581316,
      "overhead-ns": 581316,
      "exec-ns": 4652582077,
      "total-ns": 4653163393,
      "patts-hit": {},
      "rewritten": "df_p = df.pivot_table(index='ISBN', columns='User-ID', values='Book-Rating')\n"
    },
    {
      "raw": "# Select users who liked LOTR\nlotr = df_p.loc['0345339703'] # Lord of the Rings Part 1\nlike_lotr = lotr[lotr == 10].to_frame().reset_index()\nusers = like_lotr['User-ID'].to_frame()",
      "rewrite-ns": 1374280,
      "overhead-ns": 1374280,
      "exec-ns": 3181447,
      "total-ns": 4555727,
      "patts-hit": {},
      "rewritten": "lotr = df_p.loc['0345339703']\nlike_lotr = lotr[lotr == 10].to_frame().reset_index()\nusers = like_lotr['User-ID'].to_frame()\n"
    },
    {
      "raw": "# Trim original dataset\nliked = pd.merge(users, df, on='User-ID', how='inner')",
      "rewrite-ns": 587251,
      "overhead-ns": 587251,
      "exec-ns": 12806051,
      "total-ns": 13393302,
      "patts-hit": {},
      "rewritten": "liked = pd.merge(users, df, on='User-ID', how='inner')\n"
    },
    {
      "raw": "rating_count = liked.groupby('ISBN')['Book-Rating'].count().to_frame()",
      "rewrite-ns": 672954,
      "overhead-ns": 672954,
      "exec-ns": 1213228,
      "total-ns": 1886182,
      "patts-hit": {},
      "rewritten": "rating_count = liked.groupby('ISBN')['Book-Rating'].count().to_frame()\n"
    },
    {
      "raw": "rating_mean = liked.groupby('ISBN')['Book-Rating'].mean().to_frame()",
      "rewrite-ns": 661947,
      "overhead-ns": 661947,
      "exec-ns": 56162973,
      "total-ns": 56824920,
      "patts-hit": {},
      "rewritten": "rating_mean = liked.groupby('ISBN')['Book-Rating'].mean().to_frame()\n"
    },
    {
      "raw": "rating_count.rename(columns={'Book-Rating':'Rating-Count'}, inplace=True)",
      "rewrite-ns": 504847,
      "overhead-ns": 504847,
      "exec-ns": 547572,
      "total-ns": 1052419,
      "patts-hit": {},
      "rewritten": "rating_count.rename(columns={'Book-Rating': 'Rating-Count'}, inplace=True)\n"
    },
    {
      "raw": "rating_mean.rename(columns={'Book-Rating':'Rating-Mean'}, inplace=True)",
      "rewrite-ns": 472800,
      "overhead-ns": 472800,
      "exec-ns": 503255,
      "total-ns": 976055,
      "patts-hit": {},
      "rewritten": "rating_mean.rename(columns={'Book-Rating': 'Rating-Mean'}, inplace=True)\n"
    },
    {
      "raw": "liked = pd.merge(liked, rating_count, on='ISBN', how='inner')",
      "rewrite-ns": 540089,
      "overhead-ns": 540089,
      "exec-ns": 1742574,
      "total-ns": 2282663,
      "patts-hit": {},
      "rewritten": "liked = pd.merge(liked, rating_count, on='ISBN', how='inner')\n"
    },
    {
      "raw": "liked = pd.merge(liked, rating_mean, on='ISBN', how='inner')",
      "rewrite-ns": 554341,
      "overhead-ns": 554341,
      "exec-ns": 1601147,
      "total-ns": 2155488,
      "patts-hit": {},
      "rewritten": "liked = pd.merge(liked, rating_mean, on='ISBN', how='inner')\n"
    },
    {
      "raw": "liked['Rating-Mean'] = liked['Rating-Mean'].round(2)",
      "rewrite-ns": 556117,
      "overhead-ns": 556117,
      "exec-ns": 438686,
      "total-ns": 994803,
      "patts-hit": {},
      "rewritten": "liked['Rating-Mean'] = liked['Rating-Mean'].round(2)\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# liked['Rating-Count'].hist()\nliked['Rating-Count']",
      "rewrite-ns": 245304,
      "overhead-ns": 245304,
      "exec-ns": 1038122,
      "total-ns": 1283426,
      "patts-hit": {},
      "rewritten": "liked['Rating-Count']\n"
    },
    {
      "raw": "C = liked['Rating-Mean'].mean()\nC",
      "rewrite-ns": 448946,
      "overhead-ns": 448946,
      "exec-ns": 615505,
      "total-ns": 1064451,
      "patts-hit": {},
      "rewritten": "C = liked['Rating-Mean'].mean()\nC\n"
    },
    {
      "raw": "m = rating_count.quantile(.995)[0] # .9\nm",
      "rewrite-ns": 469734,
      "overhead-ns": 469734,
      "exec-ns": 982255,
      "total-ns": 1451989,
      "patts-hit": {},
      "rewritten": "m = rating_count.quantile(0.995)[0]\nm\n"
    },
    {
      "raw": "# IMDB formula; source: http://trailerpark.weebly.com/imdb-rating.html?source=post_page---------------------------\ndef weighted_rating(x, m=m, C=C):\n    v = x['Rating-Count']\n    R = x['Rating-Mean']\n\n    return (v/(v+m) * R) + (m/(m+v) * C)",
      "rewrite-ns": 1597517,
      "overhead-ns": 1597517,
      "exec-ns": 372041,
      "total-ns": 1969558,
      "patts-hit": {},
      "rewritten": "def weighted_rating(x, m=m, C=C):\n    v = x['Rating-Count']\n    R = x['Rating-Mean']\n    return v / (v + m) * R + m / (m + v) * C\n"
    },
    {
      "raw": "# Create relevant sub-dataset\nliked_q = liked.copy().loc[liked['Rating-Count'] >= m]\nliked_q.shape",
      "rewrite-ns": 702114,
      "overhead-ns": 702114,
      "exec-ns": 1231973,
      "total-ns": 1934087,
      "patts-hit": {},
      "rewritten": "liked_q = liked.copy().loc[liked['Rating-Count'] >= m]\nliked_q.shape\n"
    },
    {
      "raw": "liked_q['Score'] = liked_q.apply(weighted_rating, axis=1)",
      "rewrite-ns": 548817,
      "overhead-ns": 1183809,
      "exec-ns": 1607138,
      "total-ns": 2155955,
      "patts-hit": {
        "HasOnlyMath": 1
      },
      "rewritten": "liked_q['Score'] = liked_q.apply(weighted_rating, axis=1)\n"
    },
    {
      "raw": "top_r = liked_q[['Book-Title', 'Rating-Mean']]",
      "rewrite-ns": 396149,
      "overhead-ns": 396149,
      "exec-ns": 702846,
      "total-ns": 1098995,
      "patts-hit": {},
      "rewritten": "top_r = liked_q[['Book-Title', 'Rating-Mean']]\n"
    },
    {
      "raw": "top_r = top_r.groupby(['Book-Title'])['Rating-Mean'].mean().to_frame()",
      "rewrite-ns": 697655,
      "overhead-ns": 697655,
      "exec-ns": 831703,
      "total-ns": 1529358,
      "patts-hit": {},
      "rewritten": "top_r = top_r.groupby(['Book-Title'])['Rating-Mean'].mean().to_frame()\n"
    },
    {
      "raw": "top_r.sort_values(by='Rating-Mean', ascending=False).head(10)",
      "rewrite-ns": 318332,
      "overhead-ns": 318332,
      "exec-ns": 3265081,
      "total-ns": 3583413,
      "patts-hit": {
        "SortHead": 1
      },
      "rewritten": "dias.rewriter.sort_head(called_on=top_r, by='Rating-Mean', n=10, asc=False,\n    orig=lambda _DIAS_x: _DIAS_x.sort_values(by='Rating-Mean', ascending=\n    False).head(10))\n"
    },
    {
      "raw": "top_p = liked[['Book-Title', 'Rating-Count']]",
      "rewrite-ns": 397107,
      "overhead-ns": 397107,
      "exec-ns": 877454,
      "total-ns": 1274561,
      "patts-hit": {},
      "rewritten": "top_p = liked[['Book-Title', 'Rating-Count']]\n"
    },
    {
      "raw": "top_p = top_p.groupby(['Book-Title'])['Rating-Count'].mean().to_frame()",
      "rewrite-ns": 699607,
      "overhead-ns": 699607,
      "exec-ns": 1194939,
      "total-ns": 1894546,
      "patts-hit": {},
      "rewritten": "top_p = top_p.groupby(['Book-Title'])['Rating-Count'].mean().to_frame()\n"
    },
    {
      "raw": "top_p.sort_values(by='Rating-Count', ascending=False).head(10)#.plot(kind='barh')",
      "rewrite-ns": 312957,
      "overhead-ns": 312957,
      "exec-ns": 3285013,
      "total-ns": 3597970,
      "patts-hit": {
        "SortHead": 1
      },
      "rewritten": "dias.rewriter.sort_head(called_on=top_p, by='Rating-Count', n=10, asc=False,\n    orig=lambda _DIAS_x: _DIAS_x.sort_values(by='Rating-Count', ascending=\n    False).head(10))\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove plotting\n# from tqdm import tqdm\n# from gensim.models import Word2Vec \nimport random",
      "rewrite-ns": 121784,
      "overhead-ns": 121784,
      "exec-ns": 179550,
      "total-ns": 301334,
      "patts-hit": {},
      "rewritten": "import random\n"
    },
    {
      "raw": "users = df[\"User-ID\"].unique().tolist()\nlen(users)",
      "rewrite-ns": 538783,
      "overhead-ns": 538783,
      "exec-ns": 1006419,
      "total-ns": 1545202,
      "patts-hit": {},
      "rewritten": "users = df['User-ID'].unique().tolist()\nlen(users)\n"
    },
    {
      "raw": "# shuffle users ID's\nrandom.shuffle(users)\n\n# extract 90% of customer ID's\nusers_train = [users[i] for i in range(round(0.9*len(users)))]\n\n# split data into train and validation set\ntrain_df = df[df['User-ID'].isin(users_train)]\nvalidation_df = df[~df['User-ID'].isin(users_train)]",
      "rewrite-ns": 2107624,
      "overhead-ns": 2107624,
      "exec-ns": 9878935,
      "total-ns": 11986559,
      "patts-hit": {},
      "rewritten": "random.shuffle(users)\nusers_train = [users[i] for i in range(round(0.9 * len(users)))]\ntrain_df = df[df['User-ID'].isin(users_train)]\nvalidation_df = df[~df['User-ID'].isin(users_train)]\n"
    },
    {
      "raw": "# list to capture purchase history of the customers\nreads_train = []\n\n# populate the list with the product codes\n# FIRST-AUTHOR: remove extra display code\n# for i in tqdm(users_train):\nfor i in users_train:\n    temp = train_df[train_df[\"User-ID\"] == i][\"ISBN\"].tolist()\n    reads_train.append(temp)",
      "rewrite-ns": 1239906,
      "overhead-ns": 1239906,
      "exec-ns": 739096474,
      "total-ns": 740336380,
      "patts-hit": {},
      "rewritten": "reads_train = []\nfor i in users_train:\n    temp = train_df[train_df['User-ID'] == i]['ISBN'].tolist()\n    reads_train.append(temp)\n"
    },
    {
      "raw": "# list to capture purchase history of the customers\nreads_val = []\n\n# populate the list with the product codes\n# FIRST-AUTHOR: remove extra display code\n# for i in tqdm(validation_df['User-ID'].unique()):\nfor i in validation_df['User-ID'].unique():\n    temp = validation_df[validation_df[\"User-ID\"] == i][\"ISBN\"].tolist()\n    reads_val.append(temp)",
      "rewrite-ns": 1555640,
      "overhead-ns": 1555640,
      "exec-ns": 66637025,
      "total-ns": 68192665,
      "patts-hit": {},
      "rewritten": "reads_val = []\nfor i in validation_df['User-ID'].unique():\n    temp = validation_df[validation_df['User-ID'] == i]['ISBN'].tolist()\n    reads_val.append(temp)\n"
    },
    {
      "raw": "# train word2vec model\n# FIRST-AUTHOR: remove ML code\n# model = Word2Vec(window = 10, sg = 1, hs = 0,\n#                  negative = 10, # for negative sampling\n#                  alpha=0.03, min_alpha=0.0007,\n#                  seed = 14)\n\n# model.build_vocab(reads_train, progress_per=200)\n\n# model.train(reads_train, total_examples = model.corpus_count, \n#             epochs=10, report_delay=1)",
      "rewrite-ns": 19058,
      "overhead-ns": 19058,
      "exec-ns": 101362,
      "total-ns": 120420,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# model.init_sims(replace=True)",
      "rewrite-ns": 12161,
      "overhead-ns": 12161,
      "exec-ns": 71821,
      "total-ns": 83982,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# print(model)",
      "rewrite-ns": 10704,
      "overhead-ns": 10704,
      "exec-ns": 60021,
      "total-ns": 70725,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# extract all vectors\n# FIRST-AUTHOR: remove ML code\n# X = model[model.wv.vocab]\n\n# X.shape",
      "rewrite-ns": 10155,
      "overhead-ns": 10155,
      "exec-ns": 58225,
      "total-ns": 68380,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code, plotting\n# import umap\n\n# cluster_embedding = umap.UMAP(n_neighbors=30, min_dist=0.0,\n#                               n_components=2, random_state=42).fit_transform(X)\n\n# plt.figure(figsize=(10,9))\n# plt.scatter(cluster_embedding[:, 0], cluster_embedding[:, 1], s=3, cmap='Spectral')",
      "rewrite-ns": 11235,
      "overhead-ns": 11235,
      "exec-ns": 53935,
      "total-ns": 65170,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "books = train_df[[\"ISBN\", \"Book-Title\"]]\n\n# remove duplicates\nbooks.drop_duplicates(inplace=True, subset='ISBN', keep=\"last\")\n\n# create product-ID and product-description dictionary\nbooks_dict = books.groupby('ISBN')['Book-Title'].apply(list).to_dict()",
      "rewrite-ns": 1462552,
      "overhead-ns": 1462552,
      "exec-ns": 121817975,
      "total-ns": 123280527,
      "patts-hit": {},
      "rewritten": "books = train_df[['ISBN', 'Book-Title']]\nbooks.drop_duplicates(inplace=True, subset='ISBN', keep='last')\nbooks_dict = books.groupby('ISBN')['Book-Title'].apply(list).to_dict()\n"
    },
    {
      "raw": "# Find LOTR\ndf[df['Book-Title'].str.contains('Lord of the Rings')].sample()",
      "rewrite-ns": 692686,
      "overhead-ns": 692686,
      "exec-ns": 23242542,
      "total-ns": 23935228,
      "patts-hit": {},
      "rewritten": "df[df['Book-Title'].str.contains('Lord of the Rings')].sample()\n"
    },
    {
      "raw": "# Check\nbooks_dict['0345339703']",
      "rewrite-ns": 268716,
      "overhead-ns": 268716,
      "exec-ns": 469235,
      "total-ns": 737951,
      "patts-hit": {},
      "rewritten": "books_dict['0345339703']\n"
    },
    {
      "raw": "# FIRST-AUTHOR: remove ML code\n# def similar_books(v, n = 15):\n    \n#     # extract most similar products for the input vector\n#     ms = model.similar_by_vector(v, topn= n+1)[1:]\n    \n#     # extract name and similarity score of the similar products\n#     new_ms = []\n#     for j in ms:\n#         pair = (books_dict[j[0]][0], j[1])\n#         new_ms.append(pair)\n        \n#     return new_ms ",
      "rewrite-ns": 14638,
      "overhead-ns": 14638,
      "exec-ns": 74001,
      "total-ns": 88639,
      "patts-hit": {},
      "rewritten": ""
    },
    {
      "raw": "# Recommend\n# FIRST-AUTHOR: remove ML code\n# similar_books(model['0345339703'])",
      "rewrite-ns": 10735,
      "overhead-ns": 10735,
      "exec-ns": 59983,
      "total-ns": 70718,
      "patts-hit": {},
      "rewritten": ""
    }
  ],
  "total-time-in-sec": 11.473853041,
  "max-disk-in-mb": 0
}